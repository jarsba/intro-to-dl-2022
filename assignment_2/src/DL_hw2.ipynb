{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 200\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 128\n",
    "BATCH_SIZE_VALIDATION = 128\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- fixed constants ---\n",
    "NUM_CLASSES = 24\n",
    "DATA_DIR = '../data/sign_mnist_%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset initialization ---\n",
    "\n",
    "# We transform image files' contents to tensors\n",
    "# Plus, we can add random transformations to the training data if we like\n",
    "# Think on what kind of transformations may be meaningful for this data.\n",
    "# Eg., horizontal-flip is definitely a bad idea for sign language data.\n",
    "# You can use another transformation here if you find a better one.\n",
    "train_transform = transforms.Compose([\n",
    "                                        #transforms.RandomRotation(degrees=20),\n",
    "                                        #transforms.RandomCrop(size=(24, 24)),\n",
    "                                        #transforms.Pad(padding=2),\n",
    "                                        transforms.ToTensor()\n",
    "                                    ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_set = datasets.ImageFolder(DATA_DIR % 'train', transform=train_transform)\n",
    "dev_set   = datasets.ImageFolder(DATA_DIR % 'dev',   transform=test_transform)\n",
    "test_set  = datasets.ImageFolder(DATA_DIR % 'test',  transform=test_transform)\n",
    "\n",
    "# Create Pytorch data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE_TEST, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=dev_set, batch_size=BATCH_SIZE_VALIDATION, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(50, NUM_CLASSES),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.25, inplace=False)\n",
      "    (6): Linear(in_features=50, out_features=24, bias=True)\n",
      "    (7): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#--- set up ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)\n",
    "loss_function = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch 0 - Batch 0/215: Loss: 3.1852 | Train Acc: 6.250% (8/128)\n",
      "Training: Epoch 0 - Batch 25/215: Loss: 0.1224 | Train Acc: 4.237% (141/3328)\n",
      "Training: Epoch 0 - Batch 50/215: Loss: 0.0625 | Train Acc: 4.366% (285/6528)\n",
      "Training: Epoch 0 - Batch 75/215: Loss: 0.0419 | Train Acc: 4.225% (411/9728)\n",
      "Training: Epoch 0 - Batch 100/215: Loss: 0.0315 | Train Acc: 4.409% (570/12928)\n",
      "Training: Epoch 0 - Batch 125/215: Loss: 0.0252 | Train Acc: 4.384% (707/16128)\n",
      "Training: Epoch 0 - Batch 150/215: Loss: 0.0210 | Train Acc: 4.450% (860/19328)\n",
      "Training: Epoch 0 - Batch 175/215: Loss: 0.0181 | Train Acc: 4.426% (997/22528)\n",
      "Training: Epoch 0 - Batch 200/215: Loss: 0.0158 | Train Acc: 4.462% (1148/25728)\n",
      "Validation: Epoch 0: Loss: 89.0234 | Validation Acc: 3.057% (107/3500)\n",
      "Training: Epoch 1 - Batch 0/215: Loss: 3.1692 | Train Acc: 4.688% (6/128)\n",
      "Training: Epoch 1 - Batch 25/215: Loss: 0.1222 | Train Acc: 4.808% (160/3328)\n",
      "Training: Epoch 1 - Batch 50/215: Loss: 0.0621 | Train Acc: 4.841% (316/6528)\n",
      "Training: Epoch 1 - Batch 75/215: Loss: 0.0417 | Train Acc: 5.140% (500/9728)\n",
      "Training: Epoch 1 - Batch 100/215: Loss: 0.0314 | Train Acc: 5.430% (702/12928)\n",
      "Training: Epoch 1 - Batch 125/215: Loss: 0.0252 | Train Acc: 5.407% (872/16128)\n",
      "Training: Epoch 1 - Batch 150/215: Loss: 0.0210 | Train Acc: 5.500% (1063/19328)\n",
      "Training: Epoch 1 - Batch 175/215: Loss: 0.0180 | Train Acc: 5.589% (1259/22528)\n",
      "Training: Epoch 1 - Batch 200/215: Loss: 0.0157 | Train Acc: 5.737% (1476/25728)\n",
      "Validation: Epoch 1: Loss: 88.7936 | Validation Acc: 4.800% (168/3500)\n",
      "Training: Epoch 2 - Batch 0/215: Loss: 3.1646 | Train Acc: 6.250% (8/128)\n",
      "Training: Epoch 2 - Batch 25/215: Loss: 0.1220 | Train Acc: 7.692% (256/3328)\n",
      "Training: Epoch 2 - Batch 50/215: Loss: 0.0620 | Train Acc: 7.613% (497/6528)\n",
      "Training: Epoch 2 - Batch 75/215: Loss: 0.0412 | Train Acc: 7.771% (756/9728)\n",
      "Training: Epoch 2 - Batch 100/215: Loss: 0.0310 | Train Acc: 8.091% (1046/12928)\n",
      "Training: Epoch 2 - Batch 125/215: Loss: 0.0247 | Train Acc: 8.439% (1361/16128)\n",
      "Training: Epoch 2 - Batch 150/215: Loss: 0.0205 | Train Acc: 8.620% (1666/19328)\n",
      "Training: Epoch 2 - Batch 175/215: Loss: 0.0175 | Train Acc: 8.860% (1996/22528)\n",
      "Training: Epoch 2 - Batch 200/215: Loss: 0.0149 | Train Acc: 9.200% (2367/25728)\n",
      "Validation: Epoch 2: Loss: 83.2009 | Validation Acc: 11.486% (402/3500)\n",
      "Training: Epoch 3 - Batch 0/215: Loss: 2.8854 | Train Acc: 18.750% (24/128)\n",
      "Training: Epoch 3 - Batch 25/215: Loss: 0.1091 | Train Acc: 13.431% (447/3328)\n",
      "Training: Epoch 3 - Batch 50/215: Loss: 0.0540 | Train Acc: 14.354% (937/6528)\n",
      "Training: Epoch 3 - Batch 75/215: Loss: 0.0352 | Train Acc: 15.265% (1485/9728)\n",
      "Training: Epoch 3 - Batch 100/215: Loss: 0.0252 | Train Acc: 16.159% (2089/12928)\n",
      "Training: Epoch 3 - Batch 125/215: Loss: 0.0198 | Train Acc: 17.045% (2749/16128)\n",
      "Training: Epoch 3 - Batch 150/215: Loss: 0.0160 | Train Acc: 17.876% (3455/19328)\n",
      "Training: Epoch 3 - Batch 175/215: Loss: 0.0130 | Train Acc: 18.723% (4218/22528)\n",
      "Training: Epoch 3 - Batch 200/215: Loss: 0.0112 | Train Acc: 19.504% (5018/25728)\n",
      "Validation: Epoch 3: Loss: 65.7861 | Validation Acc: 22.429% (785/3500)\n",
      "Training: Epoch 4 - Batch 0/215: Loss: 2.2080 | Train Acc: 31.250% (40/128)\n",
      "Training: Epoch 4 - Batch 25/215: Loss: 0.0863 | Train Acc: 27.825% (926/3328)\n",
      "Training: Epoch 4 - Batch 50/215: Loss: 0.0396 | Train Acc: 28.998% (1893/6528)\n",
      "Training: Epoch 4 - Batch 75/215: Loss: 0.0266 | Train Acc: 29.914% (2910/9728)\n",
      "Training: Epoch 4 - Batch 100/215: Loss: 0.0213 | Train Acc: 30.028% (3882/12928)\n",
      "Training: Epoch 4 - Batch 125/215: Loss: 0.0171 | Train Acc: 30.872% (4979/16128)\n",
      "Training: Epoch 4 - Batch 150/215: Loss: 0.0122 | Train Acc: 31.597% (6107/19328)\n",
      "Training: Epoch 4 - Batch 175/215: Loss: 0.0095 | Train Acc: 32.222% (7259/22528)\n",
      "Training: Epoch 4 - Batch 200/215: Loss: 0.0100 | Train Acc: 32.898% (8464/25728)\n",
      "Validation: Epoch 4: Loss: 55.8011 | Validation Acc: 35.971% (1259/3500)\n",
      "Training: Epoch 5 - Batch 0/215: Loss: 1.8757 | Train Acc: 37.500% (48/128)\n",
      "Training: Epoch 5 - Batch 25/215: Loss: 0.0678 | Train Acc: 39.513% (1315/3328)\n",
      "Training: Epoch 5 - Batch 50/215: Loss: 0.0320 | Train Acc: 41.054% (2680/6528)\n",
      "Training: Epoch 5 - Batch 75/215: Loss: 0.0224 | Train Acc: 41.345% (4022/9728)\n",
      "Training: Epoch 5 - Batch 100/215: Loss: 0.0160 | Train Acc: 42.133% (5447/12928)\n",
      "Training: Epoch 5 - Batch 125/215: Loss: 0.0126 | Train Acc: 42.677% (6883/16128)\n",
      "Training: Epoch 5 - Batch 150/215: Loss: 0.0102 | Train Acc: 43.310% (8371/19328)\n",
      "Training: Epoch 5 - Batch 175/215: Loss: 0.0092 | Train Acc: 44.092% (9933/22528)\n",
      "Training: Epoch 5 - Batch 200/215: Loss: 0.0074 | Train Acc: 44.558% (11464/25728)\n",
      "Validation: Epoch 5: Loss: 46.8956 | Validation Acc: 45.743% (1601/3500)\n",
      "Training: Epoch 6 - Batch 0/215: Loss: 1.4363 | Train Acc: 58.594% (75/128)\n",
      "Training: Epoch 6 - Batch 25/215: Loss: 0.0526 | Train Acc: 50.030% (1665/3328)\n",
      "Training: Epoch 6 - Batch 50/215: Loss: 0.0301 | Train Acc: 50.490% (3296/6528)\n",
      "Training: Epoch 6 - Batch 75/215: Loss: 0.0198 | Train Acc: 50.319% (4895/9728)\n",
      "Training: Epoch 6 - Batch 100/215: Loss: 0.0146 | Train Acc: 51.021% (6596/12928)\n",
      "Training: Epoch 6 - Batch 125/215: Loss: 0.0111 | Train Acc: 51.333% (8279/16128)\n",
      "Training: Epoch 6 - Batch 150/215: Loss: 0.0103 | Train Acc: 52.033% (10057/19328)\n",
      "Training: Epoch 6 - Batch 175/215: Loss: 0.0077 | Train Acc: 52.379% (11800/22528)\n",
      "Training: Epoch 6 - Batch 200/215: Loss: 0.0057 | Train Acc: 52.942% (13621/25728)\n",
      "Validation: Epoch 6: Loss: 45.3204 | Validation Acc: 46.771% (1637/3500)\n",
      "Training: Epoch 7 - Batch 0/215: Loss: 1.4083 | Train Acc: 54.688% (70/128)\n",
      "Training: Epoch 7 - Batch 25/215: Loss: 0.0522 | Train Acc: 56.400% (1877/3328)\n",
      "Training: Epoch 7 - Batch 50/215: Loss: 0.0225 | Train Acc: 57.751% (3770/6528)\n",
      "Training: Epoch 7 - Batch 75/215: Loss: 0.0153 | Train Acc: 57.895% (5632/9728)\n",
      "Training: Epoch 7 - Batch 100/215: Loss: 0.0140 | Train Acc: 58.369% (7546/12928)\n",
      "Training: Epoch 7 - Batch 125/215: Loss: 0.0085 | Train Acc: 58.643% (9458/16128)\n",
      "Training: Epoch 7 - Batch 150/215: Loss: 0.0076 | Train Acc: 58.883% (11381/19328)\n",
      "Training: Epoch 7 - Batch 175/215: Loss: 0.0068 | Train Acc: 59.153% (13326/22528)\n",
      "Training: Epoch 7 - Batch 200/215: Loss: 0.0058 | Train Acc: 59.387% (15279/25728)\n",
      "Validation: Epoch 7: Loss: 38.6712 | Validation Acc: 53.029% (1856/3500)\n",
      "Training: Epoch 8 - Batch 0/215: Loss: 1.1018 | Train Acc: 62.500% (80/128)\n",
      "Training: Epoch 8 - Batch 25/215: Loss: 0.0431 | Train Acc: 62.861% (2092/3328)\n",
      "Training: Epoch 8 - Batch 50/215: Loss: 0.0183 | Train Acc: 63.388% (4138/6528)\n",
      "Training: Epoch 8 - Batch 75/215: Loss: 0.0122 | Train Acc: 63.672% (6194/9728)\n",
      "Training: Epoch 8 - Batch 100/215: Loss: 0.0095 | Train Acc: 63.877% (8258/12928)\n",
      "Training: Epoch 8 - Batch 125/215: Loss: 0.0072 | Train Acc: 64.199% (10354/16128)\n",
      "Training: Epoch 8 - Batch 150/215: Loss: 0.0059 | Train Acc: 64.559% (12478/19328)\n",
      "Training: Epoch 8 - Batch 175/215: Loss: 0.0060 | Train Acc: 64.768% (14591/22528)\n",
      "Training: Epoch 8 - Batch 200/215: Loss: 0.0045 | Train Acc: 65.050% (16736/25728)\n",
      "Validation: Epoch 8: Loss: 36.9825 | Validation Acc: 55.943% (1958/3500)\n",
      "Training: Epoch 9 - Batch 0/215: Loss: 0.9976 | Train Acc: 67.188% (86/128)\n",
      "Training: Epoch 9 - Batch 25/215: Loss: 0.0359 | Train Acc: 67.248% (2238/3328)\n",
      "Training: Epoch 9 - Batch 50/215: Loss: 0.0173 | Train Acc: 67.203% (4387/6528)\n",
      "Training: Epoch 9 - Batch 75/215: Loss: 0.0126 | Train Acc: 67.486% (6565/9728)\n",
      "Training: Epoch 9 - Batch 100/215: Loss: 0.0094 | Train Acc: 67.358% (8708/12928)\n",
      "Training: Epoch 9 - Batch 125/215: Loss: 0.0070 | Train Acc: 67.460% (10880/16128)\n",
      "Training: Epoch 9 - Batch 150/215: Loss: 0.0038 | Train Acc: 67.731% (13091/19328)\n",
      "Training: Epoch 9 - Batch 175/215: Loss: 0.0048 | Train Acc: 68.071% (15335/22528)\n",
      "Training: Epoch 9 - Batch 200/215: Loss: 0.0046 | Train Acc: 68.144% (17532/25728)\n",
      "Validation: Epoch 9: Loss: 32.8024 | Validation Acc: 60.029% (2101/3500)\n",
      "Training: Epoch 10 - Batch 0/215: Loss: 0.8271 | Train Acc: 69.531% (89/128)\n",
      "Training: Epoch 10 - Batch 25/215: Loss: 0.0342 | Train Acc: 70.042% (2331/3328)\n",
      "Training: Epoch 10 - Batch 50/215: Loss: 0.0163 | Train Acc: 70.818% (4623/6528)\n",
      "Training: Epoch 10 - Batch 75/215: Loss: 0.0121 | Train Acc: 70.446% (6853/9728)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch 10 - Batch 100/215: Loss: 0.0092 | Train Acc: 70.823% (9156/12928)\n",
      "Training: Epoch 10 - Batch 125/215: Loss: 0.0074 | Train Acc: 70.964% (11445/16128)\n",
      "Training: Epoch 10 - Batch 150/215: Loss: 0.0054 | Train Acc: 71.192% (13760/19328)\n",
      "Training: Epoch 10 - Batch 175/215: Loss: 0.0038 | Train Acc: 71.356% (16075/22528)\n",
      "Training: Epoch 10 - Batch 200/215: Loss: 0.0045 | Train Acc: 71.630% (18429/25728)\n",
      "Validation: Epoch 10: Loss: 29.9267 | Validation Acc: 63.229% (2213/3500)\n",
      "Training: Epoch 11 - Batch 0/215: Loss: 0.8696 | Train Acc: 67.188% (86/128)\n",
      "Training: Epoch 11 - Batch 25/215: Loss: 0.0309 | Train Acc: 71.755% (2388/3328)\n",
      "Training: Epoch 11 - Batch 50/215: Loss: 0.0134 | Train Acc: 73.284% (4784/6528)\n",
      "Training: Epoch 11 - Batch 75/215: Loss: 0.0096 | Train Acc: 72.995% (7101/9728)\n",
      "Training: Epoch 11 - Batch 100/215: Loss: 0.0073 | Train Acc: 73.314% (9478/12928)\n",
      "Training: Epoch 11 - Batch 125/215: Loss: 0.0054 | Train Acc: 73.624% (11874/16128)\n",
      "Training: Epoch 11 - Batch 150/215: Loss: 0.0043 | Train Acc: 73.701% (14245/19328)\n",
      "Training: Epoch 11 - Batch 175/215: Loss: 0.0037 | Train Acc: 73.793% (16624/22528)\n",
      "Training: Epoch 11 - Batch 200/215: Loss: 0.0040 | Train Acc: 73.982% (19034/25728)\n",
      "Validation: Epoch 11: Loss: 28.5537 | Validation Acc: 64.400% (2254/3500)\n",
      "Training: Epoch 12 - Batch 0/215: Loss: 0.6661 | Train Acc: 78.906% (101/128)\n",
      "Training: Epoch 12 - Batch 25/215: Loss: 0.0285 | Train Acc: 75.571% (2515/3328)\n",
      "Training: Epoch 12 - Batch 50/215: Loss: 0.0136 | Train Acc: 75.797% (4948/6528)\n",
      "Training: Epoch 12 - Batch 75/215: Loss: 0.0098 | Train Acc: 75.792% (7373/9728)\n",
      "Training: Epoch 12 - Batch 100/215: Loss: 0.0056 | Train Acc: 76.292% (9863/12928)\n",
      "Training: Epoch 12 - Batch 125/215: Loss: 0.0045 | Train Acc: 76.594% (12353/16128)\n",
      "Training: Epoch 12 - Batch 150/215: Loss: 0.0039 | Train Acc: 76.645% (14814/19328)\n",
      "Training: Epoch 12 - Batch 175/215: Loss: 0.0034 | Train Acc: 76.842% (17311/22528)\n",
      "Training: Epoch 12 - Batch 200/215: Loss: 0.0039 | Train Acc: 76.784% (19755/25728)\n",
      "Validation: Epoch 12: Loss: 28.3118 | Validation Acc: 66.200% (2317/3500)\n",
      "Training: Epoch 13 - Batch 0/215: Loss: 0.5903 | Train Acc: 82.031% (105/128)\n",
      "Training: Epoch 13 - Batch 25/215: Loss: 0.0251 | Train Acc: 78.636% (2617/3328)\n",
      "Training: Epoch 13 - Batch 50/215: Loss: 0.0136 | Train Acc: 78.385% (5117/6528)\n",
      "Training: Epoch 13 - Batch 75/215: Loss: 0.0087 | Train Acc: 77.919% (7580/9728)\n",
      "Training: Epoch 13 - Batch 100/215: Loss: 0.0052 | Train Acc: 78.241% (10115/12928)\n",
      "Training: Epoch 13 - Batch 125/215: Loss: 0.0052 | Train Acc: 78.001% (12580/16128)\n",
      "Training: Epoch 13 - Batch 150/215: Loss: 0.0047 | Train Acc: 78.208% (15116/19328)\n",
      "Training: Epoch 13 - Batch 175/215: Loss: 0.0028 | Train Acc: 78.240% (17626/22528)\n",
      "Training: Epoch 13 - Batch 200/215: Loss: 0.0039 | Train Acc: 78.214% (20123/25728)\n",
      "Validation: Epoch 13: Loss: 26.5155 | Validation Acc: 67.400% (2359/3500)\n",
      "Training: Epoch 14 - Batch 0/215: Loss: 0.5654 | Train Acc: 80.469% (103/128)\n",
      "Training: Epoch 14 - Batch 25/215: Loss: 0.0230 | Train Acc: 79.898% (2659/3328)\n",
      "Training: Epoch 14 - Batch 50/215: Loss: 0.0111 | Train Acc: 79.151% (5167/6528)\n",
      "Training: Epoch 14 - Batch 75/215: Loss: 0.0072 | Train Acc: 79.256% (7710/9728)\n",
      "Training: Epoch 14 - Batch 100/215: Loss: 0.0060 | Train Acc: 79.440% (10270/12928)\n",
      "Training: Epoch 14 - Batch 125/215: Loss: 0.0049 | Train Acc: 79.452% (12814/16128)\n",
      "Training: Epoch 14 - Batch 150/215: Loss: 0.0045 | Train Acc: 79.512% (15368/19328)\n",
      "Training: Epoch 14 - Batch 175/215: Loss: 0.0035 | Train Acc: 79.616% (17936/22528)\n",
      "Training: Epoch 14 - Batch 200/215: Loss: 0.0023 | Train Acc: 79.625% (20486/25728)\n",
      "Validation: Epoch 14: Loss: 24.5112 | Validation Acc: 69.857% (2445/3500)\n",
      "Training: Epoch 15 - Batch 0/215: Loss: 0.5826 | Train Acc: 78.906% (101/128)\n",
      "Training: Epoch 15 - Batch 25/215: Loss: 0.0256 | Train Acc: 80.138% (2667/3328)\n",
      "Training: Epoch 15 - Batch 50/215: Loss: 0.0115 | Train Acc: 80.316% (5243/6528)\n",
      "Training: Epoch 15 - Batch 75/215: Loss: 0.0068 | Train Acc: 79.944% (7777/9728)\n",
      "Training: Epoch 15 - Batch 100/215: Loss: 0.0039 | Train Acc: 80.275% (10378/12928)\n",
      "Training: Epoch 15 - Batch 125/215: Loss: 0.0037 | Train Acc: 80.525% (12987/16128)\n",
      "Training: Epoch 15 - Batch 150/215: Loss: 0.0031 | Train Acc: 80.634% (15585/19328)\n",
      "Training: Epoch 15 - Batch 175/215: Loss: 0.0030 | Train Acc: 80.757% (18193/22528)\n",
      "Training: Epoch 15 - Batch 200/215: Loss: 0.0034 | Train Acc: 80.869% (20806/25728)\n",
      "Validation: Epoch 15: Loss: 23.9785 | Validation Acc: 71.400% (2499/3500)\n",
      "Training: Epoch 16 - Batch 0/215: Loss: 0.5169 | Train Acc: 82.031% (105/128)\n",
      "Training: Epoch 16 - Batch 25/215: Loss: 0.0184 | Train Acc: 81.791% (2722/3328)\n",
      "Training: Epoch 16 - Batch 50/215: Loss: 0.0079 | Train Acc: 82.031% (5355/6528)\n",
      "Training: Epoch 16 - Batch 75/215: Loss: 0.0050 | Train Acc: 82.391% (8015/9728)\n",
      "Training: Epoch 16 - Batch 100/215: Loss: 0.0050 | Train Acc: 82.356% (10647/12928)\n",
      "Training: Epoch 16 - Batch 125/215: Loss: 0.0045 | Train Acc: 82.409% (13291/16128)\n",
      "Training: Epoch 16 - Batch 150/215: Loss: 0.0039 | Train Acc: 82.290% (15905/19328)\n",
      "Training: Epoch 16 - Batch 175/215: Loss: 0.0028 | Train Acc: 82.271% (18534/22528)\n",
      "Training: Epoch 16 - Batch 200/215: Loss: 0.0024 | Train Acc: 82.237% (21158/25728)\n",
      "Validation: Epoch 16: Loss: 23.9395 | Validation Acc: 71.857% (2515/3500)\n",
      "Training: Epoch 17 - Batch 0/215: Loss: 0.5005 | Train Acc: 83.594% (107/128)\n",
      "Training: Epoch 17 - Batch 25/215: Loss: 0.0140 | Train Acc: 82.903% (2759/3328)\n",
      "Training: Epoch 17 - Batch 50/215: Loss: 0.0091 | Train Acc: 83.441% (5447/6528)\n",
      "Training: Epoch 17 - Batch 75/215: Loss: 0.0049 | Train Acc: 83.368% (8110/9728)\n",
      "Training: Epoch 17 - Batch 100/215: Loss: 0.0044 | Train Acc: 83.447% (10788/12928)\n",
      "Training: Epoch 17 - Batch 125/215: Loss: 0.0036 | Train Acc: 83.333% (13440/16128)\n",
      "Training: Epoch 17 - Batch 150/215: Loss: 0.0031 | Train Acc: 83.439% (16127/19328)\n",
      "Training: Epoch 17 - Batch 175/215: Loss: 0.0027 | Train Acc: 83.283% (18762/22528)\n",
      "Training: Epoch 17 - Batch 200/215: Loss: 0.0021 | Train Acc: 83.438% (21467/25728)\n",
      "Validation: Epoch 17: Loss: 23.0195 | Validation Acc: 73.514% (2573/3500)\n",
      "Training: Epoch 18 - Batch 0/215: Loss: 0.4051 | Train Acc: 88.281% (113/128)\n",
      "Training: Epoch 18 - Batch 25/215: Loss: 0.0149 | Train Acc: 84.645% (2817/3328)\n",
      "Training: Epoch 18 - Batch 50/215: Loss: 0.0084 | Train Acc: 84.850% (5539/6528)\n",
      "Training: Epoch 18 - Batch 75/215: Loss: 0.0054 | Train Acc: 84.437% (8214/9728)\n",
      "Training: Epoch 18 - Batch 100/215: Loss: 0.0039 | Train Acc: 84.406% (10912/12928)\n",
      "Training: Epoch 18 - Batch 125/215: Loss: 0.0031 | Train Acc: 84.456% (13621/16128)\n",
      "Training: Epoch 18 - Batch 150/215: Loss: 0.0035 | Train Acc: 84.592% (16350/19328)\n",
      "Training: Epoch 18 - Batch 175/215: Loss: 0.0022 | Train Acc: 84.561% (19050/22528)\n",
      "Training: Epoch 18 - Batch 200/215: Loss: 0.0022 | Train Acc: 84.632% (21774/25728)\n",
      "Validation: Epoch 18: Loss: 22.9956 | Validation Acc: 73.314% (2566/3500)\n",
      "Training: Epoch 19 - Batch 0/215: Loss: 0.3430 | Train Acc: 86.719% (111/128)\n",
      "Training: Epoch 19 - Batch 25/215: Loss: 0.0171 | Train Acc: 85.126% (2833/3328)\n",
      "Training: Epoch 19 - Batch 50/215: Loss: 0.0103 | Train Acc: 85.386% (5574/6528)\n",
      "Training: Epoch 19 - Batch 75/215: Loss: 0.0055 | Train Acc: 85.115% (8280/9728)\n",
      "Training: Epoch 19 - Batch 100/215: Loss: 0.0038 | Train Acc: 85.048% (10995/12928)\n",
      "Training: Epoch 19 - Batch 125/215: Loss: 0.0041 | Train Acc: 85.045% (13716/16128)\n",
      "Training: Epoch 19 - Batch 150/215: Loss: 0.0025 | Train Acc: 85.120% (16452/19328)\n",
      "Training: Epoch 19 - Batch 175/215: Loss: 0.0016 | Train Acc: 85.063% (19163/22528)\n",
      "Training: Epoch 19 - Batch 200/215: Loss: 0.0023 | Train Acc: 85.176% (21914/25728)\n",
      "Validation: Epoch 19: Loss: 22.5019 | Validation Acc: 73.229% (2563/3500)\n",
      "Training: Epoch 20 - Batch 0/215: Loss: 0.5203 | Train Acc: 82.031% (105/128)\n",
      "Training: Epoch 20 - Batch 25/215: Loss: 0.0135 | Train Acc: 85.367% (2841/3328)\n",
      "Training: Epoch 20 - Batch 50/215: Loss: 0.0066 | Train Acc: 85.616% (5589/6528)\n",
      "Training: Epoch 20 - Batch 75/215: Loss: 0.0050 | Train Acc: 85.752% (8342/9728)\n",
      "Training: Epoch 20 - Batch 100/215: Loss: 0.0048 | Train Acc: 85.914% (11107/12928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch 20 - Batch 125/215: Loss: 0.0038 | Train Acc: 85.987% (13868/16128)\n",
      "Training: Epoch 20 - Batch 150/215: Loss: 0.0026 | Train Acc: 86.062% (16634/19328)\n",
      "Training: Epoch 20 - Batch 175/215: Loss: 0.0021 | Train Acc: 86.155% (19409/22528)\n",
      "Training: Epoch 20 - Batch 200/215: Loss: 0.0020 | Train Acc: 86.182% (22173/25728)\n",
      "Validation: Epoch 20: Loss: 19.9174 | Validation Acc: 76.514% (2678/3500)\n",
      "Training: Epoch 21 - Batch 0/215: Loss: 0.4290 | Train Acc: 85.156% (109/128)\n",
      "Training: Epoch 21 - Batch 25/215: Loss: 0.0161 | Train Acc: 86.298% (2872/3328)\n",
      "Training: Epoch 21 - Batch 50/215: Loss: 0.0064 | Train Acc: 86.596% (5653/6528)\n",
      "Training: Epoch 21 - Batch 75/215: Loss: 0.0060 | Train Acc: 86.935% (8457/9728)\n",
      "Training: Epoch 21 - Batch 100/215: Loss: 0.0029 | Train Acc: 87.005% (11248/12928)\n",
      "Training: Epoch 21 - Batch 125/215: Loss: 0.0028 | Train Acc: 87.140% (14054/16128)\n",
      "Training: Epoch 21 - Batch 150/215: Loss: 0.0018 | Train Acc: 87.153% (16845/19328)\n",
      "Training: Epoch 21 - Batch 175/215: Loss: 0.0020 | Train Acc: 87.074% (19616/22528)\n",
      "Training: Epoch 21 - Batch 200/215: Loss: 0.0017 | Train Acc: 87.255% (22449/25728)\n",
      "Validation: Epoch 21: Loss: 21.1048 | Validation Acc: 76.200% (2667/3500)\n",
      "Training: Epoch 22 - Batch 0/215: Loss: 0.2987 | Train Acc: 89.844% (115/128)\n",
      "Training: Epoch 22 - Batch 25/215: Loss: 0.0112 | Train Acc: 86.569% (2881/3328)\n",
      "Training: Epoch 22 - Batch 50/215: Loss: 0.0070 | Train Acc: 86.887% (5672/6528)\n",
      "Training: Epoch 22 - Batch 75/215: Loss: 0.0039 | Train Acc: 87.264% (8489/9728)\n",
      "Training: Epoch 22 - Batch 100/215: Loss: 0.0033 | Train Acc: 87.307% (11287/12928)\n",
      "Training: Epoch 22 - Batch 125/215: Loss: 0.0025 | Train Acc: 87.568% (14123/16128)\n",
      "Training: Epoch 22 - Batch 150/215: Loss: 0.0029 | Train Acc: 87.738% (16958/19328)\n",
      "Training: Epoch 22 - Batch 175/215: Loss: 0.0022 | Train Acc: 87.722% (19762/22528)\n",
      "Training: Epoch 22 - Batch 200/215: Loss: 0.0016 | Train Acc: 87.803% (22590/25728)\n",
      "Validation: Epoch 22: Loss: 20.7318 | Validation Acc: 75.829% (2654/3500)\n",
      "Training: Epoch 23 - Batch 0/215: Loss: 0.3337 | Train Acc: 87.500% (112/128)\n",
      "Training: Epoch 23 - Batch 25/215: Loss: 0.0099 | Train Acc: 87.470% (2911/3328)\n",
      "Training: Epoch 23 - Batch 50/215: Loss: 0.0066 | Train Acc: 87.500% (5712/6528)\n",
      "Training: Epoch 23 - Batch 75/215: Loss: 0.0038 | Train Acc: 87.850% (8546/9728)\n",
      "Training: Epoch 23 - Batch 100/215: Loss: 0.0023 | Train Acc: 87.771% (11347/12928)\n",
      "Training: Epoch 23 - Batch 125/215: Loss: 0.0026 | Train Acc: 87.884% (14174/16128)\n",
      "Training: Epoch 23 - Batch 150/215: Loss: 0.0020 | Train Acc: 87.966% (17002/19328)\n",
      "Training: Epoch 23 - Batch 175/215: Loss: 0.0026 | Train Acc: 87.975% (19819/22528)\n",
      "Training: Epoch 23 - Batch 200/215: Loss: 0.0014 | Train Acc: 88.204% (22693/25728)\n",
      "Validation: Epoch 23: Loss: 20.2084 | Validation Acc: 76.857% (2690/3500)\n",
      "Training: Epoch 24 - Batch 0/215: Loss: 0.2607 | Train Acc: 93.750% (120/128)\n",
      "Training: Epoch 24 - Batch 25/215: Loss: 0.0132 | Train Acc: 88.582% (2948/3328)\n",
      "Training: Epoch 24 - Batch 50/215: Loss: 0.0069 | Train Acc: 88.051% (5748/6528)\n",
      "Training: Epoch 24 - Batch 75/215: Loss: 0.0046 | Train Acc: 88.158% (8576/9728)\n",
      "Training: Epoch 24 - Batch 100/215: Loss: 0.0028 | Train Acc: 88.390% (11427/12928)\n",
      "Training: Epoch 24 - Batch 125/215: Loss: 0.0017 | Train Acc: 88.535% (14279/16128)\n",
      "Training: Epoch 24 - Batch 150/215: Loss: 0.0024 | Train Acc: 88.462% (17098/19328)\n",
      "Training: Epoch 24 - Batch 175/215: Loss: 0.0017 | Train Acc: 88.503% (19938/22528)\n",
      "Training: Epoch 24 - Batch 200/215: Loss: 0.0014 | Train Acc: 88.612% (22798/25728)\n",
      "Validation: Epoch 24: Loss: 18.2162 | Validation Acc: 78.629% (2752/3500)\n",
      "Training: Epoch 25 - Batch 0/215: Loss: 0.2547 | Train Acc: 92.188% (118/128)\n",
      "Training: Epoch 25 - Batch 25/215: Loss: 0.0134 | Train Acc: 89.904% (2992/3328)\n",
      "Training: Epoch 25 - Batch 50/215: Loss: 0.0032 | Train Acc: 89.568% (5847/6528)\n",
      "Training: Epoch 25 - Batch 75/215: Loss: 0.0025 | Train Acc: 89.412% (8698/9728)\n",
      "Training: Epoch 25 - Batch 100/215: Loss: 0.0024 | Train Acc: 89.310% (11546/12928)\n",
      "Training: Epoch 25 - Batch 125/215: Loss: 0.0016 | Train Acc: 89.422% (14422/16128)\n",
      "Training: Epoch 25 - Batch 150/215: Loss: 0.0017 | Train Acc: 89.368% (17273/19328)\n",
      "Training: Epoch 25 - Batch 175/215: Loss: 0.0017 | Train Acc: 89.449% (20151/22528)\n",
      "Training: Epoch 25 - Batch 200/215: Loss: 0.0015 | Train Acc: 89.607% (23054/25728)\n",
      "Validation: Epoch 25: Loss: 19.4208 | Validation Acc: 76.629% (2682/3500)\n",
      "Training: Epoch 26 - Batch 0/215: Loss: 0.3154 | Train Acc: 89.062% (114/128)\n",
      "Training: Epoch 26 - Batch 25/215: Loss: 0.0086 | Train Acc: 89.483% (2978/3328)\n",
      "Training: Epoch 26 - Batch 50/215: Loss: 0.0082 | Train Acc: 90.104% (5882/6528)\n",
      "Training: Epoch 26 - Batch 75/215: Loss: 0.0040 | Train Acc: 89.638% (8720/9728)\n",
      "Training: Epoch 26 - Batch 100/215: Loss: 0.0026 | Train Acc: 89.558% (11578/12928)\n",
      "Training: Epoch 26 - Batch 125/215: Loss: 0.0027 | Train Acc: 89.472% (14430/16128)\n",
      "Training: Epoch 26 - Batch 150/215: Loss: 0.0015 | Train Acc: 89.497% (17298/19328)\n",
      "Training: Epoch 26 - Batch 175/215: Loss: 0.0016 | Train Acc: 89.657% (20198/22528)\n",
      "Training: Epoch 26 - Batch 200/215: Loss: 0.0021 | Train Acc: 89.774% (23097/25728)\n",
      "Validation: Epoch 26: Loss: 21.2529 | Validation Acc: 76.657% (2683/3500)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "\n",
    "epoch_stopped = 0\n",
    "\n",
    "#--- training ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        output = model(data)\n",
    "        train_loss = loss_function(output, target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += data.shape[0]\n",
    "\n",
    "        if batch_num % 25 == 0:\n",
    "            print('Training: Epoch %d - Batch %d/%d: Loss: %.4f | Train Acc: %.3f%% (%d/%d)' % \n",
    "                  (epoch, batch_num, len(train_loader), train_loss / (batch_num + 1), \n",
    "                   100. * train_correct / total, train_correct, total))\n",
    "    \n",
    "    validation_loss = 0\n",
    "    validation_correct = 0\n",
    "    validation_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (data, target) in enumerate(validation_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            validation_loss += loss_function(output, target).item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            validation_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            validation_total += data.shape[0]\n",
    "\n",
    "    \n",
    "    print('Validation: Epoch %d: Loss: %.4f | Validation Acc: %.3f%% (%d/%d)' % \n",
    "          (epoch, validation_loss, (100. * validation_correct / validation_total), validation_correct, \n",
    "           validation_total))\n",
    "    \n",
    "    # Check if average of the last 5 validation losses is smaller than current validation loss\n",
    "    if epoch > 4 and statistics.mean(validation_losses[-5:]) < validation_loss:\n",
    "        epoch_stopped = epoch\n",
    "        break\n",
    "        \n",
    "    training_losses.append(train_loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "        \n",
    "    training_accuracies.append((100. * train_correct / total))\n",
    "    validation_accuracies.append((100. * validation_correct / validation_total))\n",
    "\n",
    "    \n",
    "plt.plot(range(epoch_stopped), training_losses, label = \"Training loss\")\n",
    "plt.plot(range(epoch_stopped), validation_losses, label = \"Validation loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(epoch_stopped), training_accuracies, label = \"Training accuracy\")\n",
    "plt.plot(range(epoch_stopped), validation_accuracies, label = \"Validation accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Batch 0/29: Loss: 0.0001 | Test Acc: 91.406% (117/128)\n",
      "Evaluating: Batch 25/29: Loss: 0.0000 | Test Acc: 77.734% (2587/3328)\n",
      "Final test score: Loss: 0.0003, Accuracy: 78.023%\n"
     ]
    }
   ],
   "source": [
    "#--- test ---\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        test_loss += loss_function(output, target).item()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += data.shape[0]\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "        if batch_num % 25 == 0:\n",
    "\n",
    "            print('Evaluating: Batch %d/%d: Loss: %.4f | Test Acc: %.3f%% (%d/%d)' % \n",
    "                  (batch_num, len(test_loader), test_loss / (batch_num + 1), \n",
    "                   100. * test_correct / total, test_correct, total))\n",
    "\n",
    "print(\"Final test score: Loss: %.4f, Accuracy: %.3f%%\" % (test_loss, (100. * test_correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-pytorch",
   "language": "python",
   "name": "basic-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
