=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN                                      --
├─Sequential: 1-1                        --
│    └─Conv2d: 2-1                       1,792
│    └─GroupNorm: 2-2                    128
│    └─ReLU: 2-3                         --
│    └─Conv2d: 2-4                       36,928
│    └─GroupNorm: 2-5                    128
│    └─ReLU: 2-6                         --
│    └─MaxPool2d: 2-7                    --
│    └─Conv2d: 2-8                       73,856
│    └─GroupNorm: 2-9                    256
│    └─ReLU: 2-10                        --
│    └─Conv2d: 2-11                      147,584
│    └─GroupNorm: 2-12                   256
│    └─ReLU: 2-13                        --
│    └─MaxPool2d: 2-14                   --
│    └─Conv2d: 2-15                      295,168
│    └─GroupNorm: 2-16                   512
│    └─ReLU: 2-17                        --
│    └─Conv2d: 2-18                      590,080
│    └─GroupNorm: 2-19                   512
│    └─ReLU: 2-20                        --
│    └─Conv2d: 2-21                      590,080
│    └─GroupNorm: 2-22                   512
│    └─ReLU: 2-23                        --
│    └─MaxPool2d: 2-24                   --
│    └─Conv2d: 2-25                      1,180,160
│    └─GroupNorm: 2-26                   1,024
│    └─ReLU: 2-27                        --
│    └─Conv2d: 2-28                      2,359,808
│    └─GroupNorm: 2-29                   1,024
│    └─ReLU: 2-30                        --
│    └─Conv2d: 2-31                      2,359,808
│    └─GroupNorm: 2-32                   1,024
│    └─ReLU: 2-33                        --
│    └─MaxPool2d: 2-34                   --
├─Sequential: 1-2                        --
│    └─Linear: 2-35                      8,392,704
│    └─ReLU: 2-36                        --
│    └─Dropout: 2-37                     --
│    └─Linear: 2-38                      16,781,312
│    └─ReLU: 2-39                        --
│    └─Dropout: 2-40                     --
│    └─Linear: 2-41                      4,097,000
│    └─ReLU: 2-42                        --
│    └─Dropout: 2-43                     --
│    └─Linear: 2-44                      14,014
=================================================================
Total params: 36,925,670
Trainable params: 36,925,670
Non-trainable params: 0
=================================================================
TRAINING - Epoch 0 Batch 0: loss 0.04925793036818504, f1 0.121,  prec 0.071, rec 0.418
TRAINING - Epoch 0 Batch 10: loss 0.032270096242427826, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 0 Batch 20: loss 0.033531833440065384, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 0 Batch 30: loss 0.030155792832374573, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 0 Batch 40: loss 0.03255333751440048, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 0 Batch 50: loss 0.03187723085284233, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 0 Batch 0: loss 0.03296905383467674, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 0 Batch 10: loss 0.030674170702695847, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 0 Batch 20: loss 0.03188261389732361, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 0: loss 0.0292234905064106, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 10: loss 0.03250577673316002, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 20: loss 0.03169095516204834, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 30: loss 0.030578354373574257, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 40: loss 0.030556898564100266, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 1 Batch 50: loss 0.03146199509501457, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 1 Batch 0: loss 0.03186546266078949, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 1 Batch 10: loss 0.029863720759749413, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 1 Batch 20: loss 0.031441234052181244, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 0: loss 0.02992980182170868, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 10: loss 0.03038320504128933, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 20: loss 0.029650157317519188, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 30: loss 0.03132542967796326, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 40: loss 0.030462056398391724, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 2 Batch 50: loss 0.033301033079624176, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 2 Batch 0: loss 0.030132358893752098, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 2 Batch 10: loss 0.03256390988826752, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 2 Batch 20: loss 0.031895723193883896, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 0: loss 0.029731744900345802, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 10: loss 0.02933141216635704, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 20: loss 0.031093016266822815, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 30: loss 0.030737359076738358, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 40: loss 0.03130445256829262, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 3 Batch 50: loss 0.03163107857108116, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 3 Batch 0: loss 0.03196611627936363, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 3 Batch 10: loss 0.030675599351525307, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 3 Batch 20: loss 0.03135737031698227, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 0: loss 0.030748773366212845, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 10: loss 0.028774455189704895, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 20: loss 0.030969716608524323, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 30: loss 0.03129615634679794, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 40: loss 0.031196052208542824, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 4 Batch 50: loss 0.030721427872776985, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 4 Batch 0: loss 0.0288467425853014, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 4 Batch 10: loss 0.0303002018481493, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 4 Batch 20: loss 0.031191367655992508, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 0: loss 0.03000285103917122, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 10: loss 0.030443500727415085, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 20: loss 0.031278278678655624, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 30: loss 0.03413157910108566, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 40: loss 0.030869828537106514, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 5 Batch 50: loss 0.029589757323265076, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 5 Batch 0: loss 0.032415762543678284, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 5 Batch 10: loss 0.030963962897658348, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 5 Batch 20: loss 0.030947621911764145, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 0: loss 0.030881216749548912, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 10: loss 0.03071756102144718, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 20: loss 0.030467774718999863, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 30: loss 0.031076693907380104, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 40: loss 0.03271397203207016, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 6 Batch 50: loss 0.030057445168495178, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 6 Batch 0: loss 0.029855910688638687, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 6 Batch 10: loss 0.028899189084768295, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 6 Batch 20: loss 0.03150107339024544, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 0: loss 0.03051896020770073, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 10: loss 0.03237686678767204, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 20: loss 0.029861196875572205, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 30: loss 0.02812742069363594, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 40: loss 0.030234768986701965, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 7 Batch 50: loss 0.03131423518061638, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 7 Batch 0: loss 0.031027182936668396, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 7 Batch 10: loss 0.02977902442216873, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 7 Batch 20: loss 0.030414478853344917, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 0: loss 0.03394569456577301, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 10: loss 0.029063453897833824, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 20: loss 0.0297874603420496, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 30: loss 0.0305013544857502, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 40: loss 0.029854942113161087, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 8 Batch 50: loss 0.032308127731084824, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 8 Batch 0: loss 0.03183687478303909, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 8 Batch 10: loss 0.030479654669761658, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 8 Batch 20: loss 0.031940411776304245, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 0: loss 0.030033662915229797, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 10: loss 0.0289462897926569, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 20: loss 0.033506616950035095, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 30: loss 0.031385380774736404, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 40: loss 0.02965523675084114, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 9 Batch 50: loss 0.02854575589299202, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 9 Batch 0: loss 0.031119411811232567, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 9 Batch 10: loss 0.028885412961244583, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 9 Batch 20: loss 0.0290754996240139, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 0: loss 0.028379641473293304, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 10: loss 0.028374817222356796, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 20: loss 0.032270919531583786, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 30: loss 0.0299160685390234, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 40: loss 0.02860899269580841, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 10 Batch 50: loss 0.029342656955122948, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 10 Batch 0: loss 0.031512998044490814, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 10 Batch 10: loss 0.029796728864312172, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 10 Batch 20: loss 0.030618812888860703, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 11 Batch 0: loss 0.030997544527053833, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 11 Batch 10: loss 0.029461270198225975, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 11 Batch 20: loss 0.028857365250587463, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 11 Batch 30: loss 0.029198767617344856, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 11 Batch 40: loss 0.02898631989955902, f1 0.008,  prec 1.0, rec 0.004
TRAINING - Epoch 11 Batch 50: loss 0.03024834766983986, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 11 Batch 0: loss 0.03094034641981125, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 11 Batch 10: loss 0.030803486704826355, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 11 Batch 20: loss 0.03164801746606827, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 12 Batch 0: loss 0.03010156750679016, f1 0.046,  prec 0.429, rec 0.024
TRAINING - Epoch 12 Batch 10: loss 0.029914939776062965, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 12 Batch 20: loss 0.03034719079732895, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 12 Batch 30: loss 0.031049802899360657, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 12 Batch 40: loss 0.029554883018136024, f1 0.007,  prec 0.333, rec 0.004
TRAINING - Epoch 12 Batch 50: loss 0.031369101256132126, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 12 Batch 0: loss 0.030351903289556503, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 12 Batch 10: loss 0.029605675488710403, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 12 Batch 20: loss 0.027537088841199875, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 13 Batch 0: loss 0.028678052127361298, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 13 Batch 10: loss 0.028263099491596222, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 13 Batch 20: loss 0.030332498252391815, f1 0.029,  prec 0.5, rec 0.015
TRAINING - Epoch 13 Batch 30: loss 0.03141053393483162, f1 0.109,  prec 0.586, rec 0.06
TRAINING - Epoch 13 Batch 40: loss 0.030401155352592468, f1 0.266,  prec 0.441, rec 0.19
TRAINING - Epoch 13 Batch 50: loss 0.02863321267068386, f1 0.0,  prec 0.0, rec 0.0
VALIDATION - Epoch 13 Batch 0: loss 0.030049623921513557, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 13 Batch 10: loss 0.027835404500365257, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 13 Batch 20: loss 0.028494851663708687, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 14 Batch 0: loss 0.029278278350830078, f1 0.008,  prec 1.0, rec 0.004
TRAINING - Epoch 14 Batch 10: loss 0.03434251993894577, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 14 Batch 20: loss 0.029645875096321106, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 14 Batch 30: loss 0.028102632611989975, f1 0.14,  prec 0.655, rec 0.079
TRAINING - Epoch 14 Batch 40: loss 0.027847478166222572, f1 0.106,  prec 0.467, rec 0.06
TRAINING - Epoch 14 Batch 50: loss 0.029426537454128265, f1 0.028,  prec 0.571, rec 0.014
VALIDATION - Epoch 14 Batch 0: loss 0.029007086530327797, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 14 Batch 10: loss 0.031295549124479294, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 14 Batch 20: loss 0.027052978053689003, f1 0.009, prec 1.0, rec 0.004
TRAINING - Epoch 15 Batch 0: loss 0.02701597847044468, f1 0.032,  prec 0.364, rec 0.017
TRAINING - Epoch 15 Batch 10: loss 0.027152279391884804, f1 0.024,  prec 0.75, rec 0.012
TRAINING - Epoch 15 Batch 20: loss 0.03062308393418789, f1 0.028,  prec 0.571, rec 0.015
TRAINING - Epoch 15 Batch 30: loss 0.027703259140253067, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 15 Batch 40: loss 0.028139596804976463, f1 0.257,  prec 0.472, rec 0.176
TRAINING - Epoch 15 Batch 50: loss 0.03007361851632595, f1 0.105,  prec 0.5, rec 0.059
VALIDATION - Epoch 15 Batch 0: loss 0.02702324092388153, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 15 Batch 10: loss 0.029782608151435852, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 15 Batch 20: loss 0.0273574348539114, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 16 Batch 0: loss 0.028161928057670593, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 16 Batch 10: loss 0.029551178216934204, f1 0.234,  prec 0.519, rec 0.151
TRAINING - Epoch 16 Batch 20: loss 0.02539561130106449, f1 0.17,  prec 0.75, rec 0.096
TRAINING - Epoch 16 Batch 30: loss 0.027691757306456566, f1 0.281,  prec 0.511, rec 0.193
TRAINING - Epoch 16 Batch 40: loss 0.028937624767422676, f1 0.103,  prec 0.517, rec 0.057
TRAINING - Epoch 16 Batch 50: loss 0.0296359583735466, f1 0.211,  prec 0.434, rec 0.14
VALIDATION - Epoch 16 Batch 0: loss 0.026166770607233047, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 16 Batch 10: loss 0.0307401642203331, f1 0.0, prec 0.0, rec 0.0
VALIDATION - Epoch 16 Batch 20: loss 0.026530291885137558, f1 0.0, prec 0.0, rec 0.0
TRAINING - Epoch 17 Batch 0: loss 0.02684079110622406, f1 0.0,  prec 0.0, rec 0.0
TRAINING - Epoch 17 Batch 10: loss 0.030180731788277626, f1 0.271,  prec 0.459, rec 0.192
TRAINING - Epoch 17 Batch 20: loss 0.028585679829120636, f1 0.171,  prec 0.482, rec 0.104
TRAINING - Epoch 17 Batch 30: loss 0.02828960306942463, f1 0.164,  prec 0.667, rec 0.093
TRAINING - Epoch 17 Batch 40: loss 0.02820572815835476, f1 0.158,  prec 0.611, rec 0.091
TRAINING - Epoch 17 Batch 50: loss 0.027485648170113564, f1 0.175,  prec 0.473, rec 0.107
VALIDATION - Epoch 17 Batch 0: loss 0.029260866343975067, f1 0.236, prec 0.594, rec 0.147
VALIDATION - Epoch 17 Batch 10: loss 0.029062021523714066, f1 0.236, prec 0.586, rec 0.147
VALIDATION - Epoch 17 Batch 20: loss 0.029852811247110367, f1 0.251, prec 0.635, rec 0.157
TRAINING - Epoch 18 Batch 0: loss 0.02914351411163807, f1 0.229,  prec 0.521, rec 0.147
TRAINING - Epoch 18 Batch 10: loss 0.028697406873106956, f1 0.193,  prec 0.582, rec 0.116
TRAINING - Epoch 18 Batch 20: loss 0.03093160316348076, f1 0.042,  prec 0.429, rec 0.022
TRAINING - Epoch 18 Batch 30: loss 0.02735375612974167, f1 0.211,  prec 0.611, rec 0.127
TRAINING - Epoch 18 Batch 40: loss 0.030344823375344276, f1 0.091,  prec 0.591, rec 0.049
TRAINING - Epoch 18 Batch 50: loss 0.0272695142775774, f1 0.282,  prec 0.534, rec 0.192
VALIDATION - Epoch 18 Batch 0: loss 0.029494985938072205, f1 0.161, prec 0.722, rec 0.091
VALIDATION - Epoch 18 Batch 10: loss 0.027555564418435097, f1 0.211, prec 0.723, rec 0.123
VALIDATION - Epoch 18 Batch 20: loss 0.025277812033891678, f1 0.13, prec 0.567, rec 0.073
TRAINING - Epoch 19 Batch 0: loss 0.029568320140242577, f1 0.161,  prec 0.581, rec 0.094
TRAINING - Epoch 19 Batch 10: loss 0.029030999168753624, f1 0.12,  prec 0.529, rec 0.068
TRAINING - Epoch 19 Batch 20: loss 0.028226351365447044, f1 0.159,  prec 0.523, rec 0.093
TRAINING - Epoch 19 Batch 30: loss 0.030240774154663086, f1 0.21,  prec 0.644, rec 0.125
TRAINING - Epoch 19 Batch 40: loss 0.028495678678154945, f1 0.198,  prec 0.509, rec 0.123
TRAINING - Epoch 19 Batch 50: loss 0.025893038138747215, f1 0.164,  prec 0.622, rec 0.094
VALIDATION - Epoch 19 Batch 0: loss 0.028094973415136337, f1 0.109, prec 0.556, rec 0.06
VALIDATION - Epoch 19 Batch 10: loss 0.027784597128629684, f1 0.115, prec 0.567, rec 0.064
VALIDATION - Epoch 19 Batch 20: loss 0.028013890609145164, f1 0.116, prec 0.5, rec 0.065
TRAINING - Epoch 20 Batch 0: loss 0.025950279086828232, f1 0.136,  prec 0.6, rec 0.077
TRAINING - Epoch 20 Batch 10: loss 0.029741430655121803, f1 0.228,  prec 0.551, rec 0.144
TRAINING - Epoch 20 Batch 20: loss 0.02763151377439499, f1 0.212,  prec 0.6, rec 0.129
TRAINING - Epoch 20 Batch 30: loss 0.02784399688243866, f1 0.068,  prec 0.529, rec 0.036
TRAINING - Epoch 20 Batch 40: loss 0.026328127831220627, f1 0.157,  prec 0.447, rec 0.095
TRAINING - Epoch 20 Batch 50: loss 0.028539586812257767, f1 0.148,  prec 0.618, rec 0.084
VALIDATION - Epoch 20 Batch 0: loss 0.030181460082530975, f1 0.225, prec 0.556, rec 0.141
VALIDATION - Epoch 20 Batch 10: loss 0.029373856261372566, f1 0.234, prec 0.547, rec 0.149
VALIDATION - Epoch 20 Batch 20: loss 0.029078485444188118, f1 0.24, prec 0.473, rec 0.16
TRAINING - Epoch 21 Batch 0: loss 0.028090763837099075, f1 0.276,  prec 0.573, rec 0.182
TRAINING - Epoch 21 Batch 10: loss 0.028922593221068382, f1 0.044,  prec 0.667, rec 0.023
TRAINING - Epoch 21 Batch 20: loss 0.02850266918540001, f1 0.03,  prec 0.667, rec 0.015
TRAINING - Epoch 21 Batch 30: loss 0.029022308066487312, f1 0.25,  prec 0.444, rec 0.174
TRAINING - Epoch 21 Batch 40: loss 0.027496518567204475, f1 0.161,  prec 0.571, rec 0.094
TRAINING - Epoch 21 Batch 50: loss 0.026757318526506424, f1 0.131,  prec 0.531, rec 0.075
VALIDATION - Epoch 21 Batch 0: loss 0.02983933314681053, f1 0.286, prec 0.535, rec 0.196
VALIDATION - Epoch 21 Batch 10: loss 0.02733946405351162, f1 0.337, prec 0.552, rec 0.243
VALIDATION - Epoch 21 Batch 20: loss 0.03011281229555607, f1 0.255, prec 0.5, rec 0.171
TRAINING - Epoch 22 Batch 0: loss 0.028440440073609352, f1 0.289,  prec 0.467, rec 0.209
TRAINING - Epoch 22 Batch 10: loss 0.02658158913254738, f1 0.115,  prec 0.577, rec 0.064
TRAINING - Epoch 22 Batch 20: loss 0.02835356816649437, f1 0.207,  prec 0.582, rec 0.126
TRAINING - Epoch 22 Batch 30: loss 0.02705085650086403, f1 0.219,  prec 0.593, rec 0.134
TRAINING - Epoch 22 Batch 40: loss 0.027549341320991516, f1 0.239,  prec 0.679, rec 0.145
TRAINING - Epoch 22 Batch 50: loss 0.02731877937912941, f1 0.08,  prec 0.44, rec 0.044
VALIDATION - Epoch 22 Batch 0: loss 0.026897793635725975, f1 0.254, prec 0.462, rec 0.175
VALIDATION - Epoch 22 Batch 10: loss 0.02941085956990719, f1 0.286, prec 0.559, rec 0.192
VALIDATION - Epoch 22 Batch 20: loss 0.02919253706932068, f1 0.317, prec 0.54, rec 0.224
TRAINING - Epoch 23 Batch 0: loss 0.027709156274795532, f1 0.304,  prec 0.505, rec 0.217
TRAINING - Epoch 23 Batch 10: loss 0.025774139910936356, f1 0.233,  prec 0.618, rec 0.143
TRAINING - Epoch 23 Batch 20: loss 0.02859819307923317, f1 0.135,  prec 0.588, rec 0.076
TRAINING - Epoch 23 Batch 30: loss 0.02865041419863701, f1 0.044,  prec 0.667, rec 0.023
TRAINING - Epoch 23 Batch 40: loss 0.026804031804203987, f1 0.23,  prec 0.648, rec 0.14
TRAINING - Epoch 23 Batch 50: loss 0.026006527245044708, f1 0.22,  prec 0.635, rec 0.133
VALIDATION - Epoch 23 Batch 0: loss 0.0267801396548748, f1 0.21, prec 0.635, rec 0.125
VALIDATION - Epoch 23 Batch 10: loss 0.02940399944782257, f1 0.144, prec 0.548, rec 0.083
VALIDATION - Epoch 23 Batch 20: loss 0.026913005858659744, f1 0.176, prec 0.605, rec 0.103
TRAINING - Epoch 24 Batch 0: loss 0.028571031987667084, f1 0.142,  prec 0.525, rec 0.082
TRAINING - Epoch 24 Batch 10: loss 0.028293851763010025, f1 0.129,  prec 0.633, rec 0.072
TRAINING - Epoch 24 Batch 20: loss 0.026848983019590378, f1 0.025,  prec 0.273, rec 0.013
TRAINING - Epoch 24 Batch 30: loss 0.025689998641610146, f1 0.272,  prec 0.557, rec 0.18
TRAINING - Epoch 24 Batch 40: loss 0.0283423513174057, f1 0.182,  prec 0.644, rec 0.106
TRAINING - Epoch 24 Batch 50: loss 0.02900048717856407, f1 0.312,  prec 0.602, rec 0.211
VALIDATION - Epoch 24 Batch 0: loss 0.030463362112641335, f1 0.053, prec 0.889, rec 0.027
VALIDATION - Epoch 24 Batch 10: loss 0.028378892689943314, f1 0.057, prec 0.8, rec 0.03
VALIDATION - Epoch 24 Batch 20: loss 0.028159329667687416, f1 0.05, prec 0.583, rec 0.026
TRAINING - Epoch 25 Batch 0: loss 0.02804592251777649, f1 0.053,  prec 0.636, rec 0.028
TRAINING - Epoch 25 Batch 10: loss 0.02848861739039421, f1 0.253,  prec 0.549, rec 0.164
TRAINING - Epoch 25 Batch 20: loss 0.0249060969799757, f1 0.181,  prec 0.714, rec 0.104
TRAINING - Epoch 25 Batch 30: loss 0.026216235011816025, f1 0.135,  prec 0.655, rec 0.075
TRAINING - Epoch 25 Batch 40: loss 0.028712086379528046, f1 0.14,  prec 0.75, rec 0.077
TRAINING - Epoch 25 Batch 50: loss 0.029342278838157654, f1 0.093,  prec 0.538, rec 0.051
VALIDATION - Epoch 25 Batch 0: loss 0.028218448162078857, f1 0.212, prec 0.53, rec 0.133
VALIDATION - Epoch 25 Batch 10: loss 0.02845403179526329, f1 0.21, prec 0.569, rec 0.128
VALIDATION - Epoch 25 Batch 20: loss 0.02809341438114643, f1 0.238, prec 0.714, rec 0.143
TRAINING - Epoch 26 Batch 0: loss 0.02672138437628746, f1 0.19,  prec 0.538, rec 0.115
TRAINING - Epoch 26 Batch 10: loss 0.027800297364592552, f1 0.037,  prec 0.5, rec 0.019
TRAINING - Epoch 26 Batch 20: loss 0.029055941849946976, f1 0.122,  prec 0.576, rec 0.068
TRAINING - Epoch 26 Batch 30: loss 0.02786984294652939, f1 0.223,  prec 0.545, rec 0.14
TRAINING - Epoch 26 Batch 40: loss 0.02868247777223587, f1 0.215,  prec 0.486, rec 0.138
TRAINING - Epoch 26 Batch 50: loss 0.02856789529323578, f1 0.102,  prec 0.517, rec 0.057
VALIDATION - Epoch 26 Batch 0: loss 0.02781505323946476, f1 0.194, prec 0.64, rec 0.114
VALIDATION - Epoch 26 Batch 10: loss 0.02972630225121975, f1 0.174, prec 0.56, rec 0.103
VALIDATION - Epoch 26 Batch 20: loss 0.027897270396351814, f1 0.18, prec 0.636, rec 0.105
TRAINING - Epoch 27 Batch 0: loss 0.030551651492714882, f1 0.194,  prec 0.579, rec 0.117
TRAINING - Epoch 27 Batch 10: loss 0.030102577060461044, f1 0.239,  prec 0.482, rec 0.159
TRAINING - Epoch 27 Batch 20: loss 0.028142761439085007, f1 0.196,  prec 0.571, rec 0.119
TRAINING - Epoch 27 Batch 30: loss 0.028877660632133484, f1 0.17,  prec 0.634, rec 0.098
TRAINING - Epoch 27 Batch 40: loss 0.02833445370197296, f1 0.192,  prec 0.612, rec 0.114
TRAINING - Epoch 27 Batch 50: loss 0.027866709977388382, f1 0.259,  prec 0.703, rec 0.158
VALIDATION - Epoch 27 Batch 0: loss 0.025898845866322517, f1 0.151, prec 0.688, rec 0.085
VALIDATION - Epoch 27 Batch 10: loss 0.027098823338747025, f1 0.111, prec 0.517, rec 0.062
VALIDATION - Epoch 27 Batch 20: loss 0.02828204818069935, f1 0.13, prec 0.594, rec 0.073
TRAINING - Epoch 28 Batch 0: loss 0.029061809182167053, f1 0.164,  prec 0.667, rec 0.094
TRAINING - Epoch 28 Batch 10: loss 0.02775668539106846, f1 0.193,  prec 0.6, rec 0.115
TRAINING - Epoch 28 Batch 20: loss 0.027798568829894066, f1 0.107,  prec 0.652, rec 0.058
TRAINING - Epoch 28 Batch 30: loss 0.02766312099993229, f1 0.218,  prec 0.493, rec 0.14
TRAINING - Epoch 28 Batch 40: loss 0.02924015000462532, f1 0.066,  prec 0.562, rec 0.035
TRAINING - Epoch 28 Batch 50: loss 0.02799193188548088, f1 0.27,  prec 0.548, rec 0.179
VALIDATION - Epoch 28 Batch 0: loss 0.027326200157403946, f1 0.323, prec 0.649, rec 0.215
VALIDATION - Epoch 28 Batch 10: loss 0.025793788954615593, f1 0.339, prec 0.622, rec 0.233
VALIDATION - Epoch 28 Batch 20: loss 0.027923304587602615, f1 0.26, prec 0.458, rec 0.181
TRAINING - Epoch 29 Batch 0: loss 0.028410043567419052, f1 0.264,  prec 0.484, rec 0.181
TRAINING - Epoch 29 Batch 10: loss 0.025787435472011566, f1 0.156,  prec 0.535, rec 0.091
TRAINING - Epoch 29 Batch 20: loss 0.025209570303559303, f1 0.093,  prec 0.545, rec 0.051
TRAINING - Epoch 29 Batch 30: loss 0.025680404156446457, f1 0.212,  prec 0.674, rec 0.126
TRAINING - Epoch 29 Batch 40: loss 0.028742477297782898, f1 0.174,  prec 0.7, rec 0.1
TRAINING - Epoch 29 Batch 50: loss 0.027490021660923958, f1 0.245,  prec 0.5, rec 0.163
VALIDATION - Epoch 29 Batch 0: loss 0.026435742154717445, f1 0.207, prec 0.537, rec 0.128
VALIDATION - Epoch 29 Batch 10: loss 0.028830384835600853, f1 0.214, prec 0.648, rec 0.128
VALIDATION - Epoch 29 Batch 20: loss 0.028987476602196693, f1 0.241, prec 0.597, rec 0.151
TRAINING - Epoch 30 Batch 0: loss 0.027742482721805573, f1 0.215,  prec 0.515, rec 0.135
TRAINING - Epoch 30 Batch 10: loss 0.02786616049706936, f1 0.234,  prec 0.458, rec 0.157
TRAINING - Epoch 30 Batch 20: loss 0.027450034394860268, f1 0.168,  prec 0.565, rec 0.098
TRAINING - Epoch 30 Batch 30: loss 0.026425307616591454, f1 0.209,  prec 0.696, rec 0.123
TRAINING - Epoch 30 Batch 40: loss 0.025392157956957817, f1 0.144,  prec 0.741, rec 0.08
TRAINING - Epoch 30 Batch 50: loss 0.02757461741566658, f1 0.25,  prec 0.539, rec 0.163
VALIDATION - Epoch 30 Batch 0: loss 0.026463991031050682, f1 0.148, prec 0.579, rec 0.085
VALIDATION - Epoch 30 Batch 10: loss 0.027805231511592865, f1 0.218, prec 0.655, rec 0.131
VALIDATION - Epoch 30 Batch 20: loss 0.028134316205978394, f1 0.116, prec 0.567, rec 0.065
TRAINING - Epoch 31 Batch 0: loss 0.025936629623174667, f1 0.17,  prec 0.706, rec 0.097
TRAINING - Epoch 31 Batch 10: loss 0.02855694480240345, f1 0.177,  prec 0.651, rec 0.103
TRAINING - Epoch 31 Batch 20: loss 0.025752848014235497, f1 0.132,  prec 0.562, rec 0.075
TRAINING - Epoch 31 Batch 30: loss 0.024533158168196678, f1 0.168,  prec 0.611, rec 0.097
TRAINING - Epoch 31 Batch 40: loss 0.02714705467224121, f1 0.251,  prec 0.627, rec 0.157
TRAINING - Epoch 31 Batch 50: loss 0.02660747803747654, f1 0.17,  prec 0.531, rec 0.101
VALIDATION - Epoch 31 Batch 0: loss 0.029916977509856224, f1 0.102, prec 0.6, rec 0.056
VALIDATION - Epoch 31 Batch 10: loss 0.026167413219809532, f1 0.103, prec 0.7, rec 0.056
VALIDATION - Epoch 31 Batch 20: loss 0.028902476653456688, f1 0.082, prec 0.706, rec 0.043
TRAINING - Epoch 32 Batch 0: loss 0.025988180190324783, f1 0.083,  prec 0.647, rec 0.044
TRAINING - Epoch 32 Batch 10: loss 0.02492188662290573, f1 0.177,  prec 0.641, rec 0.102
TRAINING - Epoch 32 Batch 20: loss 0.02542812190949917, f1 0.221,  prec 0.738, rec 0.13
TRAINING - Epoch 32 Batch 30: loss 0.026182683184742928, f1 0.252,  prec 0.548, rec 0.164
TRAINING - Epoch 32 Batch 40: loss 0.025410529226064682, f1 0.212,  prec 0.674, rec 0.126
TRAINING - Epoch 32 Batch 50: loss 0.02740621753036976, f1 0.16,  prec 0.46, rec 0.097
VALIDATION - Epoch 32 Batch 0: loss 0.028846900910139084, f1 0.057, prec 0.421, rec 0.03
VALIDATION - Epoch 32 Batch 10: loss 0.031074881553649902, f1 0.125, prec 0.677, rec 0.069
VALIDATION - Epoch 32 Batch 20: loss 0.030066724866628647, f1 0.148, prec 0.649, rec 0.084
TRAINING - Epoch 33 Batch 0: loss 0.024137822911143303, f1 0.192,  prec 0.543, rec 0.117
TRAINING - Epoch 33 Batch 10: loss 0.026613440364599228, f1 0.206,  prec 0.593, rec 0.125
TRAINING - Epoch 33 Batch 20: loss 0.027795251458883286, f1 0.273,  prec 0.6, rec 0.176
TRAINING - Epoch 33 Batch 30: loss 0.028164062649011612, f1 0.118,  prec 0.739, rec 0.064
TRAINING - Epoch 33 Batch 40: loss 0.02721095085144043, f1 0.315,  prec 0.514, rec 0.227
TRAINING - Epoch 33 Batch 50: loss 0.027705708518624306, f1 0.127,  prec 0.643, rec 0.071
VALIDATION - Epoch 33 Batch 0: loss 0.02482643537223339, f1 0.131, prec 0.548, rec 0.074
VALIDATION - Epoch 33 Batch 10: loss 0.029466604813933372, f1 0.148, prec 0.727, rec 0.082
VALIDATION - Epoch 33 Batch 20: loss 0.027708452194929123, f1 0.18, prec 0.771, rec 0.102
TRAINING - Epoch 34 Batch 0: loss 0.028608413413167, f1 0.166,  prec 0.75, rec 0.093
TRAINING - Epoch 34 Batch 10: loss 0.029186829924583435, f1 0.265,  prec 0.578, rec 0.172
TRAINING - Epoch 34 Batch 20: loss 0.026245038956403732, f1 0.2,  prec 0.492, rec 0.126
TRAINING - Epoch 34 Batch 30: loss 0.026586534455418587, f1 0.152,  prec 0.537, rec 0.089
TRAINING - Epoch 34 Batch 40: loss 0.025396516546607018, f1 0.272,  prec 0.634, rec 0.173
TRAINING - Epoch 34 Batch 50: loss 0.02403218112885952, f1 0.203,  prec 0.519, rec 0.126
VALIDATION - Epoch 34 Batch 0: loss 0.028747573494911194, f1 0.185, prec 0.714, rec 0.106
VALIDATION - Epoch 34 Batch 10: loss 0.025733018293976784, f1 0.21, prec 0.675, rec 0.124
VALIDATION - Epoch 34 Batch 20: loss 0.02777046151459217, f1 0.19, prec 0.69, rec 0.11
TRAINING - Epoch 35 Batch 0: loss 0.025293763726949692, f1 0.171,  prec 0.564, rec 0.101
TRAINING - Epoch 35 Batch 10: loss 0.02706066705286503, f1 0.248,  prec 0.614, rec 0.155
TRAINING - Epoch 35 Batch 20: loss 0.025401754304766655, f1 0.177,  prec 0.686, rec 0.102
TRAINING - Epoch 35 Batch 30: loss 0.02854089066386223, f1 0.185,  prec 0.545, rec 0.112
TRAINING - Epoch 35 Batch 40: loss 0.028183018788695335, f1 0.212,  prec 0.614, rec 0.128
TRAINING - Epoch 35 Batch 50: loss 0.028297295793890953, f1 0.161,  prec 0.65, rec 0.092
VALIDATION - Epoch 35 Batch 0: loss 0.02605145424604416, f1 0.125, prec 0.75, rec 0.068
VALIDATION - Epoch 35 Batch 10: loss 0.02651231735944748, f1 0.103, prec 0.619, rec 0.056
VALIDATION - Epoch 35 Batch 20: loss 0.02613767609000206, f1 0.132, prec 0.586, rec 0.075
TRAINING - Epoch 36 Batch 0: loss 0.02865677699446678, f1 0.146,  prec 0.647, rec 0.082
TRAINING - Epoch 36 Batch 10: loss 0.026981517672538757, f1 0.329,  prec 0.541, rec 0.236
TRAINING - Epoch 36 Batch 20: loss 0.028570720925927162, f1 0.146,  prec 0.676, rec 0.082
TRAINING - Epoch 36 Batch 30: loss 0.02678113803267479, f1 0.305,  prec 0.609, rec 0.204
TRAINING - Epoch 36 Batch 40: loss 0.026720043271780014, f1 0.243,  prec 0.684, rec 0.148
TRAINING - Epoch 36 Batch 50: loss 0.025943931192159653, f1 0.191,  prec 0.644, rec 0.112
VALIDATION - Epoch 36 Batch 0: loss 0.02762702666223049, f1 0.174, prec 0.667, rec 0.1
VALIDATION - Epoch 36 Batch 10: loss 0.027039214968681335, f1 0.235, prec 0.583, rec 0.147
VALIDATION - Epoch 36 Batch 20: loss 0.027739569544792175, f1 0.193, prec 0.612, rec 0.115
TRAINING - Epoch 37 Batch 0: loss 0.028217695653438568, f1 0.177,  prec 0.54, rec 0.106
TRAINING - Epoch 37 Batch 10: loss 0.027389463037252426, f1 0.257,  prec 0.714, rec 0.157
TRAINING - Epoch 37 Batch 20: loss 0.0297295693308115, f1 0.238,  prec 0.506, rec 0.155
TRAINING - Epoch 37 Batch 30: loss 0.02740347571671009, f1 0.193,  prec 0.588, rec 0.115
TRAINING - Epoch 37 Batch 40: loss 0.025300180539488792, f1 0.209,  prec 0.627, rec 0.125
TRAINING - Epoch 37 Batch 50: loss 0.029962923377752304, f1 0.104,  prec 0.63, rec 0.056
VALIDATION - Epoch 37 Batch 0: loss 0.028153186663985252, f1 0.144, prec 0.92, rec 0.078
VALIDATION - Epoch 37 Batch 10: loss 0.02701534703373909, f1 0.162, prec 0.615, rec 0.093
VALIDATION - Epoch 37 Batch 20: loss 0.026028016582131386, f1 0.179, prec 0.667, rec 0.103
TRAINING - Epoch 38 Batch 0: loss 0.02832256630063057, f1 0.18,  prec 0.58, rec 0.107
TRAINING - Epoch 38 Batch 10: loss 0.02914450317621231, f1 0.015,  prec 0.4, rec 0.008
TRAINING - Epoch 38 Batch 20: loss 0.02482067421078682, f1 0.185,  prec 0.595, rec 0.109
TRAINING - Epoch 38 Batch 30: loss 0.025099189952015877, f1 0.27,  prec 0.609, rec 0.173
TRAINING - Epoch 38 Batch 40: loss 0.025570940226316452, f1 0.205,  prec 0.732, rec 0.119
TRAINING - Epoch 38 Batch 50: loss 0.027051802724599838, f1 0.258,  prec 0.656, rec 0.16
VALIDATION - Epoch 38 Batch 0: loss 0.027247682213783264, f1 0.066, prec 0.75, rec 0.035
VALIDATION - Epoch 38 Batch 10: loss 0.026959579437971115, f1 0.032, prec 0.5, rec 0.016
VALIDATION - Epoch 38 Batch 20: loss 0.030515097081661224, f1 0.014, prec 0.5, rec 0.007
TRAINING - Epoch 39 Batch 0: loss 0.026791710406541824, f1 0.094,  prec 0.929, rec 0.05
TRAINING - Epoch 39 Batch 10: loss 0.02580038271844387, f1 0.173,  prec 0.619, rec 0.101
TRAINING - Epoch 39 Batch 20: loss 0.02516443096101284, f1 0.248,  prec 0.593, rec 0.157
TRAINING - Epoch 39 Batch 30: loss 0.028536200523376465, f1 0.22,  prec 0.745, rec 0.129
TRAINING - Epoch 39 Batch 40: loss 0.026099810376763344, f1 0.199,  prec 0.625, rec 0.119
TRAINING - Epoch 39 Batch 50: loss 0.027947982773184776, f1 0.148,  prec 0.629, rec 0.084
VALIDATION - Epoch 39 Batch 0: loss 0.0304863378405571, f1 0.191, prec 0.729, rec 0.11
VALIDATION - Epoch 39 Batch 10: loss 0.028222935274243355, f1 0.174, prec 0.659, rec 0.1
VALIDATION - Epoch 39 Batch 20: loss 0.02605384774506092, f1 0.157, prec 0.636, rec 0.089
TRAINING - Epoch 40 Batch 0: loss 0.02773299440741539, f1 0.202,  prec 0.667, rec 0.119
TRAINING - Epoch 40 Batch 10: loss 0.028497066348791122, f1 0.249,  prec 0.667, rec 0.153
TRAINING - Epoch 40 Batch 20: loss 0.026226969435811043, f1 0.269,  prec 0.484, rec 0.186
TRAINING - Epoch 40 Batch 30: loss 0.030217669904232025, f1 0.125,  prec 0.426, rec 0.074
TRAINING - Epoch 40 Batch 40: loss 0.025514671579003334, f1 0.241,  prec 0.551, rec 0.154
TRAINING - Epoch 40 Batch 50: loss 0.02499922178685665, f1 0.162,  prec 0.677, rec 0.092
VALIDATION - Epoch 40 Batch 0: loss 0.02873912826180458, f1 0.141, prec 0.579, rec 0.081
VALIDATION - Epoch 40 Batch 10: loss 0.027480075135827065, f1 0.147, prec 0.611, rec 0.083
VALIDATION - Epoch 40 Batch 20: loss 0.028661206364631653, f1 0.152, prec 0.686, rec 0.086
TRAINING - Epoch 41 Batch 0: loss 0.027919478714466095, f1 0.141,  prec 0.618, rec 0.08
TRAINING - Epoch 41 Batch 10: loss 0.02611130103468895, f1 0.163,  prec 0.543, rec 0.096
TRAINING - Epoch 41 Batch 20: loss 0.026902243494987488, f1 0.257,  prec 0.533, rec 0.169
TRAINING - Epoch 41 Batch 30: loss 0.0281890407204628, f1 0.231,  prec 0.615, rec 0.142
TRAINING - Epoch 41 Batch 40: loss 0.028251180425286293, f1 0.172,  prec 0.556, rec 0.102
TRAINING - Epoch 41 Batch 50: loss 0.029477201402187347, f1 0.216,  prec 0.551, rec 0.134
VALIDATION - Epoch 41 Batch 0: loss 0.024589937180280685, f1 0.23, prec 0.517, rec 0.148
VALIDATION - Epoch 41 Batch 10: loss 0.0258584413677454, f1 0.204, prec 0.5, rec 0.128
VALIDATION - Epoch 41 Batch 20: loss 0.026970362290740013, f1 0.241, prec 0.629, rec 0.149
TRAINING - Epoch 42 Batch 0: loss 0.02459905855357647, f1 0.262,  prec 0.6, rec 0.167
TRAINING - Epoch 42 Batch 10: loss 0.02690618857741356, f1 0.232,  prec 0.493, rec 0.152
TRAINING - Epoch 42 Batch 20: loss 0.026698144152760506, f1 0.211,  prec 0.68, rec 0.125
TRAINING - Epoch 42 Batch 30: loss 0.025614658370614052, f1 0.217,  prec 0.64, rec 0.131
TRAINING - Epoch 42 Batch 40: loss 0.02504255808889866, f1 0.243,  prec 0.578, rec 0.154
TRAINING - Epoch 42 Batch 50: loss 0.026715150102972984, f1 0.154,  prec 0.75, rec 0.086
VALIDATION - Epoch 42 Batch 0: loss 0.02692318893969059, f1 0.284, prec 0.636, rec 0.183
VALIDATION - Epoch 42 Batch 10: loss 0.02766341157257557, f1 0.272, prec 0.645, rec 0.173
VALIDATION - Epoch 42 Batch 20: loss 0.02587784081697464, f1 0.306, prec 0.631, rec 0.202
TRAINING - Epoch 43 Batch 0: loss 0.026215363293886185, f1 0.32,  prec 0.59, rec 0.219
TRAINING - Epoch 43 Batch 10: loss 0.025833262130618095, f1 0.222,  prec 0.667, rec 0.133
TRAINING - Epoch 43 Batch 20: loss 0.028644200414419174, f1 0.123,  prec 0.633, rec 0.068
TRAINING - Epoch 43 Batch 30: loss 0.026507612317800522, f1 0.129,  prec 0.486, rec 0.074
TRAINING - Epoch 43 Batch 40: loss 0.025981130078434944, f1 0.305,  prec 0.455, rec 0.23
TRAINING - Epoch 43 Batch 50: loss 0.027827681973576546, f1 0.163,  prec 0.714, rec 0.092
VALIDATION - Epoch 43 Batch 0: loss 0.02694346010684967, f1 0.233, prec 0.535, rec 0.149
VALIDATION - Epoch 43 Batch 10: loss 0.026183193549513817, f1 0.281, prec 0.623, rec 0.181
VALIDATION - Epoch 43 Batch 20: loss 0.02511904202401638, f1 0.298, prec 0.548, rec 0.205
TRAINING - Epoch 44 Batch 0: loss 0.02726876735687256, f1 0.323,  prec 0.622, rec 0.218
TRAINING - Epoch 44 Batch 10: loss 0.025682812556624413, f1 0.263,  prec 0.538, rec 0.174
TRAINING - Epoch 44 Batch 20: loss 0.025325341150164604, f1 0.224,  prec 0.667, rec 0.134
TRAINING - Epoch 44 Batch 30: loss 0.02618398889899254, f1 0.29,  prec 0.731, rec 0.181
TRAINING - Epoch 44 Batch 40: loss 0.02518514357507229, f1 0.141,  prec 0.818, rec 0.077
TRAINING - Epoch 44 Batch 50: loss 0.02656601555645466, f1 0.237,  prec 0.587, rec 0.149
VALIDATION - Epoch 44 Batch 0: loss 0.029632454738020897, f1 0.096, prec 0.714, rec 0.051
VALIDATION - Epoch 44 Batch 10: loss 0.025965265929698944, f1 0.128, prec 0.75, rec 0.07
VALIDATION - Epoch 44 Batch 20: loss 0.024387525394558907, f1 0.121, prec 0.682, rec 0.067
TRAINING - Epoch 45 Batch 0: loss 0.027577392756938934, f1 0.14,  prec 0.645, rec 0.078
TRAINING - Epoch 45 Batch 10: loss 0.026040997356176376, f1 0.273,  prec 0.671, rec 0.172
TRAINING - Epoch 45 Batch 20: loss 0.029592979699373245, f1 0.295,  prec 0.611, rec 0.194
TRAINING - Epoch 45 Batch 30: loss 0.026632798835635185, f1 0.207,  prec 0.689, rec 0.122
TRAINING - Epoch 45 Batch 40: loss 0.02786354348063469, f1 0.131,  prec 0.645, rec 0.073
TRAINING - Epoch 45 Batch 50: loss 0.025595707818865776, f1 0.238,  prec 0.607, rec 0.148
VALIDATION - Epoch 45 Batch 0: loss 0.030289851129055023, f1 0.201, prec 0.642, rec 0.119
VALIDATION - Epoch 45 Batch 10: loss 0.0262118112295866, f1 0.209, prec 0.627, rec 0.125
VALIDATION - Epoch 45 Batch 20: loss 0.026526035740971565, f1 0.206, prec 0.711, rec 0.121
TRAINING - Epoch 46 Batch 0: loss 0.02744332328438759, f1 0.185,  prec 0.536, rec 0.112
TRAINING - Epoch 46 Batch 10: loss 0.027416273951530457, f1 0.231,  prec 0.512, rec 0.149
TRAINING - Epoch 46 Batch 20: loss 0.027454381808638573, f1 0.204,  prec 0.78, rec 0.117
TRAINING - Epoch 46 Batch 30: loss 0.028044961392879486, f1 0.265,  prec 0.662, rec 0.165
TRAINING - Epoch 46 Batch 40: loss 0.026733243837952614, f1 0.19,  prec 0.58, rec 0.114
TRAINING - Epoch 46 Batch 50: loss 0.02981555461883545, f1 0.059,  prec 0.75, rec 0.031
VALIDATION - Epoch 46 Batch 0: loss 0.02673833817243576, f1 0.178, prec 0.8, rec 0.1
VALIDATION - Epoch 46 Batch 10: loss 0.031637098640203476, f1 0.145, prec 0.788, rec 0.08
VALIDATION - Epoch 46 Batch 20: loss 0.025768814608454704, f1 0.173, prec 0.622, rec 0.1
TRAINING - Epoch 47 Batch 0: loss 0.025641407817602158, f1 0.169,  prec 0.676, rec 0.097
TRAINING - Epoch 47 Batch 10: loss 0.028493588790297508, f1 0.257,  prec 0.647, rec 0.161
TRAINING - Epoch 47 Batch 20: loss 0.028958911076188087, f1 0.218,  prec 0.488, rec 0.14
TRAINING - Epoch 47 Batch 30: loss 0.026663610711693764, f1 0.236,  prec 0.625, rec 0.145
TRAINING - Epoch 47 Batch 40: loss 0.027033578604459763, f1 0.366,  prec 0.514, rec 0.284
TRAINING - Epoch 47 Batch 50: loss 0.02821759134531021, f1 0.229,  prec 0.627, rec 0.14
VALIDATION - Epoch 47 Batch 0: loss 0.02923506498336792, f1 0.127, prec 0.864, rec 0.069
VALIDATION - Epoch 47 Batch 10: loss 0.02607249841094017, f1 0.097, prec 0.684, rec 0.052
VALIDATION - Epoch 47 Batch 20: loss 0.025044161826372147, f1 0.109, prec 0.737, rec 0.059
TRAINING - Epoch 48 Batch 0: loss 0.02243177965283394, f1 0.115,  prec 0.765, rec 0.062
TRAINING - Epoch 48 Batch 10: loss 0.02545442059636116, f1 0.264,  prec 0.714, rec 0.162
TRAINING - Epoch 48 Batch 20: loss 0.02703789807856083, f1 0.15,  prec 0.583, rec 0.086
TRAINING - Epoch 48 Batch 30: loss 0.027128655463457108, f1 0.131,  prec 0.452, rec 0.077
TRAINING - Epoch 48 Batch 40: loss 0.02644587866961956, f1 0.235,  prec 0.632, rec 0.144
TRAINING - Epoch 48 Batch 50: loss 0.02922068163752556, f1 0.245,  prec 0.548, rec 0.158
VALIDATION - Epoch 48 Batch 0: loss 0.02748855948448181, f1 0.161, prec 0.758, rec 0.09
VALIDATION - Epoch 48 Batch 10: loss 0.02574223466217518, f1 0.125, prec 0.727, rec 0.069
VALIDATION - Epoch 48 Batch 20: loss 0.02787243016064167, f1 0.173, prec 0.781, rec 0.097
TRAINING - Epoch 49 Batch 0: loss 0.026765797287225723, f1 0.144,  prec 0.778, rec 0.08
TRAINING - Epoch 49 Batch 10: loss 0.027391590178012848, f1 0.374,  prec 0.518, rec 0.292
TRAINING - Epoch 49 Batch 20: loss 0.025231460109353065, f1 0.188,  prec 0.628, rec 0.111
TRAINING - Epoch 49 Batch 30: loss 0.02542824111878872, f1 0.328,  prec 0.559, rec 0.232
TRAINING - Epoch 49 Batch 40: loss 0.027024930343031883, f1 0.206,  prec 0.681, rec 0.121
TRAINING - Epoch 49 Batch 50: loss 0.027170401066541672, f1 0.289,  prec 0.649, rec 0.186
VALIDATION - Epoch 49 Batch 0: loss 0.02813808061182499, f1 0.141, prec 0.553, rec 0.081
VALIDATION - Epoch 49 Batch 10: loss 0.029438616707921028, f1 0.206, prec 0.706, rec 0.121
VALIDATION - Epoch 49 Batch 20: loss 0.02715536393225193, f1 0.162, prec 0.857, rec 0.09
TRAINING - Epoch 50 Batch 0: loss 0.02630034275352955, f1 0.173,  prec 0.574, rec 0.102
TRAINING - Epoch 50 Batch 10: loss 0.024288801476359367, f1 0.268,  prec 0.635, rec 0.169
TRAINING - Epoch 50 Batch 20: loss 0.02657889761030674, f1 0.303,  prec 0.63, rec 0.199
TRAINING - Epoch 50 Batch 30: loss 0.026031427085399628, f1 0.269,  prec 0.582, rec 0.175
TRAINING - Epoch 50 Batch 40: loss 0.02704307809472084, f1 0.359,  prec 0.637, rec 0.25
TRAINING - Epoch 50 Batch 50: loss 0.026245074346661568, f1 0.275,  prec 0.652, rec 0.174
VALIDATION - Epoch 50 Batch 0: loss 0.027720261365175247, f1 0.262, prec 0.7, rec 0.162
VALIDATION - Epoch 50 Batch 10: loss 0.02507084794342518, f1 0.298, prec 0.59, rec 0.199
VALIDATION - Epoch 50 Batch 20: loss 0.026258083060383797, f1 0.241, prec 0.557, rec 0.154
TRAINING - Epoch 51 Batch 0: loss 0.027456184849143028, f1 0.338,  prec 0.656, rec 0.227
TRAINING - Epoch 51 Batch 10: loss 0.025128057226538658, f1 0.188,  prec 0.765, rec 0.107
TRAINING - Epoch 51 Batch 20: loss 0.025718804448843002, f1 0.288,  prec 0.649, rec 0.185
TRAINING - Epoch 51 Batch 30: loss 0.02884761616587639, f1 0.192,  prec 0.821, rec 0.109
TRAINING - Epoch 51 Batch 40: loss 0.02662639692425728, f1 0.288,  prec 0.671, rec 0.184
TRAINING - Epoch 51 Batch 50: loss 0.026669014245271683, f1 0.295,  prec 0.505, rec 0.208
VALIDATION - Epoch 51 Batch 0: loss 0.02620593272149563, f1 0.239, prec 0.74, rec 0.142
VALIDATION - Epoch 51 Batch 10: loss 0.024706395342946053, f1 0.197, prec 0.509, rec 0.122
VALIDATION - Epoch 51 Batch 20: loss 0.027663812041282654, f1 0.214, prec 0.692, rec 0.127
TRAINING - Epoch 52 Batch 0: loss 0.025492018088698387, f1 0.271,  prec 0.553, rec 0.179
TRAINING - Epoch 52 Batch 10: loss 0.027121582999825478, f1 0.145,  prec 0.769, rec 0.08
TRAINING - Epoch 52 Batch 20: loss 0.025982584804296494, f1 0.426,  prec 0.563, rec 0.342
TRAINING - Epoch 52 Batch 30: loss 0.023761488497257233, f1 0.241,  prec 0.854, rec 0.14
TRAINING - Epoch 52 Batch 40: loss 0.02424181066453457, f1 0.33,  prec 0.667, rec 0.22
TRAINING - Epoch 52 Batch 50: loss 0.027381572872400284, f1 0.178,  prec 0.703, rec 0.102
VALIDATION - Epoch 52 Batch 0: loss 0.025934644043445587, f1 0.304, prec 0.684, rec 0.195
VALIDATION - Epoch 52 Batch 10: loss 0.02459450624883175, f1 0.327, prec 0.646, rec 0.219
VALIDATION - Epoch 52 Batch 20: loss 0.0249317716807127, f1 0.298, prec 0.593, rec 0.199
TRAINING - Epoch 53 Batch 0: loss 0.023656094446778297, f1 0.363,  prec 0.67, rec 0.249
TRAINING - Epoch 53 Batch 10: loss 0.02478962019085884, f1 0.308,  prec 0.575, rec 0.21
TRAINING - Epoch 53 Batch 20: loss 0.026029370725154877, f1 0.276,  prec 0.742, rec 0.17
TRAINING - Epoch 53 Batch 30: loss 0.028078090399503708, f1 0.18,  prec 0.674, rec 0.104
TRAINING - Epoch 53 Batch 40: loss 0.025283057242631912, f1 0.221,  prec 0.767, rec 0.129
TRAINING - Epoch 53 Batch 50: loss 0.02656983584165573, f1 0.212,  prec 0.705, rec 0.124
VALIDATION - Epoch 53 Batch 0: loss 0.024665702134370804, f1 0.187, prec 0.694, rec 0.108
VALIDATION - Epoch 53 Batch 10: loss 0.029025185853242874, f1 0.11, prec 0.8, rec 0.059
VALIDATION - Epoch 53 Batch 20: loss 0.02771802432835102, f1 0.158, prec 0.658, rec 0.09
TRAINING - Epoch 54 Batch 0: loss 0.02680126205086708, f1 0.172,  prec 0.65, rec 0.099
TRAINING - Epoch 54 Batch 10: loss 0.029268013313412666, f1 0.264,  prec 0.565, rec 0.172
TRAINING - Epoch 54 Batch 20: loss 0.025425998494029045, f1 0.326,  prec 0.675, rec 0.215
TRAINING - Epoch 54 Batch 30: loss 0.026525769382715225, f1 0.16,  prec 0.657, rec 0.091
TRAINING - Epoch 54 Batch 40: loss 0.025424791499972343, f1 0.289,  prec 0.804, rec 0.176
TRAINING - Epoch 54 Batch 50: loss 0.027290621772408485, f1 0.172,  prec 0.591, rec 0.101
VALIDATION - Epoch 54 Batch 0: loss 0.027444401755928993, f1 0.182, prec 0.871, rec 0.102
VALIDATION - Epoch 54 Batch 10: loss 0.026697363704442978, f1 0.166, prec 0.821, rec 0.092
VALIDATION - Epoch 54 Batch 20: loss 0.026217155158519745, f1 0.166, prec 0.75, rec 0.093
TRAINING - Epoch 55 Batch 0: loss 0.024520479142665863, f1 0.167,  prec 0.71, rec 0.095
TRAINING - Epoch 55 Batch 10: loss 0.02674231491982937, f1 0.305,  prec 0.679, rec 0.196
TRAINING - Epoch 55 Batch 20: loss 0.026340771466493607, f1 0.371,  prec 0.663, rec 0.257
TRAINING - Epoch 55 Batch 30: loss 0.026547152549028397, f1 0.128,  prec 0.643, rec 0.071
TRAINING - Epoch 55 Batch 40: loss 0.029714934527873993, f1 0.137,  prec 0.679, rec 0.076
TRAINING - Epoch 55 Batch 50: loss 0.02502010576426983, f1 0.412,  prec 0.518, rec 0.341
VALIDATION - Epoch 55 Batch 0: loss 0.0263349786400795, f1 0.273, prec 0.575, rec 0.179
VALIDATION - Epoch 55 Batch 10: loss 0.025099212303757668, f1 0.329, prec 0.565, rec 0.232
VALIDATION - Epoch 55 Batch 20: loss 0.027879804372787476, f1 0.343, prec 0.629, rec 0.236
TRAINING - Epoch 56 Batch 0: loss 0.025182779878377914, f1 0.35,  prec 0.578, rec 0.251
TRAINING - Epoch 56 Batch 10: loss 0.023222889751195908, f1 0.315,  prec 0.646, rec 0.208
TRAINING - Epoch 56 Batch 20: loss 0.026032913476228714, f1 0.223,  prec 0.711, rec 0.132
TRAINING - Epoch 56 Batch 30: loss 0.027831977233290672, f1 0.202,  prec 0.723, rec 0.117
TRAINING - Epoch 56 Batch 40: loss 0.02487780712544918, f1 0.29,  prec 0.652, rec 0.187
TRAINING - Epoch 56 Batch 50: loss 0.02789737470448017, f1 0.355,  prec 0.772, rec 0.231
VALIDATION - Epoch 56 Batch 0: loss 0.02400074526667595, f1 0.261, prec 0.784, rec 0.157
VALIDATION - Epoch 56 Batch 10: loss 0.02543073520064354, f1 0.188, prec 0.684, rec 0.109
VALIDATION - Epoch 56 Batch 20: loss 0.025148488581180573, f1 0.173, prec 0.727, rec 0.098
TRAINING - Epoch 57 Batch 0: loss 0.0262667965143919, f1 0.19,  prec 0.707, rec 0.11
TRAINING - Epoch 57 Batch 10: loss 0.026990946382284164, f1 0.365,  prec 0.579, rec 0.266
TRAINING - Epoch 57 Batch 20: loss 0.023137357085943222, f1 0.275,  prec 0.636, rec 0.175
TRAINING - Epoch 57 Batch 30: loss 0.025186117738485336, f1 0.335,  prec 0.596, rec 0.233
TRAINING - Epoch 57 Batch 40: loss 0.027914609760046005, f1 0.255,  prec 0.573, rec 0.164
TRAINING - Epoch 57 Batch 50: loss 0.02791929803788662, f1 0.122,  prec 0.708, rec 0.067
VALIDATION - Epoch 57 Batch 0: loss 0.027240073308348656, f1 0.235, prec 0.929, rec 0.134
VALIDATION - Epoch 57 Batch 10: loss 0.025591647252440453, f1 0.158, prec 0.7, rec 0.089
VALIDATION - Epoch 57 Batch 20: loss 0.025126539170742035, f1 0.157, prec 0.656, rec 0.089
TRAINING - Epoch 58 Batch 0: loss 0.02521965093910694, f1 0.213,  prec 0.816, rec 0.123
TRAINING - Epoch 58 Batch 10: loss 0.02994408831000328, f1 0.226,  prec 0.7, rec 0.135
TRAINING - Epoch 58 Batch 20: loss 0.02636077255010605, f1 0.315,  prec 0.582, rec 0.216
TRAINING - Epoch 58 Batch 30: loss 0.023750565946102142, f1 0.36,  prec 0.621, rec 0.253
TRAINING - Epoch 58 Batch 40: loss 0.025242425501346588, f1 0.215,  prec 0.914, rec 0.122
TRAINING - Epoch 58 Batch 50: loss 0.026967858895659447, f1 0.317,  prec 0.611, rec 0.214
VALIDATION - Epoch 58 Batch 0: loss 0.024596204981207848, f1 0.288, prec 0.726, rec 0.18
VALIDATION - Epoch 58 Batch 10: loss 0.02589808776974678, f1 0.264, prec 0.722, rec 0.162
VALIDATION - Epoch 58 Batch 20: loss 0.02598346211016178, f1 0.228, prec 0.688, rec 0.136
TRAINING - Epoch 59 Batch 0: loss 0.026628954336047173, f1 0.289,  prec 0.721, rec 0.18
TRAINING - Epoch 59 Batch 10: loss 0.02455051988363266, f1 0.274,  prec 0.774, rec 0.167
TRAINING - Epoch 59 Batch 20: loss 0.02644895389676094, f1 0.226,  prec 0.72, rec 0.134
TRAINING - Epoch 59 Batch 30: loss 0.02491912990808487, f1 0.235,  prec 0.711, rec 0.141
TRAINING - Epoch 59 Batch 40: loss 0.02905460074543953, f1 0.379,  prec 0.602, rec 0.277
TRAINING - Epoch 59 Batch 50: loss 0.023298759013414383, f1 0.287,  prec 0.57, rec 0.191
VALIDATION - Epoch 59 Batch 0: loss 0.027514761313796043, f1 0.375, prec 0.698, rec 0.256
VALIDATION - Epoch 59 Batch 10: loss 0.0258354339748621, f1 0.363, prec 0.693, rec 0.246
VALIDATION - Epoch 59 Batch 20: loss 0.024426979944109917, f1 0.3, prec 0.484, rec 0.217
TRAINING - Epoch 60 Batch 0: loss 0.028886200860142708, f1 0.304,  prec 0.508, rec 0.217
TRAINING - Epoch 60 Batch 10: loss 0.02326580509543419, f1 0.319,  prec 0.82, rec 0.198
TRAINING - Epoch 60 Batch 20: loss 0.023818183690309525, f1 0.289,  prec 0.811, rec 0.176
TRAINING - Epoch 60 Batch 30: loss 0.027386385947465897, f1 0.112,  prec 0.68, rec 0.061
TRAINING - Epoch 60 Batch 40: loss 0.02673063427209854, f1 0.339,  prec 0.65, rec 0.229
TRAINING - Epoch 60 Batch 50: loss 0.023879757151007652, f1 0.368,  prec 0.849, rec 0.235
VALIDATION - Epoch 60 Batch 0: loss 0.026705550029873848, f1 0.334, prec 0.517, rec 0.247
VALIDATION - Epoch 60 Batch 10: loss 0.025109486654400826, f1 0.407, prec 0.645, rec 0.297
VALIDATION - Epoch 60 Batch 20: loss 0.02623452991247177, f1 0.395, prec 0.656, rec 0.283
TRAINING - Epoch 61 Batch 0: loss 0.025331787765026093, f1 0.434,  prec 0.593, rec 0.343
TRAINING - Epoch 61 Batch 10: loss 0.028028033673763275, f1 0.3,  prec 0.675, rec 0.193
TRAINING - Epoch 61 Batch 20: loss 0.02774803340435028, f1 0.423,  prec 0.447, rec 0.402
TRAINING - Epoch 61 Batch 30: loss 0.025920908898115158, f1 0.226,  prec 0.61, rec 0.138
TRAINING - Epoch 61 Batch 40: loss 0.025757603347301483, f1 0.331,  prec 0.636, rec 0.224
TRAINING - Epoch 61 Batch 50: loss 0.025614997372031212, f1 0.143,  prec 0.576, rec 0.082
VALIDATION - Epoch 61 Batch 0: loss 0.02434203214943409, f1 0.22, prec 0.857, rec 0.126
VALIDATION - Epoch 61 Batch 10: loss 0.026879344135522842, f1 0.179, prec 0.75, rec 0.102
VALIDATION - Epoch 61 Batch 20: loss 0.025828856974840164, f1 0.227, prec 0.829, rec 0.132
TRAINING - Epoch 62 Batch 0: loss 0.025113414973020554, f1 0.208,  prec 0.857, rec 0.118
TRAINING - Epoch 62 Batch 10: loss 0.023567775264382362, f1 0.256,  prec 0.829, rec 0.151
TRAINING - Epoch 62 Batch 20: loss 0.025199661031365395, f1 0.331,  prec 0.659, rec 0.221
TRAINING - Epoch 62 Batch 30: loss 0.024898823350667953, f1 0.344,  prec 0.594, rec 0.242
TRAINING - Epoch 62 Batch 40: loss 0.02597692236304283, f1 0.343,  prec 0.7, rec 0.227
TRAINING - Epoch 62 Batch 50: loss 0.024435121566057205, f1 0.385,  prec 0.824, rec 0.251
VALIDATION - Epoch 62 Batch 0: loss 0.02099785953760147, f1 0.28, prec 0.542, rec 0.188
VALIDATION - Epoch 62 Batch 10: loss 0.026275554671883583, f1 0.315, prec 0.609, rec 0.212
VALIDATION - Epoch 62 Batch 20: loss 0.024275418370962143, f1 0.427, prec 0.757, rec 0.298
TRAINING - Epoch 63 Batch 0: loss 0.025586949661374092, f1 0.379,  prec 0.676, rec 0.263
TRAINING - Epoch 63 Batch 10: loss 0.02535324916243553, f1 0.315,  prec 0.773, rec 0.198
TRAINING - Epoch 63 Batch 20: loss 0.02483549900352955, f1 0.337,  prec 0.641, rec 0.229
TRAINING - Epoch 63 Batch 30: loss 0.024573544040322304, f1 0.335,  prec 0.675, rec 0.223
TRAINING - Epoch 63 Batch 40: loss 0.02700807899236679, f1 0.321,  prec 0.725, rec 0.206
TRAINING - Epoch 63 Batch 50: loss 0.026413794606924057, f1 0.333,  prec 0.833, rec 0.208
VALIDATION - Epoch 63 Batch 0: loss 0.024731045588850975, f1 0.374, prec 0.683, rec 0.257
VALIDATION - Epoch 63 Batch 10: loss 0.026882540434598923, f1 0.299, prec 0.641, rec 0.195
VALIDATION - Epoch 63 Batch 20: loss 0.02566809393465519, f1 0.315, prec 0.609, rec 0.213
TRAINING - Epoch 64 Batch 0: loss 0.026801984757184982, f1 0.296,  prec 0.632, rec 0.194
TRAINING - Epoch 64 Batch 10: loss 0.022292351350188255, f1 0.318,  prec 0.681, rec 0.207
TRAINING - Epoch 64 Batch 20: loss 0.027599940076470375, f1 0.158,  prec 0.923, rec 0.087
TRAINING - Epoch 64 Batch 30: loss 0.027301549911499023, f1 0.392,  prec 0.567, rec 0.3
TRAINING - Epoch 64 Batch 40: loss 0.026233544573187828, f1 0.151,  prec 0.759, rec 0.084
TRAINING - Epoch 64 Batch 50: loss 0.02493545599281788, f1 0.36,  prec 0.643, rec 0.25
VALIDATION - Epoch 64 Batch 0: loss 0.026142636314034462, f1 0.281, prec 0.657, rec 0.179
VALIDATION - Epoch 64 Batch 10: loss 0.02641036920249462, f1 0.313, prec 0.758, rec 0.198
VALIDATION - Epoch 64 Batch 20: loss 0.026174848899245262, f1 0.317, prec 0.806, rec 0.197
TRAINING - Epoch 65 Batch 0: loss 0.025631079450249672, f1 0.283,  prec 0.719, rec 0.176
TRAINING - Epoch 65 Batch 10: loss 0.02364441007375717, f1 0.269,  prec 0.714, rec 0.166
TRAINING - Epoch 65 Batch 20: loss 0.027090469375252724, f1 0.419,  prec 0.655, rec 0.308
TRAINING - Epoch 65 Batch 30: loss 0.02378315106034279, f1 0.279,  prec 0.651, rec 0.177
TRAINING - Epoch 65 Batch 40: loss 0.026040416210889816, f1 0.406,  prec 0.574, rec 0.314
TRAINING - Epoch 65 Batch 50: loss 0.024738479405641556, f1 0.243,  prec 0.654, rec 0.149
VALIDATION - Epoch 65 Batch 0: loss 0.02605428174138069, f1 0.224, prec 0.875, rec 0.129
VALIDATION - Epoch 65 Batch 10: loss 0.02828156389296055, f1 0.212, prec 0.778, rec 0.123
VALIDATION - Epoch 65 Batch 20: loss 0.024438239634037018, f1 0.178, prec 0.923, rec 0.099
TRAINING - Epoch 66 Batch 0: loss 0.029353952035307884, f1 0.234,  prec 0.812, rec 0.137
TRAINING - Epoch 66 Batch 10: loss 0.027090763673186302, f1 0.398,  prec 0.618, rec 0.293
TRAINING - Epoch 66 Batch 20: loss 0.02094964310526848, f1 0.1,  prec 0.688, rec 0.054
TRAINING - Epoch 66 Batch 30: loss 0.024584384635090828, f1 0.09,  prec 1.0, rec 0.047
TRAINING - Epoch 66 Batch 40: loss 0.025411373004317284, f1 0.378,  prec 0.567, rec 0.283
TRAINING - Epoch 66 Batch 50: loss 0.024089265614748, f1 0.241,  prec 0.547, rec 0.154
VALIDATION - Epoch 66 Batch 0: loss 0.027022644877433777, f1 0.316, prec 0.763, rec 0.199
VALIDATION - Epoch 66 Batch 10: loss 0.02424546331167221, f1 0.261, prec 0.685, rec 0.162
VALIDATION - Epoch 66 Batch 20: loss 0.027496691793203354, f1 0.324, prec 0.724, rec 0.209
TRAINING - Epoch 67 Batch 0: loss 0.02503545954823494, f1 0.382,  prec 0.673, rec 0.267
TRAINING - Epoch 67 Batch 10: loss 0.024737482890486717, f1 0.246,  prec 0.8, rec 0.145
TRAINING - Epoch 67 Batch 20: loss 0.027110343798995018, f1 0.404,  prec 0.503, rec 0.337
TRAINING - Epoch 67 Batch 30: loss 0.024231083691120148, f1 0.331,  prec 0.811, rec 0.208
TRAINING - Epoch 67 Batch 40: loss 0.02700665220618248, f1 0.411,  prec 0.564, rec 0.323
TRAINING - Epoch 67 Batch 50: loss 0.02435574121773243, f1 0.237,  prec 0.642, rec 0.145
VALIDATION - Epoch 67 Batch 0: loss 0.026097459718585014, f1 0.409, prec 0.535, rec 0.331
VALIDATION - Epoch 67 Batch 10: loss 0.025872590020298958, f1 0.47, prec 0.626, rec 0.377
VALIDATION - Epoch 67 Batch 20: loss 0.025801541283726692, f1 0.456, prec 0.678, rec 0.344
TRAINING - Epoch 68 Batch 0: loss 0.02690747380256653, f1 0.43,  prec 0.588, rec 0.339
TRAINING - Epoch 68 Batch 10: loss 0.025287669152021408, f1 0.185,  prec 0.893, rec 0.103
TRAINING - Epoch 68 Batch 20: loss 0.02847813442349434, f1 0.394,  prec 0.75, rec 0.267
TRAINING - Epoch 68 Batch 30: loss 0.02484838105738163, f1 0.409,  prec 0.67, rec 0.294
TRAINING - Epoch 68 Batch 40: loss 0.02278829924762249, f1 0.327,  prec 0.776, rec 0.207
TRAINING - Epoch 68 Batch 50: loss 0.02465912513434887, f1 0.227,  prec 0.567, rec 0.142
VALIDATION - Epoch 68 Batch 0: loss 0.02549494244158268, f1 0.401, prec 0.576, rec 0.308
VALIDATION - Epoch 68 Batch 10: loss 0.026075001806020737, f1 0.454, prec 0.618, rec 0.359
VALIDATION - Epoch 68 Batch 20: loss 0.026346901431679726, f1 0.413, prec 0.571, rec 0.323
TRAINING - Epoch 69 Batch 0: loss 0.023706110194325447, f1 0.464,  prec 0.687, rec 0.351
TRAINING - Epoch 69 Batch 10: loss 0.026672495529055595, f1 0.2,  prec 0.75, rec 0.115
TRAINING - Epoch 69 Batch 20: loss 0.025374742224812508, f1 0.351,  prec 0.653, rec 0.24
TRAINING - Epoch 69 Batch 30: loss 0.02475227788090706, f1 0.381,  prec 0.66, rec 0.268
TRAINING - Epoch 69 Batch 40: loss 0.027282610535621643, f1 0.421,  prec 0.611, rec 0.322
TRAINING - Epoch 69 Batch 50: loss 0.024398796260356903, f1 0.333,  prec 0.663, rec 0.223
VALIDATION - Epoch 69 Batch 0: loss 0.027883144095540047, f1 0.148, prec 0.852, rec 0.081
VALIDATION - Epoch 69 Batch 10: loss 0.03132535144686699, f1 0.144, prec 0.8, rec 0.079
VALIDATION - Epoch 69 Batch 20: loss 0.027592526748776436, f1 0.162, prec 0.852, rec 0.089
TRAINING - Epoch 70 Batch 0: loss 0.023913081735372543, f1 0.214,  prec 0.667, rec 0.128
TRAINING - Epoch 70 Batch 10: loss 0.02413616143167019, f1 0.446,  prec 0.642, rec 0.341
TRAINING - Epoch 70 Batch 20: loss 0.022827813401818275, f1 0.353,  prec 0.711, rec 0.235
TRAINING - Epoch 70 Batch 30: loss 0.023347537964582443, f1 0.3,  prec 0.807, rec 0.184
TRAINING - Epoch 70 Batch 40: loss 0.022347310557961464, f1 0.356,  prec 0.614, rec 0.251
TRAINING - Epoch 70 Batch 50: loss 0.02578681893646717, f1 0.31,  prec 0.831, rec 0.191
VALIDATION - Epoch 70 Batch 0: loss 0.025667766109108925, f1 0.212, prec 0.62, rec 0.128
VALIDATION - Epoch 70 Batch 10: loss 0.023942848667502403, f1 0.284, prec 0.687, rec 0.179
VALIDATION - Epoch 70 Batch 20: loss 0.025688940659165382, f1 0.317, prec 0.79, rec 0.198
TRAINING - Epoch 71 Batch 0: loss 0.02424866519868374, f1 0.232,  prec 0.673, rec 0.14
TRAINING - Epoch 71 Batch 10: loss 0.024335043504834175, f1 0.213,  prec 0.8, rec 0.123
TRAINING - Epoch 71 Batch 20: loss 0.02486964873969555, f1 0.389,  prec 0.69, rec 0.271
TRAINING - Epoch 71 Batch 30: loss 0.022188937291502953, f1 0.203,  prec 0.839, rec 0.116
TRAINING - Epoch 71 Batch 40: loss 0.024623436853289604, f1 0.362,  prec 0.812, rec 0.233
TRAINING - Epoch 71 Batch 50: loss 0.023837443441152573, f1 0.432,  prec 0.631, rec 0.328
VALIDATION - Epoch 71 Batch 0: loss 0.029464390128850937, f1 0.331, prec 0.739, rec 0.213
VALIDATION - Epoch 71 Batch 10: loss 0.024886097759008408, f1 0.306, prec 0.649, rec 0.2
VALIDATION - Epoch 71 Batch 20: loss 0.025975560769438744, f1 0.35, prec 0.709, rec 0.232
TRAINING - Epoch 72 Batch 0: loss 0.024814190343022346, f1 0.342,  prec 0.602, rec 0.239
TRAINING - Epoch 72 Batch 10: loss 0.024646079167723656, f1 0.271,  prec 0.792, rec 0.163
TRAINING - Epoch 72 Batch 20: loss 0.024228859692811966, f1 0.313,  prec 0.823, rec 0.193
TRAINING - Epoch 72 Batch 30: loss 0.024241425096988678, f1 0.444,  prec 0.766, rec 0.313
TRAINING - Epoch 72 Batch 40: loss 0.023779766634106636, f1 0.351,  prec 0.659, rec 0.239
TRAINING - Epoch 72 Batch 50: loss 0.02406071312725544, f1 0.394,  prec 0.795, rec 0.262
VALIDATION - Epoch 72 Batch 0: loss 0.024633200839161873, f1 0.377, prec 0.685, rec 0.26
VALIDATION - Epoch 72 Batch 10: loss 0.021738244220614433, f1 0.404, prec 0.716, rec 0.281
VALIDATION - Epoch 72 Batch 20: loss 0.024089116603136063, f1 0.346, prec 0.716, rec 0.228
TRAINING - Epoch 73 Batch 0: loss 0.024353621527552605, f1 0.369,  prec 0.702, rec 0.25
TRAINING - Epoch 73 Batch 10: loss 0.024812940508127213, f1 0.277,  prec 0.707, rec 0.172
TRAINING - Epoch 73 Batch 20: loss 0.02197093330323696, f1 0.403,  prec 0.76, rec 0.274
TRAINING - Epoch 73 Batch 30: loss 0.02711113542318344, f1 0.346,  prec 0.695, rec 0.231
TRAINING - Epoch 73 Batch 40: loss 0.02518857829272747, f1 0.391,  prec 0.689, rec 0.273
TRAINING - Epoch 73 Batch 50: loss 0.02327241376042366, f1 0.279,  prec 0.759, rec 0.171
VALIDATION - Epoch 73 Batch 0: loss 0.023998355492949486, f1 0.393, prec 0.698, rec 0.273
VALIDATION - Epoch 73 Batch 10: loss 0.026064878329634666, f1 0.33, prec 0.61, rec 0.226
VALIDATION - Epoch 73 Batch 20: loss 0.024528371170163155, f1 0.398, prec 0.699, rec 0.278
TRAINING - Epoch 74 Batch 0: loss 0.024184124544262886, f1 0.391,  prec 0.667, rec 0.276
TRAINING - Epoch 74 Batch 10: loss 0.024891328066587448, f1 0.409,  prec 0.659, rec 0.297
TRAINING - Epoch 74 Batch 20: loss 0.022633906453847885, f1 0.274,  prec 0.792, rec 0.166
TRAINING - Epoch 74 Batch 30: loss 0.023285305127501488, f1 0.379,  prec 0.72, rec 0.257
TRAINING - Epoch 74 Batch 40: loss 0.023083891719579697, f1 0.431,  prec 0.626, rec 0.329
TRAINING - Epoch 74 Batch 50: loss 0.026877596974372864, f1 0.203,  prec 0.882, rec 0.115
VALIDATION - Epoch 74 Batch 0: loss 0.023324469104409218, f1 0.337, prec 0.684, rec 0.223
VALIDATION - Epoch 74 Batch 10: loss 0.024076828733086586, f1 0.33, prec 0.709, rec 0.215
VALIDATION - Epoch 74 Batch 20: loss 0.02531873807311058, f1 0.347, prec 0.689, rec 0.232
TRAINING - Epoch 75 Batch 0: loss 0.023215068504214287, f1 0.373,  prec 0.66, rec 0.26
TRAINING - Epoch 75 Batch 10: loss 0.025375252589583397, f1 0.357,  prec 0.642, rec 0.247
TRAINING - Epoch 75 Batch 20: loss 0.022260792553424835, f1 0.46,  prec 0.61, rec 0.369
TRAINING - Epoch 75 Batch 30: loss 0.02245398424565792, f1 0.435,  prec 0.713, rec 0.313
TRAINING - Epoch 75 Batch 40: loss 0.02411050908267498, f1 0.201,  prec 0.844, rec 0.114
TRAINING - Epoch 75 Batch 50: loss 0.022113298997282982, f1 0.353,  prec 0.724, rec 0.233
VALIDATION - Epoch 75 Batch 0: loss 0.02498197741806507, f1 0.304, prec 0.862, rec 0.185
VALIDATION - Epoch 75 Batch 10: loss 0.025839632377028465, f1 0.307, prec 0.764, rec 0.192
VALIDATION - Epoch 75 Batch 20: loss 0.025010578334331512, f1 0.267, prec 0.745, rec 0.163
TRAINING - Epoch 76 Batch 0: loss 0.025701293721795082, f1 0.289,  prec 0.85, rec 0.174
TRAINING - Epoch 76 Batch 10: loss 0.022883327677845955, f1 0.425,  prec 0.771, rec 0.294
TRAINING - Epoch 76 Batch 20: loss 0.028348859399557114, f1 0.405,  prec 0.518, rec 0.332
TRAINING - Epoch 76 Batch 30: loss 0.025497110560536385, f1 0.349,  prec 0.692, rec 0.233
TRAINING - Epoch 76 Batch 40: loss 0.02488092891871929, f1 0.309,  prec 0.742, rec 0.195
TRAINING - Epoch 76 Batch 50: loss 0.02184399589896202, f1 0.289,  prec 0.694, rec 0.182
VALIDATION - Epoch 76 Batch 0: loss 0.02511768788099289, f1 0.322, prec 0.732, rec 0.206
VALIDATION - Epoch 76 Batch 10: loss 0.025388922542333603, f1 0.223, prec 0.767, rec 0.13
VALIDATION - Epoch 76 Batch 20: loss 0.025282422080636024, f1 0.358, prec 0.871, rec 0.225
TRAINING - Epoch 77 Batch 0: loss 0.024265971034765244, f1 0.357,  prec 0.811, rec 0.229
TRAINING - Epoch 77 Batch 10: loss 0.02467069961130619, f1 0.366,  prec 0.741, rec 0.243
TRAINING - Epoch 77 Batch 20: loss 0.024659844115376472, f1 0.441,  prec 0.692, rec 0.324
TRAINING - Epoch 77 Batch 30: loss 0.025636697188019753, f1 0.121,  prec 0.842, rec 0.065
TRAINING - Epoch 77 Batch 40: loss 0.026830680668354034, f1 0.349,  prec 0.542, rec 0.257
TRAINING - Epoch 77 Batch 50: loss 0.02548292838037014, f1 0.238,  prec 0.833, rec 0.139
VALIDATION - Epoch 77 Batch 0: loss 0.025756744667887688, f1 0.444, prec 0.575, rec 0.362
VALIDATION - Epoch 77 Batch 10: loss 0.02510271780192852, f1 0.463, prec 0.615, rec 0.371
VALIDATION - Epoch 77 Batch 20: loss 0.026369057595729828, f1 0.481, prec 0.557, rec 0.424
TRAINING - Epoch 78 Batch 0: loss 0.02523263357579708, f1 0.506,  prec 0.64, rec 0.418
TRAINING - Epoch 78 Batch 10: loss 0.02162700518965721, f1 0.37,  prec 0.833, rec 0.238
TRAINING - Epoch 78 Batch 20: loss 0.025451457127928734, f1 0.155,  prec 0.96, rec 0.085
TRAINING - Epoch 78 Batch 30: loss 0.0223012063652277, f1 0.387,  prec 0.722, rec 0.264
TRAINING - Epoch 78 Batch 40: loss 0.024330880492925644, f1 0.448,  prec 0.674, rec 0.336
TRAINING - Epoch 78 Batch 50: loss 0.025829466059803963, f1 0.342,  prec 0.721, rec 0.224
VALIDATION - Epoch 78 Batch 0: loss 0.025516469031572342, f1 0.286, prec 0.797, rec 0.174
VALIDATION - Epoch 78 Batch 10: loss 0.026554401963949203, f1 0.282, prec 0.823, rec 0.17
VALIDATION - Epoch 78 Batch 20: loss 0.02648843638598919, f1 0.219, prec 0.667, rec 0.131
TRAINING - Epoch 79 Batch 0: loss 0.01976068876683712, f1 0.338,  prec 0.763, rec 0.217
TRAINING - Epoch 79 Batch 10: loss 0.023073989897966385, f1 0.463,  prec 0.744, rec 0.336
TRAINING - Epoch 79 Batch 20: loss 0.022234538570046425, f1 0.434,  prec 0.598, rec 0.341
TRAINING - Epoch 79 Batch 30: loss 0.022648049518465996, f1 0.362,  prec 0.699, rec 0.244
TRAINING - Epoch 79 Batch 40: loss 0.023702222853899002, f1 0.334,  prec 0.8, rec 0.211
TRAINING - Epoch 79 Batch 50: loss 0.02490266039967537, f1 0.217,  prec 0.721, rec 0.128
VALIDATION - Epoch 79 Batch 0: loss 0.02551240846514702, f1 0.289, prec 0.9, rec 0.172
VALIDATION - Epoch 79 Batch 10: loss 0.02825813740491867, f1 0.236, prec 0.774, rec 0.139
VALIDATION - Epoch 79 Batch 20: loss 0.026693131774663925, f1 0.237, prec 0.804, rec 0.139
TRAINING - Epoch 80 Batch 0: loss 0.023245085030794144, f1 0.263,  prec 0.851, rec 0.156
TRAINING - Epoch 80 Batch 10: loss 0.024027101695537567, f1 0.442,  prec 0.654, rec 0.333
TRAINING - Epoch 80 Batch 20: loss 0.021138694137334824, f1 0.435,  prec 0.794, rec 0.3
TRAINING - Epoch 80 Batch 30: loss 0.024224331602454185, f1 0.251,  prec 0.95, rec 0.144
TRAINING - Epoch 80 Batch 40: loss 0.023043448105454445, f1 0.367,  prec 0.693, rec 0.25
TRAINING - Epoch 80 Batch 50: loss 0.020036881789565086, f1 0.453,  prec 0.788, rec 0.318
VALIDATION - Epoch 80 Batch 0: loss 0.02472621574997902, f1 0.447, prec 0.736, rec 0.321
VALIDATION - Epoch 80 Batch 10: loss 0.023673292249441147, f1 0.371, prec 0.596, rec 0.269
VALIDATION - Epoch 80 Batch 20: loss 0.025090141221880913, f1 0.325, prec 0.593, rec 0.224
TRAINING - Epoch 81 Batch 0: loss 0.02322525717318058, f1 0.437,  prec 0.721, rec 0.314
TRAINING - Epoch 81 Batch 10: loss 0.023061348125338554, f1 0.406,  prec 0.723, rec 0.282
TRAINING - Epoch 81 Batch 20: loss 0.02361905761063099, f1 0.321,  prec 0.847, rec 0.198
TRAINING - Epoch 81 Batch 30: loss 0.023421434685587883, f1 0.265,  prec 0.684, rec 0.165
TRAINING - Epoch 81 Batch 40: loss 0.023327643051743507, f1 0.392,  prec 0.723, rec 0.269
TRAINING - Epoch 81 Batch 50: loss 0.02473660185933113, f1 0.361,  prec 0.627, rec 0.253
VALIDATION - Epoch 81 Batch 0: loss 0.023416753858327866, f1 0.356, prec 0.701, rec 0.238
VALIDATION - Epoch 81 Batch 10: loss 0.02453192137181759, f1 0.359, prec 0.721, rec 0.239
VALIDATION - Epoch 81 Batch 20: loss 0.023494146764278412, f1 0.427, prec 0.837, rec 0.286
TRAINING - Epoch 82 Batch 0: loss 0.024528244510293007, f1 0.3,  prec 0.643, rec 0.196
TRAINING - Epoch 82 Batch 10: loss 0.023973090574145317, f1 0.532,  prec 0.669, rec 0.442
TRAINING - Epoch 82 Batch 20: loss 0.021590586751699448, f1 0.389,  prec 0.584, rec 0.292
TRAINING - Epoch 82 Batch 30: loss 0.026000959798693657, f1 0.399,  prec 0.673, rec 0.284
TRAINING - Epoch 82 Batch 40: loss 0.025111768394708633, f1 0.223,  prec 0.829, rec 0.129
TRAINING - Epoch 82 Batch 50: loss 0.0250279288738966, f1 0.461,  prec 0.556, rec 0.394
VALIDATION - Epoch 82 Batch 0: loss 0.029065337032079697, f1 0.244, prec 0.721, rec 0.147
VALIDATION - Epoch 82 Batch 10: loss 0.024942079558968544, f1 0.329, prec 0.778, rec 0.209
VALIDATION - Epoch 82 Batch 20: loss 0.02675122208893299, f1 0.228, prec 0.778, rec 0.134
TRAINING - Epoch 83 Batch 0: loss 0.022914854809641838, f1 0.381,  prec 0.803, rec 0.25
TRAINING - Epoch 83 Batch 10: loss 0.02439996227622032, f1 0.471,  prec 0.599, rec 0.388
TRAINING - Epoch 83 Batch 20: loss 0.024517275393009186, f1 0.38,  prec 0.758, rec 0.254
TRAINING - Epoch 83 Batch 30: loss 0.02301991917192936, f1 0.41,  prec 0.726, rec 0.286
TRAINING - Epoch 83 Batch 40: loss 0.019614502787590027, f1 0.392,  prec 0.862, rec 0.253
TRAINING - Epoch 83 Batch 50: loss 0.028881395235657692, f1 0.022,  prec 1.0, rec 0.011
VALIDATION - Epoch 83 Batch 0: loss 0.026355942711234093, f1 0.33, prec 0.824, rec 0.207
VALIDATION - Epoch 83 Batch 10: loss 0.02534547634422779, f1 0.299, prec 0.662, rec 0.193
VALIDATION - Epoch 83 Batch 20: loss 0.025611350312829018, f1 0.318, prec 0.765, rec 0.201
TRAINING - Epoch 84 Batch 0: loss 0.024560661986470222, f1 0.346,  prec 0.72, rec 0.228
TRAINING - Epoch 84 Batch 10: loss 0.022945251315832138, f1 0.293,  prec 0.746, rec 0.183
TRAINING - Epoch 84 Batch 20: loss 0.020457766950130463, f1 0.455,  prec 0.709, rec 0.335
TRAINING - Epoch 84 Batch 30: loss 0.025283100083470345, f1 0.316,  prec 0.809, rec 0.196
TRAINING - Epoch 84 Batch 40: loss 0.02351940982043743, f1 0.302,  prec 0.62, rec 0.2
TRAINING - Epoch 84 Batch 50: loss 0.021580474451184273, f1 0.367,  prec 0.693, rec 0.25
VALIDATION - Epoch 84 Batch 0: loss 0.02516760490834713, f1 0.354, prec 0.693, rec 0.237
VALIDATION - Epoch 84 Batch 10: loss 0.02379094436764717, f1 0.319, prec 0.73, rec 0.204
VALIDATION - Epoch 84 Batch 20: loss 0.027285970747470856, f1 0.32, prec 0.728, rec 0.205
TRAINING - Epoch 85 Batch 0: loss 0.023717690259218216, f1 0.38,  prec 0.691, rec 0.262
TRAINING - Epoch 85 Batch 10: loss 0.022858403623104095, f1 0.436,  prec 0.696, rec 0.318
TRAINING - Epoch 85 Batch 20: loss 0.02212161011993885, f1 0.489,  prec 0.601, rec 0.412
TRAINING - Epoch 85 Batch 30: loss 0.025241607800126076, f1 0.349,  prec 0.705, rec 0.232
TRAINING - Epoch 85 Batch 40: loss 0.023297255858778954, f1 0.451,  prec 0.669, rec 0.34
TRAINING - Epoch 85 Batch 50: loss 0.021070973947644234, f1 0.345,  prec 0.746, rec 0.225
VALIDATION - Epoch 85 Batch 0: loss 0.028107240796089172, f1 0.299, prec 0.859, rec 0.181
VALIDATION - Epoch 85 Batch 10: loss 0.026225486770272255, f1 0.329, prec 0.831, rec 0.205
VALIDATION - Epoch 85 Batch 20: loss 0.02391771413385868, f1 0.316, prec 0.787, rec 0.198
TRAINING - Epoch 86 Batch 0: loss 0.025683263316750526, f1 0.359,  prec 0.844, rec 0.228
TRAINING - Epoch 86 Batch 10: loss 0.023073209449648857, f1 0.471,  prec 0.632, rec 0.375
TRAINING - Epoch 86 Batch 20: loss 0.02420111745595932, f1 0.299,  prec 0.806, rec 0.183
TRAINING - Epoch 86 Batch 30: loss 0.022905508056282997, f1 0.354,  prec 0.632, rec 0.246
TRAINING - Epoch 86 Batch 40: loss 0.026219943538308144, f1 0.259,  prec 0.854, rec 0.152
TRAINING - Epoch 86 Batch 50: loss 0.0244925357401371, f1 0.423,  prec 0.506, rec 0.364
VALIDATION - Epoch 86 Batch 0: loss 0.02654731087386608, f1 0.353, prec 0.747, rec 0.231
VALIDATION - Epoch 86 Batch 10: loss 0.02611476369202137, f1 0.338, prec 0.656, rec 0.228
VALIDATION - Epoch 86 Batch 20: loss 0.02330978587269783, f1 0.349, prec 0.764, rec 0.226
TRAINING - Epoch 87 Batch 0: loss 0.025937052443623543, f1 0.344,  prec 0.67, rec 0.232
TRAINING - Epoch 87 Batch 10: loss 0.022521354258060455, f1 0.34,  prec 0.671, rec 0.227
TRAINING - Epoch 87 Batch 20: loss 0.022288214415311813, f1 0.168,  prec 0.864, rec 0.093
TRAINING - Epoch 87 Batch 30: loss 0.01970284804701805, f1 0.425,  prec 0.667, rec 0.312
TRAINING - Epoch 87 Batch 40: loss 0.02206365019083023, f1 0.392,  prec 0.713, rec 0.271
TRAINING - Epoch 87 Batch 50: loss 0.024641485884785652, f1 0.372,  prec 0.758, rec 0.247
VALIDATION - Epoch 87 Batch 0: loss 0.026105191558599472, f1 0.403, prec 0.79, rec 0.271
VALIDATION - Epoch 87 Batch 10: loss 0.029573429375886917, f1 0.207, prec 0.694, rec 0.121
VALIDATION - Epoch 87 Batch 20: loss 0.023621533066034317, f1 0.31, prec 0.773, rec 0.194
TRAINING - Epoch 88 Batch 0: loss 0.025877680629491806, f1 0.375,  prec 0.828, rec 0.242
TRAINING - Epoch 88 Batch 10: loss 0.022685958072543144, f1 0.28,  prec 0.612, rec 0.181
TRAINING - Epoch 88 Batch 20: loss 0.022014956921339035, f1 0.357,  prec 0.723, rec 0.237
TRAINING - Epoch 88 Batch 30: loss 0.02507086843252182, f1 0.389,  prec 0.778, rec 0.259
TRAINING - Epoch 88 Batch 40: loss 0.02259521372616291, f1 0.423,  prec 0.684, rec 0.307
TRAINING - Epoch 88 Batch 50: loss 0.02318640984594822, f1 0.35,  prec 0.712, rec 0.232
VALIDATION - Epoch 88 Batch 0: loss 0.02298072539269924, f1 0.387, prec 0.663, rec 0.273
VALIDATION - Epoch 88 Batch 10: loss 0.02728126011788845, f1 0.367, prec 0.791, rec 0.239
VALIDATION - Epoch 88 Batch 20: loss 0.023920392617583275, f1 0.363, prec 0.75, rec 0.239
TRAINING - Epoch 89 Batch 0: loss 0.024159211665391922, f1 0.393,  prec 0.66, rec 0.28
TRAINING - Epoch 89 Batch 10: loss 0.02137439325451851, f1 0.448,  prec 0.757, rec 0.318
TRAINING - Epoch 89 Batch 20: loss 0.023252779617905617, f1 0.438,  prec 0.782, rec 0.304
TRAINING - Epoch 89 Batch 30: loss 0.02198360301554203, f1 0.435,  prec 0.643, rec 0.329
TRAINING - Epoch 89 Batch 40: loss 0.024690113961696625, f1 0.388,  prec 0.655, rec 0.276
TRAINING - Epoch 89 Batch 50: loss 0.023442966863512993, f1 0.398,  prec 0.75, rec 0.271
VALIDATION - Epoch 89 Batch 0: loss 0.02388163097202778, f1 0.34, prec 0.806, rec 0.216
VALIDATION - Epoch 89 Batch 10: loss 0.02235906943678856, f1 0.401, prec 0.726, rec 0.277
VALIDATION - Epoch 89 Batch 20: loss 0.024402907118201256, f1 0.32, prec 0.73, rec 0.205
TRAINING - Epoch 90 Batch 0: loss 0.0224901270121336, f1 0.354,  prec 0.667, rec 0.241
TRAINING - Epoch 90 Batch 10: loss 0.024968894198536873, f1 0.477,  prec 0.624, rec 0.386
TRAINING - Epoch 90 Batch 20: loss 0.023066828027367592, f1 0.289,  prec 0.754, rec 0.178
TRAINING - Epoch 90 Batch 30: loss 0.025060387328267097, f1 0.419,  prec 0.689, rec 0.301
TRAINING - Epoch 90 Batch 40: loss 0.02074270509183407, f1 0.513,  prec 0.658, rec 0.42
TRAINING - Epoch 90 Batch 50: loss 0.02449650503695011, f1 0.422,  prec 0.595, rec 0.327
VALIDATION - Epoch 90 Batch 0: loss 0.026086386293172836, f1 0.425, prec 0.596, rec 0.33
VALIDATION - Epoch 90 Batch 10: loss 0.022972606122493744, f1 0.472, prec 0.655, rec 0.369
VALIDATION - Epoch 90 Batch 20: loss 0.02331119030714035, f1 0.392, prec 0.552, rec 0.304
TRAINING - Epoch 91 Batch 0: loss 0.023603159934282303, f1 0.475,  prec 0.59, rec 0.397
TRAINING - Epoch 91 Batch 10: loss 0.022255223244428635, f1 0.399,  prec 0.648, rec 0.288
TRAINING - Epoch 91 Batch 20: loss 0.022992245852947235, f1 0.442,  prec 0.759, rec 0.312
TRAINING - Epoch 91 Batch 30: loss 0.022917067632079124, f1 0.45,  prec 0.611, rec 0.357
TRAINING - Epoch 91 Batch 40: loss 0.022841867059469223, f1 0.406,  prec 0.651, rec 0.295
TRAINING - Epoch 91 Batch 50: loss 0.020457707345485687, f1 0.354,  prec 0.718, rec 0.235
VALIDATION - Epoch 91 Batch 0: loss 0.02512066438794136, f1 0.468, prec 0.656, rec 0.364
VALIDATION - Epoch 91 Batch 10: loss 0.023125285282731056, f1 0.474, prec 0.652, rec 0.372
VALIDATION - Epoch 91 Batch 20: loss 0.023405466228723526, f1 0.375, prec 0.545, rec 0.286
TRAINING - Epoch 92 Batch 0: loss 0.022552834823727608, f1 0.492,  prec 0.632, rec 0.403
TRAINING - Epoch 92 Batch 10: loss 0.020849641412496567, f1 0.361,  prec 0.674, rec 0.247
TRAINING - Epoch 92 Batch 20: loss 0.023044047877192497, f1 0.324,  prec 0.726, rec 0.209
TRAINING - Epoch 92 Batch 30: loss 0.023671310395002365, f1 0.401,  prec 0.518, rec 0.327
TRAINING - Epoch 92 Batch 40: loss 0.02215009555220604, f1 0.452,  prec 0.691, rec 0.336
TRAINING - Epoch 92 Batch 50: loss 0.02537887543439865, f1 0.435,  prec 0.662, rec 0.324
VALIDATION - Epoch 92 Batch 0: loss 0.026562752202153206, f1 0.312, prec 0.705, rec 0.2
VALIDATION - Epoch 92 Batch 10: loss 0.025664474815130234, f1 0.353, prec 0.843, rec 0.223
VALIDATION - Epoch 92 Batch 20: loss 0.023843608796596527, f1 0.381, prec 0.791, rec 0.251
TRAINING - Epoch 93 Batch 0: loss 0.022966627031564713, f1 0.431,  prec 0.821, rec 0.292
TRAINING - Epoch 93 Batch 10: loss 0.024138623848557472, f1 0.334,  prec 0.871, rec 0.207
TRAINING - Epoch 93 Batch 20: loss 0.022484485059976578, f1 0.3,  prec 0.825, rec 0.184
TRAINING - Epoch 93 Batch 30: loss 0.022839806973934174, f1 0.472,  prec 0.7, rec 0.355
TRAINING - Epoch 93 Batch 40: loss 0.02197253331542015, f1 0.404,  prec 0.677, rec 0.288
TRAINING - Epoch 93 Batch 50: loss 0.02195723168551922, f1 0.441,  prec 0.837, rec 0.299
VALIDATION - Epoch 93 Batch 0: loss 0.024661950767040253, f1 0.413, prec 0.667, rec 0.299
VALIDATION - Epoch 93 Batch 10: loss 0.026030544191598892, f1 0.337, prec 0.628, rec 0.23
VALIDATION - Epoch 93 Batch 20: loss 0.025921864435076714, f1 0.407, prec 0.667, rec 0.293
TRAINING - Epoch 94 Batch 0: loss 0.021954970434308052, f1 0.396,  prec 0.695, rec 0.277
TRAINING - Epoch 94 Batch 10: loss 0.022990915924310684, f1 0.352,  prec 0.769, rec 0.228
TRAINING - Epoch 94 Batch 20: loss 0.02173537202179432, f1 0.391,  prec 0.779, rec 0.261
TRAINING - Epoch 94 Batch 30: loss 0.02529730275273323, f1 0.329,  prec 0.704, rec 0.215
TRAINING - Epoch 94 Batch 40: loss 0.020117342472076416, f1 0.387,  prec 0.725, rec 0.264
TRAINING - Epoch 94 Batch 50: loss 0.02436017617583275, f1 0.4,  prec 0.565, rec 0.31
VALIDATION - Epoch 94 Batch 0: loss 0.022910885512828827, f1 0.39, prec 0.636, rec 0.281
VALIDATION - Epoch 94 Batch 10: loss 0.02407633513212204, f1 0.423, prec 0.752, rec 0.295
VALIDATION - Epoch 94 Batch 20: loss 0.02345067821443081, f1 0.386, prec 0.615, rec 0.281
TRAINING - Epoch 95 Batch 0: loss 0.019826987758278847, f1 0.526,  prec 0.797, rec 0.393
TRAINING - Epoch 95 Batch 10: loss 0.02362433262169361, f1 0.255,  prec 0.826, rec 0.151
TRAINING - Epoch 95 Batch 20: loss 0.0233211200684309, f1 0.46,  prec 0.664, rec 0.352
TRAINING - Epoch 95 Batch 30: loss 0.023991812020540237, f1 0.455,  prec 0.695, rec 0.338
TRAINING - Epoch 95 Batch 40: loss 0.021108215674757957, f1 0.379,  prec 0.744, rec 0.254
TRAINING - Epoch 95 Batch 50: loss 0.02221912331879139, f1 0.416,  prec 0.793, rec 0.282
VALIDATION - Epoch 95 Batch 0: loss 0.025297289714217186, f1 0.261, prec 0.755, rec 0.158
VALIDATION - Epoch 95 Batch 10: loss 0.022052383050322533, f1 0.349, prec 0.776, rec 0.225
VALIDATION - Epoch 95 Batch 20: loss 0.02480904571712017, f1 0.334, prec 0.731, rec 0.217
TRAINING - Epoch 96 Batch 0: loss 0.021370645612478256, f1 0.28,  prec 0.696, rec 0.175
TRAINING - Epoch 96 Batch 10: loss 0.020008224993944168, f1 0.45,  prec 0.696, rec 0.332
TRAINING - Epoch 96 Batch 20: loss 0.02233091928064823, f1 0.357,  prec 0.734, rec 0.236
TRAINING - Epoch 96 Batch 30: loss 0.024987244978547096, f1 0.341,  prec 0.765, rec 0.219
TRAINING - Epoch 96 Batch 40: loss 0.024150924757122993, f1 0.479,  prec 0.724, rec 0.358
TRAINING - Epoch 96 Batch 50: loss 0.02172078564763069, f1 0.404,  prec 0.713, rec 0.282
VALIDATION - Epoch 96 Batch 0: loss 0.023645084351301193, f1 0.505, prec 0.764, rec 0.377
VALIDATION - Epoch 96 Batch 10: loss 0.025179149582982063, f1 0.403, prec 0.636, rec 0.295
VALIDATION - Epoch 96 Batch 20: loss 0.02276528626680374, f1 0.457, prec 0.741, rec 0.331
TRAINING - Epoch 97 Batch 0: loss 0.023536549881100655, f1 0.432,  prec 0.594, rec 0.339
TRAINING - Epoch 97 Batch 10: loss 0.020894331857562065, f1 0.391,  prec 0.775, rec 0.262
TRAINING - Epoch 97 Batch 20: loss 0.02634112350642681, f1 0.352,  prec 0.808, rec 0.225
TRAINING - Epoch 97 Batch 30: loss 0.024618642404675484, f1 0.438,  prec 0.621, rec 0.338
TRAINING - Epoch 97 Batch 40: loss 0.023115945979952812, f1 0.279,  prec 0.851, rec 0.167
TRAINING - Epoch 97 Batch 50: loss 0.01985967718064785, f1 0.487,  prec 0.603, rec 0.409
VALIDATION - Epoch 97 Batch 0: loss 0.02558298222720623, f1 0.345, prec 0.678, rec 0.231
VALIDATION - Epoch 97 Batch 10: loss 0.02235022373497486, f1 0.397, prec 0.8, rec 0.264
VALIDATION - Epoch 97 Batch 20: loss 0.02273249253630638, f1 0.264, prec 0.771, rec 0.159
TRAINING - Epoch 98 Batch 0: loss 0.02258516103029251, f1 0.489,  prec 0.857, rec 0.342
TRAINING - Epoch 98 Batch 10: loss 0.022098461166024208, f1 0.451,  prec 0.711, rec 0.331
TRAINING - Epoch 98 Batch 20: loss 0.02324608340859413, f1 0.436,  prec 0.856, rec 0.292
TRAINING - Epoch 98 Batch 30: loss 0.024688513949513435, f1 0.392,  prec 0.852, rec 0.254
TRAINING - Epoch 98 Batch 40: loss 0.020022574812173843, f1 0.492,  prec 0.662, rec 0.391
TRAINING - Epoch 98 Batch 50: loss 0.021631022915244102, f1 0.424,  prec 0.651, rec 0.314
VALIDATION - Epoch 98 Batch 0: loss 0.022882578894495964, f1 0.377, prec 0.745, rec 0.253
VALIDATION - Epoch 98 Batch 10: loss 0.022726407274603844, f1 0.372, prec 0.802, rec 0.243
VALIDATION - Epoch 98 Batch 20: loss 0.02409205213189125, f1 0.348, prec 0.644, rec 0.238
TRAINING - Epoch 99 Batch 0: loss 0.022641588002443314, f1 0.395,  prec 0.75, rec 0.268
TRAINING - Epoch 99 Batch 10: loss 0.021640796214342117, f1 0.424,  prec 0.69, rec 0.306
TRAINING - Epoch 99 Batch 20: loss 0.021579714491963387, f1 0.486,  prec 0.651, rec 0.388
TRAINING - Epoch 99 Batch 30: loss 0.023721810430288315, f1 0.488,  prec 0.731, rec 0.367
TRAINING - Epoch 99 Batch 40: loss 0.02161947824060917, f1 0.354,  prec 0.757, rec 0.231
TRAINING - Epoch 99 Batch 50: loss 0.021398862823843956, f1 0.432,  prec 0.67, rec 0.319
VALIDATION - Epoch 99 Batch 0: loss 0.0235463697463274, f1 0.427, prec 0.717, rec 0.305
VALIDATION - Epoch 99 Batch 10: loss 0.02289198711514473, f1 0.399, prec 0.745, rec 0.272
VALIDATION - Epoch 99 Batch 20: loss 0.024663398042321205, f1 0.415, prec 0.757, rec 0.286
TRAINING - Epoch 100 Batch 0: loss 0.02329740859568119, f1 0.4,  prec 0.747, rec 0.273
TRAINING - Epoch 100 Batch 10: loss 0.02480190247297287, f1 0.369,  prec 0.722, rec 0.248
TRAINING - Epoch 100 Batch 20: loss 0.020518934354186058, f1 0.42,  prec 0.737, rec 0.294
TRAINING - Epoch 100 Batch 30: loss 0.020234666764736176, f1 0.465,  prec 0.664, rec 0.358
TRAINING - Epoch 100 Batch 40: loss 0.02220255881547928, f1 0.466,  prec 0.713, rec 0.346
TRAINING - Epoch 100 Batch 50: loss 0.02014898881316185, f1 0.33,  prec 0.768, rec 0.21
VALIDATION - Epoch 100 Batch 0: loss 0.02248230390250683, f1 0.464, prec 0.664, rec 0.356
VALIDATION - Epoch 100 Batch 10: loss 0.023905733600258827, f1 0.478, prec 0.648, rec 0.378
VALIDATION - Epoch 100 Batch 20: loss 0.022516753524541855, f1 0.444, prec 0.669, rec 0.332
TRAINING - Epoch 101 Batch 0: loss 0.02253527007997036, f1 0.495,  prec 0.639, rec 0.405
TRAINING - Epoch 101 Batch 10: loss 0.02243976667523384, f1 0.402,  prec 0.816, rec 0.267
TRAINING - Epoch 101 Batch 20: loss 0.021433822810649872, f1 0.44,  prec 0.849, rec 0.297
TRAINING - Epoch 101 Batch 30: loss 0.02180723287165165, f1 0.375,  prec 0.759, rec 0.249
TRAINING - Epoch 101 Batch 40: loss 0.02113693207502365, f1 0.463,  prec 0.612, rec 0.373
TRAINING - Epoch 101 Batch 50: loss 0.023440204560756683, f1 0.433,  prec 0.705, rec 0.313
VALIDATION - Epoch 101 Batch 0: loss 0.025125300511717796, f1 0.333, prec 0.771, rec 0.213
VALIDATION - Epoch 101 Batch 10: loss 0.025192704051733017, f1 0.439, prec 0.847, rec 0.296
VALIDATION - Epoch 101 Batch 20: loss 0.024340469390153885, f1 0.301, prec 0.82, rec 0.185
TRAINING - Epoch 102 Batch 0: loss 0.022596735507249832, f1 0.315,  prec 0.721, rec 0.202
TRAINING - Epoch 102 Batch 10: loss 0.02413027361035347, f1 0.501,  prec 0.695, rec 0.392
TRAINING - Epoch 102 Batch 20: loss 0.020984221249818802, f1 0.419,  prec 0.826, rec 0.281
TRAINING - Epoch 102 Batch 30: loss 0.022903533652424812, f1 0.42,  prec 0.713, rec 0.297
TRAINING - Epoch 102 Batch 40: loss 0.022645989432930946, f1 0.472,  prec 0.708, rec 0.354
TRAINING - Epoch 102 Batch 50: loss 0.0198406632989645, f1 0.433,  prec 0.724, rec 0.309
VALIDATION - Epoch 102 Batch 0: loss 0.02479652501642704, f1 0.457, prec 0.596, rec 0.37
VALIDATION - Epoch 102 Batch 10: loss 0.02077672816812992, f1 0.465, prec 0.608, rec 0.376
VALIDATION - Epoch 102 Batch 20: loss 0.023822668939828873, f1 0.44, prec 0.662, rec 0.33
TRAINING - Epoch 103 Batch 0: loss 0.02315082587301731, f1 0.457,  prec 0.592, rec 0.372
TRAINING - Epoch 103 Batch 10: loss 0.02170579507946968, f1 0.399,  prec 0.788, rec 0.267
TRAINING - Epoch 103 Batch 20: loss 0.02086617425084114, f1 0.438,  prec 0.79, rec 0.303
TRAINING - Epoch 103 Batch 30: loss 0.021898867562413216, f1 0.495,  prec 0.662, rec 0.396
TRAINING - Epoch 103 Batch 40: loss 0.024171132594347, f1 0.379,  prec 0.72, rec 0.257
TRAINING - Epoch 103 Batch 50: loss 0.023510077968239784, f1 0.448,  prec 0.627, rec 0.348
VALIDATION - Epoch 103 Batch 0: loss 0.02580403722822666, f1 0.402, prec 0.728, rec 0.278
VALIDATION - Epoch 103 Batch 10: loss 0.02493215911090374, f1 0.467, prec 0.754, rec 0.338
VALIDATION - Epoch 103 Batch 20: loss 0.02177850343286991, f1 0.42, prec 0.763, rec 0.29
TRAINING - Epoch 104 Batch 0: loss 0.02092043310403824, f1 0.511,  prec 0.793, rec 0.377
TRAINING - Epoch 104 Batch 10: loss 0.023829367011785507, f1 0.344,  prec 0.803, rec 0.219
TRAINING - Epoch 104 Batch 20: loss 0.0212358720600605, f1 0.439,  prec 0.771, rec 0.307
TRAINING - Epoch 104 Batch 30: loss 0.02272411435842514, f1 0.39,  prec 0.758, rec 0.262
TRAINING - Epoch 104 Batch 40: loss 0.021813420578837395, f1 0.353,  prec 0.593, rec 0.251
TRAINING - Epoch 104 Batch 50: loss 0.020720776170492172, f1 0.382,  prec 0.697, rec 0.263
VALIDATION - Epoch 104 Batch 0: loss 0.022117342799901962, f1 0.401, prec 0.726, rec 0.277
VALIDATION - Epoch 104 Batch 10: loss 0.02478897199034691, f1 0.384, prec 0.718, rec 0.262
VALIDATION - Epoch 104 Batch 20: loss 0.022952506318688393, f1 0.379, prec 0.684, rec 0.262
TRAINING - Epoch 105 Batch 0: loss 0.020123958587646484, f1 0.492,  prec 0.782, rec 0.359
TRAINING - Epoch 105 Batch 10: loss 0.021338922902941704, f1 0.452,  prec 0.659, rec 0.344
TRAINING - Epoch 105 Batch 20: loss 0.021869996562600136, f1 0.414,  prec 0.8, rec 0.279
TRAINING - Epoch 105 Batch 30: loss 0.020755000412464142, f1 0.545,  prec 0.8, rec 0.414
TRAINING - Epoch 105 Batch 40: loss 0.021942807361483574, f1 0.535,  prec 0.707, rec 0.43
TRAINING - Epoch 105 Batch 50: loss 0.022866880521178246, f1 0.225,  prec 0.886, rec 0.129
VALIDATION - Epoch 105 Batch 0: loss 0.02414492331445217, f1 0.412, prec 0.824, rec 0.275
VALIDATION - Epoch 105 Batch 10: loss 0.025566430762410164, f1 0.351, prec 0.744, rec 0.229
VALIDATION - Epoch 105 Batch 20: loss 0.024794725701212883, f1 0.356, prec 0.718, rec 0.236
TRAINING - Epoch 106 Batch 0: loss 0.022904906421899796, f1 0.428,  prec 0.766, rec 0.297
TRAINING - Epoch 106 Batch 10: loss 0.022881997749209404, f1 0.37,  prec 0.739, rec 0.247
TRAINING - Epoch 106 Batch 20: loss 0.022354120388627052, f1 0.391,  prec 0.678, rec 0.275
TRAINING - Epoch 106 Batch 30: loss 0.018890969455242157, f1 0.534,  prec 0.732, rec 0.421
TRAINING - Epoch 106 Batch 40: loss 0.023032106459140778, f1 0.3,  prec 0.773, rec 0.186
TRAINING - Epoch 106 Batch 50: loss 0.021940777078270912, f1 0.439,  prec 0.698, rec 0.32
VALIDATION - Epoch 106 Batch 0: loss 0.024912787601351738, f1 0.29, prec 0.797, rec 0.177
VALIDATION - Epoch 106 Batch 10: loss 0.02606544829905033, f1 0.286, prec 0.793, rec 0.174
VALIDATION - Epoch 106 Batch 20: loss 0.02544591762125492, f1 0.353, prec 0.873, rec 0.221
TRAINING - Epoch 107 Batch 0: loss 0.022181669250130653, f1 0.398,  prec 0.824, rec 0.262
TRAINING - Epoch 107 Batch 10: loss 0.02055450901389122, f1 0.455,  prec 0.705, rec 0.336
TRAINING - Epoch 107 Batch 20: loss 0.01894894242286682, f1 0.431,  prec 0.758, rec 0.301
TRAINING - Epoch 107 Batch 30: loss 0.01927303895354271, f1 0.491,  prec 0.762, rec 0.362
TRAINING - Epoch 107 Batch 40: loss 0.023381108418107033, f1 0.362,  prec 0.747, rec 0.238
TRAINING - Epoch 107 Batch 50: loss 0.02022133581340313, f1 0.463,  prec 0.732, rec 0.339
VALIDATION - Epoch 107 Batch 0: loss 0.023659149184823036, f1 0.306, prec 0.649, rec 0.2
VALIDATION - Epoch 107 Batch 10: loss 0.01935277320444584, f1 0.469, prec 0.816, rec 0.329
VALIDATION - Epoch 107 Batch 20: loss 0.022385088726878166, f1 0.395, prec 0.636, rec 0.287
TRAINING - Epoch 108 Batch 0: loss 0.019181694835424423, f1 0.51,  prec 0.829, rec 0.368
TRAINING - Epoch 108 Batch 10: loss 0.021428348496556282, f1 0.433,  prec 0.743, rec 0.306
TRAINING - Epoch 108 Batch 20: loss 0.023670025169849396, f1 0.412,  prec 0.776, rec 0.28
TRAINING - Epoch 108 Batch 30: loss 0.02366730198264122, f1 0.494,  prec 0.752, rec 0.368
TRAINING - Epoch 108 Batch 40: loss 0.022087549790740013, f1 0.21,  prec 0.765, rec 0.121
TRAINING - Epoch 108 Batch 50: loss 0.021503722295165062, f1 0.457,  prec 0.715, rec 0.336
VALIDATION - Epoch 108 Batch 0: loss 0.023267703130841255, f1 0.347, prec 0.841, rec 0.219
VALIDATION - Epoch 108 Batch 10: loss 0.025480395182967186, f1 0.278, prec 0.698, rec 0.174
VALIDATION - Epoch 108 Batch 20: loss 0.022711601108312607, f1 0.387, prec 0.815, rec 0.254
TRAINING - Epoch 109 Batch 0: loss 0.020145785063505173, f1 0.391,  prec 0.849, rec 0.254
TRAINING - Epoch 109 Batch 10: loss 0.023043017834424973, f1 0.401,  prec 0.779, rec 0.27
TRAINING - Epoch 109 Batch 20: loss 0.022221215069293976, f1 0.295,  prec 0.868, rec 0.178
TRAINING - Epoch 109 Batch 30: loss 0.022251952439546585, f1 0.481,  prec 0.718, rec 0.362
TRAINING - Epoch 109 Batch 40: loss 0.02332017943263054, f1 0.391,  prec 0.735, rec 0.267
TRAINING - Epoch 109 Batch 50: loss 0.02113599143922329, f1 0.48,  prec 0.724, rec 0.359
VALIDATION - Epoch 109 Batch 0: loss 0.023718003183603287, f1 0.31, prec 0.842, rec 0.19
VALIDATION - Epoch 109 Batch 10: loss 0.025922005996108055, f1 0.353, prec 0.797, rec 0.227
VALIDATION - Epoch 109 Batch 20: loss 0.023702086880803108, f1 0.35, prec 0.875, rec 0.219
TRAINING - Epoch 110 Batch 0: loss 0.021773403510451317, f1 0.338,  prec 0.8, rec 0.215
TRAINING - Epoch 110 Batch 10: loss 0.020732218399643898, f1 0.449,  prec 0.824, rec 0.309
TRAINING - Epoch 110 Batch 20: loss 0.02064153179526329, f1 0.461,  prec 0.739, rec 0.335
TRAINING - Epoch 110 Batch 30: loss 0.023195795714855194, f1 0.403,  prec 0.768, rec 0.273
TRAINING - Epoch 110 Batch 40: loss 0.022667450830340385, f1 0.378,  prec 0.774, rec 0.25
TRAINING - Epoch 110 Batch 50: loss 0.02439453825354576, f1 0.389,  prec 0.75, rec 0.262
VALIDATION - Epoch 110 Batch 0: loss 0.02245229110121727, f1 0.444, prec 0.82, rec 0.305
VALIDATION - Epoch 110 Batch 10: loss 0.023342197760939598, f1 0.41, prec 0.82, rec 0.273
VALIDATION - Epoch 110 Batch 20: loss 0.023703372105956078, f1 0.393, prec 0.779, rec 0.263
TRAINING - Epoch 111 Batch 0: loss 0.02019558660686016, f1 0.476,  prec 0.82, rec 0.336
TRAINING - Epoch 111 Batch 10: loss 0.022046662867069244, f1 0.45,  prec 0.773, rec 0.317
TRAINING - Epoch 111 Batch 20: loss 0.021907495334744453, f1 0.438,  prec 0.737, rec 0.312
TRAINING - Epoch 111 Batch 30: loss 0.023625966161489487, f1 0.441,  prec 0.727, rec 0.316
TRAINING - Epoch 111 Batch 40: loss 0.018992125988006592, f1 0.432,  prec 0.714, rec 0.31
TRAINING - Epoch 111 Batch 50: loss 0.02122928574681282, f1 0.441,  prec 0.705, rec 0.321
VALIDATION - Epoch 111 Batch 0: loss 0.025003546848893166, f1 0.304, prec 0.781, rec 0.189
VALIDATION - Epoch 111 Batch 10: loss 0.021802779287099838, f1 0.404, prec 0.89, rec 0.261
VALIDATION - Epoch 111 Batch 20: loss 0.024517299607396126, f1 0.401, prec 0.77, rec 0.271
TRAINING - Epoch 112 Batch 0: loss 0.022219497710466385, f1 0.351,  prec 0.845, rec 0.221
TRAINING - Epoch 112 Batch 10: loss 0.02105366811156273, f1 0.411,  prec 0.758, rec 0.282
TRAINING - Epoch 112 Batch 20: loss 0.02030954696238041, f1 0.456,  prec 0.736, rec 0.331
TRAINING - Epoch 112 Batch 30: loss 0.022103900089859962, f1 0.503,  prec 0.638, rec 0.416
TRAINING - Epoch 112 Batch 40: loss 0.02162300795316696, f1 0.38,  prec 0.853, rec 0.245
TRAINING - Epoch 112 Batch 50: loss 0.02281041070818901, f1 0.502,  prec 0.618, rec 0.423
VALIDATION - Epoch 112 Batch 0: loss 0.022178174927830696, f1 0.46, prec 0.75, rec 0.332
VALIDATION - Epoch 112 Batch 10: loss 0.023968974128365517, f1 0.453, prec 0.746, rec 0.325
VALIDATION - Epoch 112 Batch 20: loss 0.022713743150234222, f1 0.47, prec 0.68, rec 0.359
TRAINING - Epoch 113 Batch 0: loss 0.020246025174856186, f1 0.509,  prec 0.735, rec 0.39
TRAINING - Epoch 113 Batch 10: loss 0.018977178260684013, f1 0.374,  prec 0.846, rec 0.24
TRAINING - Epoch 113 Batch 20: loss 0.021921660751104355, f1 0.483,  prec 0.701, rec 0.369
TRAINING - Epoch 113 Batch 30: loss 0.020358562469482422, f1 0.426,  prec 0.815, rec 0.288
TRAINING - Epoch 113 Batch 40: loss 0.022751541808247566, f1 0.378,  prec 0.824, rec 0.246
TRAINING - Epoch 113 Batch 50: loss 0.019559716805815697, f1 0.511,  prec 0.729, rec 0.393
VALIDATION - Epoch 113 Batch 0: loss 0.026500703766942024, f1 0.309, prec 0.848, rec 0.189
VALIDATION - Epoch 113 Batch 10: loss 0.022430354729294777, f1 0.349, prec 0.776, rec 0.225
VALIDATION - Epoch 113 Batch 20: loss 0.02291100099682808, f1 0.375, prec 0.753, rec 0.25
TRAINING - Epoch 114 Batch 0: loss 0.020028162747621536, f1 0.384,  prec 0.795, rec 0.253
TRAINING - Epoch 114 Batch 10: loss 0.021923283115029335, f1 0.486,  prec 0.671, rec 0.381
TRAINING - Epoch 114 Batch 20: loss 0.02018044888973236, f1 0.447,  prec 0.736, rec 0.321
TRAINING - Epoch 114 Batch 30: loss 0.019723040983080864, f1 0.459,  prec 0.649, rec 0.356
TRAINING - Epoch 114 Batch 40: loss 0.019526474177837372, f1 0.438,  prec 0.689, rec 0.322
TRAINING - Epoch 114 Batch 50: loss 0.022882577031850815, f1 0.396,  prec 0.75, rec 0.269
VALIDATION - Epoch 114 Batch 0: loss 0.023385051637887955, f1 0.405, prec 0.849, rec 0.266
VALIDATION - Epoch 114 Batch 10: loss 0.022253859788179398, f1 0.358, prec 0.698, rec 0.241
VALIDATION - Epoch 114 Batch 20: loss 0.022800464183092117, f1 0.396, prec 0.807, rec 0.262
TRAINING - Epoch 115 Batch 0: loss 0.02181157097220421, f1 0.465,  prec 0.821, rec 0.324
TRAINING - Epoch 115 Batch 10: loss 0.019264042377471924, f1 0.475,  prec 0.808, rec 0.336
TRAINING - Epoch 115 Batch 20: loss 0.022502947598695755, f1 0.363,  prec 0.744, rec 0.24
TRAINING - Epoch 115 Batch 30: loss 0.02356458082795143, f1 0.313,  prec 0.864, rec 0.191
TRAINING - Epoch 115 Batch 40: loss 0.018413284793496132, f1 0.439,  prec 0.67, rec 0.326
TRAINING - Epoch 115 Batch 50: loss 0.022851353511214256, f1 0.375,  prec 0.764, rec 0.248
VALIDATION - Epoch 115 Batch 0: loss 0.027622446417808533, f1 0.152, prec 0.913, rec 0.083
VALIDATION - Epoch 115 Batch 10: loss 0.027265431359410286, f1 0.153, prec 0.821, rec 0.085
VALIDATION - Epoch 115 Batch 20: loss 0.02423550747334957, f1 0.165, prec 0.88, rec 0.091
TRAINING - Epoch 116 Batch 0: loss 0.021912405267357826, f1 0.179,  prec 0.92, rec 0.099
TRAINING - Epoch 116 Batch 10: loss 0.022575298324227333, f1 0.439,  prec 0.755, rec 0.309
TRAINING - Epoch 116 Batch 20: loss 0.020424067974090576, f1 0.515,  prec 0.693, rec 0.409
TRAINING - Epoch 116 Batch 30: loss 0.01987835019826889, f1 0.451,  prec 0.789, rec 0.316
TRAINING - Epoch 116 Batch 40: loss 0.020723935216665268, f1 0.392,  prec 0.67, rec 0.277
TRAINING - Epoch 116 Batch 50: loss 0.0215842816978693, f1 0.413,  prec 0.824, rec 0.276
VALIDATION - Epoch 116 Batch 0: loss 0.02425527200102806, f1 0.257, prec 0.851, rec 0.152
VALIDATION - Epoch 116 Batch 10: loss 0.02559613063931465, f1 0.265, prec 0.878, rec 0.156
VALIDATION - Epoch 116 Batch 20: loss 0.029044847935438156, f1 0.233, prec 0.86, rec 0.135
TRAINING - Epoch 117 Batch 0: loss 0.023292802274227142, f1 0.227,  prec 0.895, rec 0.13
TRAINING - Epoch 117 Batch 10: loss 0.02127603068947792, f1 0.464,  prec 0.727, rec 0.341
TRAINING - Epoch 117 Batch 20: loss 0.018400615081191063, f1 0.482,  prec 0.735, rec 0.358
TRAINING - Epoch 117 Batch 30: loss 0.020305881276726723, f1 0.529,  prec 0.815, rec 0.391
TRAINING - Epoch 117 Batch 40: loss 0.02116546593606472, f1 0.513,  prec 0.752, rec 0.39
TRAINING - Epoch 117 Batch 50: loss 0.020671319216489792, f1 0.477,  prec 0.672, rec 0.37
VALIDATION - Epoch 117 Batch 0: loss 0.02009730413556099, f1 0.463, prec 0.711, rec 0.343
VALIDATION - Epoch 117 Batch 10: loss 0.02366836555302143, f1 0.404, prec 0.651, rec 0.292
VALIDATION - Epoch 117 Batch 20: loss 0.025361811742186546, f1 0.344, prec 0.59, rec 0.243
TRAINING - Epoch 118 Batch 0: loss 0.021420104429125786, f1 0.444,  prec 0.686, rec 0.328
TRAINING - Epoch 118 Batch 10: loss 0.0206732340157032, f1 0.35,  prec 0.863, rec 0.22
TRAINING - Epoch 118 Batch 20: loss 0.019375763833522797, f1 0.521,  prec 0.739, rec 0.402
TRAINING - Epoch 118 Batch 30: loss 0.021416151896119118, f1 0.479,  prec 0.71, rec 0.362
TRAINING - Epoch 118 Batch 40: loss 0.022015687078237534, f1 0.312,  prec 0.9, rec 0.189
TRAINING - Epoch 118 Batch 50: loss 0.020754331722855568, f1 0.526,  prec 0.718, rec 0.415
VALIDATION - Epoch 118 Batch 0: loss 0.02173992246389389, f1 0.432, prec 0.709, rec 0.311
VALIDATION - Epoch 118 Batch 10: loss 0.022972099483013153, f1 0.446, prec 0.705, rec 0.326
VALIDATION - Epoch 118 Batch 20: loss 0.022635530680418015, f1 0.436, prec 0.726, rec 0.312
TRAINING - Epoch 119 Batch 0: loss 0.018019169569015503, f1 0.531,  prec 0.785, rec 0.402
TRAINING - Epoch 119 Batch 10: loss 0.02090407721698284, f1 0.446,  prec 0.735, rec 0.321
TRAINING - Epoch 119 Batch 20: loss 0.021771447733044624, f1 0.448,  prec 0.723, rec 0.325
TRAINING - Epoch 119 Batch 30: loss 0.019648130983114243, f1 0.388,  prec 0.714, rec 0.267
TRAINING - Epoch 119 Batch 40: loss 0.019995341077446938, f1 0.444,  prec 0.694, rec 0.326
TRAINING - Epoch 119 Batch 50: loss 0.018810449168086052, f1 0.397,  prec 0.863, rec 0.258
VALIDATION - Epoch 119 Batch 0: loss 0.02444506250321865, f1 0.409, prec 0.806, rec 0.274
VALIDATION - Epoch 119 Batch 10: loss 0.02343841642141342, f1 0.363, prec 0.656, rec 0.251
VALIDATION - Epoch 119 Batch 20: loss 0.027259880676865578, f1 0.392, prec 0.733, rec 0.267
TRAINING - Epoch 120 Batch 0: loss 0.020973367616534233, f1 0.44,  prec 0.692, rec 0.323
TRAINING - Epoch 120 Batch 10: loss 0.024660775437951088, f1 0.463,  prec 0.722, rec 0.34
TRAINING - Epoch 120 Batch 20: loss 0.01865551993250847, f1 0.508,  prec 0.763, rec 0.381
TRAINING - Epoch 120 Batch 30: loss 0.020615659654140472, f1 0.462,  prec 0.752, rec 0.333
TRAINING - Epoch 120 Batch 40: loss 0.021376172080636024, f1 0.356,  prec 0.663, rec 0.243
TRAINING - Epoch 120 Batch 50: loss 0.017449159175157547, f1 0.473,  prec 0.754, rec 0.344
VALIDATION - Epoch 120 Batch 0: loss 0.024289626628160477, f1 0.464, prec 0.641, rec 0.364
VALIDATION - Epoch 120 Batch 10: loss 0.023485975340008736, f1 0.4, prec 0.598, rec 0.3
VALIDATION - Epoch 120 Batch 20: loss 0.024009548127651215, f1 0.414, prec 0.704, rec 0.293
TRAINING - Epoch 121 Batch 0: loss 0.023355962708592415, f1 0.544,  prec 0.638, rec 0.473
TRAINING - Epoch 121 Batch 10: loss 0.023256385698914528, f1 0.377,  prec 0.829, rec 0.244
TRAINING - Epoch 121 Batch 20: loss 0.018630992621183395, f1 0.426,  prec 0.689, rec 0.309
TRAINING - Epoch 121 Batch 30: loss 0.017207782715559006, f1 0.423,  prec 0.795, rec 0.288
TRAINING - Epoch 121 Batch 40: loss 0.020741207525134087, f1 0.434,  prec 0.735, rec 0.307
TRAINING - Epoch 121 Batch 50: loss 0.021534139290452003, f1 0.477,  prec 0.718, rec 0.357
VALIDATION - Epoch 121 Batch 0: loss 0.022875068709254265, f1 0.421, prec 0.597, rec 0.325
VALIDATION - Epoch 121 Batch 10: loss 0.022493014112114906, f1 0.478, prec 0.657, rec 0.376
VALIDATION - Epoch 121 Batch 20: loss 0.02473033033311367, f1 0.424, prec 0.691, rec 0.306
TRAINING - Epoch 122 Batch 0: loss 0.019860489293932915, f1 0.494,  prec 0.766, rec 0.364
TRAINING - Epoch 122 Batch 10: loss 0.02298017591238022, f1 0.529,  prec 0.669, rec 0.438
TRAINING - Epoch 122 Batch 20: loss 0.0194757878780365, f1 0.469,  prec 0.741, rec 0.343
TRAINING - Epoch 122 Batch 30: loss 0.01970900036394596, f1 0.521,  prec 0.629, rec 0.444
TRAINING - Epoch 122 Batch 40: loss 0.018191996961832047, f1 0.495,  prec 0.764, rec 0.366
TRAINING - Epoch 122 Batch 50: loss 0.022277457639575005, f1 0.362,  prec 0.885, rec 0.228
VALIDATION - Epoch 122 Batch 0: loss 0.026012422516942024, f1 0.453, prec 0.669, rec 0.342
VALIDATION - Epoch 122 Batch 10: loss 0.02263079211115837, f1 0.455, prec 0.79, rec 0.319
VALIDATION - Epoch 122 Batch 20: loss 0.022824665531516075, f1 0.388, prec 0.598, rec 0.288
TRAINING - Epoch 123 Batch 0: loss 0.02066504955291748, f1 0.455,  prec 0.761, rec 0.325
TRAINING - Epoch 123 Batch 10: loss 0.019060619175434113, f1 0.524,  prec 0.659, rec 0.435
TRAINING - Epoch 123 Batch 20: loss 0.022275278344750404, f1 0.489,  prec 0.595, rec 0.415
TRAINING - Epoch 123 Batch 30: loss 0.021699953824281693, f1 0.379,  prec 0.691, rec 0.261
TRAINING - Epoch 123 Batch 40: loss 0.02252778224647045, f1 0.415,  prec 0.686, rec 0.298
TRAINING - Epoch 123 Batch 50: loss 0.023427385836839676, f1 0.449,  prec 0.771, rec 0.317
VALIDATION - Epoch 123 Batch 0: loss 0.024501867592334747, f1 0.331, prec 0.72, rec 0.215
VALIDATION - Epoch 123 Batch 10: loss 0.02397606335580349, f1 0.412, prec 0.753, rec 0.284
VALIDATION - Epoch 123 Batch 20: loss 0.027466043829917908, f1 0.362, prec 0.727, rec 0.241
TRAINING - Epoch 124 Batch 0: loss 0.021413816139101982, f1 0.412,  prec 0.765, rec 0.282
TRAINING - Epoch 124 Batch 10: loss 0.019649498164653778, f1 0.445,  prec 0.827, rec 0.305
TRAINING - Epoch 124 Batch 20: loss 0.020671576261520386, f1 0.46,  prec 0.794, rec 0.324
TRAINING - Epoch 124 Batch 30: loss 0.02244163677096367, f1 0.5,  prec 0.759, rec 0.373
TRAINING - Epoch 124 Batch 40: loss 0.02030673250555992, f1 0.45,  prec 0.848, rec 0.306
TRAINING - Epoch 124 Batch 50: loss 0.020707659423351288, f1 0.371,  prec 0.831, rec 0.239
VALIDATION - Epoch 124 Batch 0: loss 0.026017628610134125, f1 0.33, prec 0.775, rec 0.21
VALIDATION - Epoch 124 Batch 10: loss 0.026767034083604813, f1 0.364, prec 0.833, rec 0.233
VALIDATION - Epoch 124 Batch 20: loss 0.024300916120409966, f1 0.373, prec 0.816, rec 0.242
TRAINING - Epoch 125 Batch 0: loss 0.019176781177520752, f1 0.462,  prec 0.827, rec 0.32
TRAINING - Epoch 125 Batch 10: loss 0.019426997750997543, f1 0.485,  prec 0.733, rec 0.362
TRAINING - Epoch 125 Batch 20: loss 0.018918408080935478, f1 0.499,  prec 0.756, rec 0.372
TRAINING - Epoch 125 Batch 30: loss 0.020739709958434105, f1 0.416,  prec 0.784, rec 0.283
TRAINING - Epoch 125 Batch 40: loss 0.01814253255724907, f1 0.413,  prec 0.829, rec 0.275
TRAINING - Epoch 125 Batch 50: loss 0.0218124371021986, f1 0.497,  prec 0.605, rec 0.422
VALIDATION - Epoch 125 Batch 0: loss 0.025514570996165276, f1 0.322, prec 0.712, rec 0.208
VALIDATION - Epoch 125 Batch 10: loss 0.024115683510899544, f1 0.344, prec 0.794, rec 0.22
VALIDATION - Epoch 125 Batch 20: loss 0.02484838292002678, f1 0.325, prec 0.754, rec 0.207
TRAINING - Epoch 126 Batch 0: loss 0.023015422746539116, f1 0.42,  prec 0.806, rec 0.284
TRAINING - Epoch 126 Batch 10: loss 0.01907997950911522, f1 0.484,  prec 0.765, rec 0.353
TRAINING - Epoch 126 Batch 20: loss 0.020220469683408737, f1 0.391,  prec 0.849, rec 0.254
TRAINING - Epoch 126 Batch 30: loss 0.0212741419672966, f1 0.454,  prec 0.777, rec 0.321
TRAINING - Epoch 126 Batch 40: loss 0.02030404657125473, f1 0.484,  prec 0.703, rec 0.369
TRAINING - Epoch 126 Batch 50: loss 0.023374903947114944, f1 0.404,  prec 0.8, rec 0.27
VALIDATION - Epoch 126 Batch 0: loss 0.02349126897752285, f1 0.345, prec 0.716, rec 0.227
VALIDATION - Epoch 126 Batch 10: loss 0.021834196522831917, f1 0.374, prec 0.732, rec 0.251
VALIDATION - Epoch 126 Batch 20: loss 0.02525862492620945, f1 0.35, prec 0.727, rec 0.23
TRAINING - Epoch 127 Batch 0: loss 0.019610995426774025, f1 0.501,  prec 0.815, rec 0.362
TRAINING - Epoch 127 Batch 10: loss 0.021674465388059616, f1 0.504,  prec 0.744, rec 0.381
TRAINING - Epoch 127 Batch 20: loss 0.01959521882236004, f1 0.477,  prec 0.752, rec 0.349
TRAINING - Epoch 127 Batch 30: loss 0.020291004329919815, f1 0.489,  prec 0.669, rec 0.386
TRAINING - Epoch 127 Batch 40: loss 0.020395927131175995, f1 0.485,  prec 0.756, rec 0.357
TRAINING - Epoch 127 Batch 50: loss 0.019515328109264374, f1 0.407,  prec 0.803, rec 0.272
VALIDATION - Epoch 127 Batch 0: loss 0.023486150428652763, f1 0.394, prec 0.68, rec 0.278
VALIDATION - Epoch 127 Batch 10: loss 0.022868676111102104, f1 0.445, prec 0.703, rec 0.325
VALIDATION - Epoch 127 Batch 20: loss 0.023272909224033356, f1 0.433, prec 0.713, rec 0.311
TRAINING - Epoch 128 Batch 0: loss 0.020516401156783104, f1 0.501,  prec 0.723, rec 0.383
TRAINING - Epoch 128 Batch 10: loss 0.019613465294241905, f1 0.483,  prec 0.679, rec 0.375
TRAINING - Epoch 128 Batch 20: loss 0.01961992122232914, f1 0.417,  prec 0.769, rec 0.286
TRAINING - Epoch 128 Batch 30: loss 0.02094217576086521, f1 0.465,  prec 0.679, rec 0.353
TRAINING - Epoch 128 Batch 40: loss 0.01859320141375065, f1 0.529,  prec 0.763, rec 0.405
TRAINING - Epoch 128 Batch 50: loss 0.019342316314578056, f1 0.488,  prec 0.703, rec 0.373
VALIDATION - Epoch 128 Batch 0: loss 0.024923691526055336, f1 0.382, prec 0.644, rec 0.271
VALIDATION - Epoch 128 Batch 10: loss 0.02268572524189949, f1 0.423, prec 0.709, rec 0.301
VALIDATION - Epoch 128 Batch 20: loss 0.02061660960316658, f1 0.404, prec 0.753, rec 0.276
TRAINING - Epoch 129 Batch 0: loss 0.018612653017044067, f1 0.494,  prec 0.721, rec 0.376
TRAINING - Epoch 129 Batch 10: loss 0.019145941361784935, f1 0.415,  prec 0.739, rec 0.288
TRAINING - Epoch 129 Batch 20: loss 0.02102174609899521, f1 0.526,  prec 0.725, rec 0.412
TRAINING - Epoch 129 Batch 30: loss 0.017836332321166992, f1 0.571,  prec 0.744, rec 0.463
TRAINING - Epoch 129 Batch 40: loss 0.019649028778076172, f1 0.436,  prec 0.602, rec 0.342
TRAINING - Epoch 129 Batch 50: loss 0.019281655550003052, f1 0.503,  prec 0.724, rec 0.385
VALIDATION - Epoch 129 Batch 0: loss 0.025225289165973663, f1 0.484, prec 0.688, rec 0.374
VALIDATION - Epoch 129 Batch 10: loss 0.024097878485918045, f1 0.438, prec 0.78, rec 0.305
VALIDATION - Epoch 129 Batch 20: loss 0.024092180654406548, f1 0.446, prec 0.755, rec 0.317
TRAINING - Epoch 130 Batch 0: loss 0.020723283290863037, f1 0.467,  prec 0.711, rec 0.347
TRAINING - Epoch 130 Batch 10: loss 0.021419305354356766, f1 0.427,  prec 0.894, rec 0.28
TRAINING - Epoch 130 Batch 20: loss 0.020030666142702103, f1 0.537,  prec 0.661, rec 0.453
TRAINING - Epoch 130 Batch 30: loss 0.020533496513962746, f1 0.463,  prec 0.798, rec 0.326
TRAINING - Epoch 130 Batch 40: loss 0.020475637167692184, f1 0.462,  prec 0.688, rec 0.348
TRAINING - Epoch 130 Batch 50: loss 0.02104955166578293, f1 0.511,  prec 0.729, rec 0.393
VALIDATION - Epoch 130 Batch 0: loss 0.020371388643980026, f1 0.448, prec 0.759, rec 0.318
VALIDATION - Epoch 130 Batch 10: loss 0.024561014026403427, f1 0.408, prec 0.794, rec 0.275
VALIDATION - Epoch 130 Batch 20: loss 0.024884643033146858, f1 0.364, prec 0.639, rec 0.255
TRAINING - Epoch 131 Batch 0: loss 0.018522173166275024, f1 0.522,  prec 0.766, rec 0.396
TRAINING - Epoch 131 Batch 10: loss 0.018320467323064804, f1 0.526,  prec 0.754, rec 0.404
TRAINING - Epoch 131 Batch 20: loss 0.022163743153214455, f1 0.516,  prec 0.764, rec 0.39
TRAINING - Epoch 131 Batch 30: loss 0.02147797681391239, f1 0.511,  prec 0.807, rec 0.373
TRAINING - Epoch 131 Batch 40: loss 0.018432462587952614, f1 0.411,  prec 0.713, rec 0.289
TRAINING - Epoch 131 Batch 50: loss 0.021306883543729782, f1 0.571,  prec 0.644, rec 0.514
VALIDATION - Epoch 131 Batch 0: loss 0.027179071679711342, f1 0.252, prec 0.776, rec 0.151
VALIDATION - Epoch 131 Batch 10: loss 0.02563617378473282, f1 0.301, prec 0.887, rec 0.181
VALIDATION - Epoch 131 Batch 20: loss 0.025425110012292862, f1 0.314, prec 0.895, rec 0.19
TRAINING - Epoch 132 Batch 0: loss 0.021235624328255653, f1 0.367,  prec 0.919, rec 0.229
TRAINING - Epoch 132 Batch 10: loss 0.019143380224704742, f1 0.497,  prec 0.744, rec 0.373
TRAINING - Epoch 132 Batch 20: loss 0.02024809457361698, f1 0.503,  prec 0.758, rec 0.376
TRAINING - Epoch 132 Batch 30: loss 0.019018778577446938, f1 0.522,  prec 0.887, rec 0.37
TRAINING - Epoch 132 Batch 40: loss 0.01998254470527172, f1 0.494,  prec 0.77, rec 0.363
TRAINING - Epoch 132 Batch 50: loss 0.021725643426179886, f1 0.474,  prec 0.768, rec 0.343
VALIDATION - Epoch 132 Batch 0: loss 0.02626888081431389, f1 0.343, prec 0.689, rec 0.229
VALIDATION - Epoch 132 Batch 10: loss 0.02306876890361309, f1 0.33, prec 0.711, rec 0.215
VALIDATION - Epoch 132 Batch 20: loss 0.021680708974599838, f1 0.359, prec 0.775, rec 0.234
TRAINING - Epoch 133 Batch 0: loss 0.018132641911506653, f1 0.448,  prec 0.762, rec 0.317
TRAINING - Epoch 133 Batch 10: loss 0.019510218873620033, f1 0.421,  prec 0.837, rec 0.281
TRAINING - Epoch 133 Batch 20: loss 0.020634889602661133, f1 0.484,  prec 0.746, rec 0.358
TRAINING - Epoch 133 Batch 30: loss 0.020541200414299965, f1 0.503,  prec 0.748, rec 0.378
TRAINING - Epoch 133 Batch 40: loss 0.021039355546236038, f1 0.4,  prec 0.874, rec 0.259
TRAINING - Epoch 133 Batch 50: loss 0.02112654224038124, f1 0.524,  prec 0.786, rec 0.393
VALIDATION - Epoch 133 Batch 0: loss 0.02318612113595009, f1 0.417, prec 0.667, rec 0.303
VALIDATION - Epoch 133 Batch 10: loss 0.022967007011175156, f1 0.347, prec 0.698, rec 0.231
VALIDATION - Epoch 133 Batch 20: loss 0.02366136573255062, f1 0.454, prec 0.684, rec 0.339
TRAINING - Epoch 134 Batch 0: loss 0.019328812137246132, f1 0.509,  prec 0.647, rec 0.419
TRAINING - Epoch 134 Batch 10: loss 0.01908828690648079, f1 0.45,  prec 0.812, rec 0.311
TRAINING - Epoch 134 Batch 20: loss 0.01874467357993126, f1 0.489,  prec 0.769, rec 0.359
TRAINING - Epoch 134 Batch 30: loss 0.020318977534770966, f1 0.483,  prec 0.758, rec 0.355
TRAINING - Epoch 134 Batch 40: loss 0.019717032089829445, f1 0.475,  prec 0.802, rec 0.337
TRAINING - Epoch 134 Batch 50: loss 0.018702149391174316, f1 0.499,  prec 0.742, rec 0.375
VALIDATION - Epoch 134 Batch 0: loss 0.024511026218533516, f1 0.357, prec 0.652, rec 0.246
VALIDATION - Epoch 134 Batch 10: loss 0.022494329139590263, f1 0.382, prec 0.66, rec 0.268
VALIDATION - Epoch 134 Batch 20: loss 0.023809557780623436, f1 0.485, prec 0.856, rec 0.339
TRAINING - Epoch 135 Batch 0: loss 0.017505651339888573, f1 0.495,  prec 0.759, rec 0.368
TRAINING - Epoch 135 Batch 10: loss 0.017911536619067192, f1 0.558,  prec 0.73, rec 0.451
TRAINING - Epoch 135 Batch 20: loss 0.018259622156620026, f1 0.519,  prec 0.77, rec 0.391
TRAINING - Epoch 135 Batch 30: loss 0.020476028323173523, f1 0.413,  prec 0.848, rec 0.273
TRAINING - Epoch 135 Batch 40: loss 0.019044063985347748, f1 0.553,  prec 0.772, rec 0.431
TRAINING - Epoch 135 Batch 50: loss 0.02033066377043724, f1 0.388,  prec 0.79, rec 0.257
VALIDATION - Epoch 135 Batch 0: loss 0.025568244978785515, f1 0.373, prec 0.729, rec 0.251
VALIDATION - Epoch 135 Batch 10: loss 0.023754948750138283, f1 0.407, prec 0.78, rec 0.275
VALIDATION - Epoch 135 Batch 20: loss 0.026203658431768417, f1 0.349, prec 0.732, rec 0.229
TRAINING - Epoch 136 Batch 0: loss 0.020579202100634575, f1 0.442,  prec 0.816, rec 0.303
TRAINING - Epoch 136 Batch 10: loss 0.018166055902838707, f1 0.532,  prec 0.705, rec 0.427
TRAINING - Epoch 136 Batch 20: loss 0.017533166334033012, f1 0.444,  prec 0.694, rec 0.326
TRAINING - Epoch 136 Batch 30: loss 0.018524788320064545, f1 0.478,  prec 0.742, rec 0.352
TRAINING - Epoch 136 Batch 40: loss 0.018958933651447296, f1 0.478,  prec 0.742, rec 0.353
TRAINING - Epoch 136 Batch 50: loss 0.019886111840605736, f1 0.548,  prec 0.779, rec 0.423
VALIDATION - Epoch 136 Batch 0: loss 0.02854226715862751, f1 0.373, prec 0.75, rec 0.248
VALIDATION - Epoch 136 Batch 10: loss 0.023740461096167564, f1 0.396, prec 0.763, rec 0.267
VALIDATION - Epoch 136 Batch 20: loss 0.02785228192806244, f1 0.373, prec 0.819, rec 0.241
TRAINING - Epoch 137 Batch 0: loss 0.019772369414567947, f1 0.441,  prec 0.765, rec 0.31
TRAINING - Epoch 137 Batch 10: loss 0.02007225714623928, f1 0.543,  prec 0.781, rec 0.416
TRAINING - Epoch 137 Batch 20: loss 0.01633336767554283, f1 0.572,  prec 0.784, rec 0.45
TRAINING - Epoch 137 Batch 30: loss 0.018450800329446793, f1 0.532,  prec 0.776, rec 0.404
TRAINING - Epoch 137 Batch 40: loss 0.018486402928829193, f1 0.536,  prec 0.77, rec 0.411
TRAINING - Epoch 137 Batch 50: loss 0.017706166952848434, f1 0.521,  prec 0.772, rec 0.394
VALIDATION - Epoch 137 Batch 0: loss 0.0225604809820652, f1 0.49, prec 0.635, rec 0.399
VALIDATION - Epoch 137 Batch 10: loss 0.02659226767718792, f1 0.461, prec 0.641, rec 0.36
VALIDATION - Epoch 137 Batch 20: loss 0.023654062300920486, f1 0.481, prec 0.675, rec 0.373
TRAINING - Epoch 138 Batch 0: loss 0.019495541229844093, f1 0.533,  prec 0.63, rec 0.462
TRAINING - Epoch 138 Batch 10: loss 0.018593810498714447, f1 0.511,  prec 0.702, rec 0.402
TRAINING - Epoch 138 Batch 20: loss 0.025796128436923027, f1 0.399,  prec 0.835, rec 0.262
TRAINING - Epoch 138 Batch 30: loss 0.01866287738084793, f1 0.544,  prec 0.704, rec 0.443
TRAINING - Epoch 138 Batch 40: loss 0.017841119319200516, f1 0.497,  prec 0.76, rec 0.369
TRAINING - Epoch 138 Batch 50: loss 0.01858198270201683, f1 0.519,  prec 0.782, rec 0.388
VALIDATION - Epoch 138 Batch 0: loss 0.023969797417521477, f1 0.44, prec 0.814, rec 0.302
VALIDATION - Epoch 138 Batch 10: loss 0.022292133420705795, f1 0.334, prec 0.688, rec 0.221
VALIDATION - Epoch 138 Batch 20: loss 0.0248444564640522, f1 0.396, prec 0.724, rec 0.272
TRAINING - Epoch 139 Batch 0: loss 0.01751694642007351, f1 0.425,  prec 0.705, rec 0.305
TRAINING - Epoch 139 Batch 10: loss 0.021731657907366753, f1 0.528,  prec 0.677, rec 0.433
TRAINING - Epoch 139 Batch 20: loss 0.018911905586719513, f1 0.441,  prec 0.852, rec 0.298
TRAINING - Epoch 139 Batch 30: loss 0.017729783430695534, f1 0.474,  prec 0.794, rec 0.337
TRAINING - Epoch 139 Batch 40: loss 0.01925204135477543, f1 0.517,  prec 0.731, rec 0.4
TRAINING - Epoch 139 Batch 50: loss 0.02175522968173027, f1 0.471,  prec 0.674, rec 0.362
VALIDATION - Epoch 139 Batch 0: loss 0.026886051520705223, f1 0.228, prec 0.841, rec 0.132
VALIDATION - Epoch 139 Batch 10: loss 0.02641783095896244, f1 0.268, prec 0.872, rec 0.158
VALIDATION - Epoch 139 Batch 20: loss 0.025409528985619545, f1 0.31, prec 0.922, rec 0.187
TRAINING - Epoch 140 Batch 0: loss 0.02002613991498947, f1 0.34,  prec 0.961, rec 0.207
TRAINING - Epoch 140 Batch 10: loss 0.017457691952586174, f1 0.599,  prec 0.811, rec 0.475
TRAINING - Epoch 140 Batch 20: loss 0.018855271860957146, f1 0.464,  prec 0.792, rec 0.328
TRAINING - Epoch 140 Batch 30: loss 0.019009197130799294, f1 0.553,  prec 0.764, rec 0.433
TRAINING - Epoch 140 Batch 40: loss 0.020028134807944298, f1 0.523,  prec 0.748, rec 0.402
TRAINING - Epoch 140 Batch 50: loss 0.02401665411889553, f1 0.383,  prec 0.707, rec 0.262
VALIDATION - Epoch 140 Batch 0: loss 0.028455521911382675, f1 0.338, prec 0.779, rec 0.216
VALIDATION - Epoch 140 Batch 10: loss 0.023226236924529076, f1 0.366, prec 0.784, rec 0.239
VALIDATION - Epoch 140 Batch 20: loss 0.023377591744065285, f1 0.365, prec 0.8, rec 0.236
TRAINING - Epoch 141 Batch 0: loss 0.01783420518040657, f1 0.488,  prec 0.838, rec 0.344
TRAINING - Epoch 141 Batch 10: loss 0.019090836867690086, f1 0.508,  prec 0.602, rec 0.439
TRAINING - Epoch 141 Batch 20: loss 0.019013522192835808, f1 0.517,  prec 0.85, rec 0.371
TRAINING - Epoch 141 Batch 30: loss 0.021255843341350555, f1 0.446,  prec 0.895, rec 0.297
TRAINING - Epoch 141 Batch 40: loss 0.020703937858343124, f1 0.495,  prec 0.652, rec 0.399
TRAINING - Epoch 141 Batch 50: loss 0.01867217756807804, f1 0.535,  prec 0.727, rec 0.423
VALIDATION - Epoch 141 Batch 0: loss 0.02299528941512108, f1 0.413, prec 0.735, rec 0.287
VALIDATION - Epoch 141 Batch 10: loss 0.023125896230340004, f1 0.391, prec 0.775, rec 0.261
VALIDATION - Epoch 141 Batch 20: loss 0.022278588265180588, f1 0.385, prec 0.688, rec 0.267
TRAINING - Epoch 142 Batch 0: loss 0.01845504902303219, f1 0.5,  prec 0.727, rec 0.381
TRAINING - Epoch 142 Batch 10: loss 0.020478002727031708, f1 0.451,  prec 0.695, rec 0.333
TRAINING - Epoch 142 Batch 20: loss 0.019929004833102226, f1 0.571,  prec 0.655, rec 0.506
TRAINING - Epoch 142 Batch 30: loss 0.016673225909471512, f1 0.423,  prec 0.835, rec 0.283
TRAINING - Epoch 142 Batch 40: loss 0.01945970579981804, f1 0.531,  prec 0.702, rec 0.426
TRAINING - Epoch 142 Batch 50: loss 0.01935369335114956, f1 0.567,  prec 0.71, rec 0.472
VALIDATION - Epoch 142 Batch 0: loss 0.02141053043305874, f1 0.475, prec 0.717, rec 0.355
VALIDATION - Epoch 142 Batch 10: loss 0.024304067716002464, f1 0.437, prec 0.701, rec 0.318
VALIDATION - Epoch 142 Batch 20: loss 0.024770589545369148, f1 0.416, prec 0.643, rec 0.308
TRAINING - Epoch 143 Batch 0: loss 0.020576953887939453, f1 0.571,  prec 0.719, rec 0.473
TRAINING - Epoch 143 Batch 10: loss 0.02309722639620304, f1 0.394,  prec 0.824, rec 0.259
TRAINING - Epoch 143 Batch 20: loss 0.019397294148802757, f1 0.494,  prec 0.742, rec 0.371
TRAINING - Epoch 143 Batch 30: loss 0.01878662221133709, f1 0.452,  prec 0.759, rec 0.322
TRAINING - Epoch 143 Batch 40: loss 0.01741473376750946, f1 0.565,  prec 0.797, rec 0.438
TRAINING - Epoch 143 Batch 50: loss 0.019887741655111313, f1 0.487,  prec 0.767, rec 0.357
VALIDATION - Epoch 143 Batch 0: loss 0.02444489672780037, f1 0.378, prec 0.723, rec 0.256
VALIDATION - Epoch 143 Batch 10: loss 0.023285511881113052, f1 0.386, prec 0.779, rec 0.257
VALIDATION - Epoch 143 Batch 20: loss 0.022537386044859886, f1 0.388, prec 0.742, rec 0.262
TRAINING - Epoch 144 Batch 0: loss 0.01890971139073372, f1 0.441,  prec 0.792, rec 0.305
TRAINING - Epoch 144 Batch 10: loss 0.016550585627555847, f1 0.525,  prec 0.787, rec 0.393
TRAINING - Epoch 144 Batch 20: loss 0.02175324223935604, f1 0.326,  prec 0.72, rec 0.211
TRAINING - Epoch 144 Batch 30: loss 0.01890195906162262, f1 0.563,  prec 0.723, rec 0.461
TRAINING - Epoch 144 Batch 40: loss 0.02246917225420475, f1 0.431,  prec 0.824, rec 0.292
TRAINING - Epoch 144 Batch 50: loss 0.02082555927336216, f1 0.532,  prec 0.646, rec 0.452
VALIDATION - Epoch 144 Batch 0: loss 0.0233610812574625, f1 0.424, prec 0.828, rec 0.285
VALIDATION - Epoch 144 Batch 10: loss 0.024690331891179085, f1 0.373, prec 0.819, rec 0.241
VALIDATION - Epoch 144 Batch 20: loss 0.020402230322360992, f1 0.465, prec 0.857, rec 0.319
TRAINING - Epoch 145 Batch 0: loss 0.020658647641539574, f1 0.47,  prec 0.74, rec 0.344
TRAINING - Epoch 145 Batch 10: loss 0.018742937594652176, f1 0.554,  prec 0.669, rec 0.473
TRAINING - Epoch 145 Batch 20: loss 0.019509803503751755, f1 0.497,  prec 0.71, rec 0.383
TRAINING - Epoch 145 Batch 30: loss 0.01850833371281624, f1 0.556,  prec 0.781, rec 0.431
TRAINING - Epoch 145 Batch 40: loss 0.017917899414896965, f1 0.552,  prec 0.697, rec 0.456
TRAINING - Epoch 145 Batch 50: loss 0.016160104423761368, f1 0.483,  prec 0.895, rec 0.33
VALIDATION - Epoch 145 Batch 0: loss 0.02484484389424324, f1 0.356, prec 0.659, rec 0.244
VALIDATION - Epoch 145 Batch 10: loss 0.025666242465376854, f1 0.472, prec 0.754, rec 0.343
VALIDATION - Epoch 145 Batch 20: loss 0.02558913640677929, f1 0.424, prec 0.722, rec 0.3
TRAINING - Epoch 146 Batch 0: loss 0.018927371129393578, f1 0.524,  prec 0.739, rec 0.406
TRAINING - Epoch 146 Batch 10: loss 0.01685435324907303, f1 0.575,  prec 0.767, rec 0.46
TRAINING - Epoch 146 Batch 20: loss 0.018498826771974564, f1 0.545,  prec 0.78, rec 0.418
TRAINING - Epoch 146 Batch 30: loss 0.016910208389163017, f1 0.503,  prec 0.69, rec 0.396
TRAINING - Epoch 146 Batch 40: loss 0.018200427293777466, f1 0.481,  prec 0.891, rec 0.329
TRAINING - Epoch 146 Batch 50: loss 0.019756624475121498, f1 0.543,  prec 0.864, rec 0.396
VALIDATION - Epoch 146 Batch 0: loss 0.023724306374788284, f1 0.43, prec 0.706, rec 0.309
VALIDATION - Epoch 146 Batch 10: loss 0.023243341594934464, f1 0.431, prec 0.78, rec 0.298
VALIDATION - Epoch 146 Batch 20: loss 0.022517768666148186, f1 0.48, prec 0.777, rec 0.347
TRAINING - Epoch 147 Batch 0: loss 0.018233701586723328, f1 0.553,  prec 0.723, rec 0.448
TRAINING - Epoch 147 Batch 10: loss 0.017862260341644287, f1 0.489,  prec 0.821, rec 0.348
TRAINING - Epoch 147 Batch 20: loss 0.017804553732275963, f1 0.461,  prec 0.949, rec 0.305
TRAINING - Epoch 147 Batch 30: loss 0.019956074655056, f1 0.52,  prec 0.766, rec 0.394
TRAINING - Epoch 147 Batch 40: loss 0.016921693459153175, f1 0.53,  prec 0.795, rec 0.398
TRAINING - Epoch 147 Batch 50: loss 0.01748012565076351, f1 0.43,  prec 0.833, rec 0.29
VALIDATION - Epoch 147 Batch 0: loss 0.025239769369363785, f1 0.482, prec 0.736, rec 0.358
VALIDATION - Epoch 147 Batch 10: loss 0.019797708839178085, f1 0.528, prec 0.733, rec 0.413
VALIDATION - Epoch 147 Batch 20: loss 0.020602833479642868, f1 0.488, prec 0.692, rec 0.377
TRAINING - Epoch 148 Batch 0: loss 0.018219292163848877, f1 0.595,  prec 0.716, rec 0.51
TRAINING - Epoch 148 Batch 10: loss 0.01891525462269783, f1 0.51,  prec 0.813, rec 0.372
TRAINING - Epoch 148 Batch 20: loss 0.019833428785204887, f1 0.527,  prec 0.71, rec 0.42
TRAINING - Epoch 148 Batch 30: loss 0.01950978673994541, f1 0.514,  prec 0.734, rec 0.395
TRAINING - Epoch 148 Batch 40: loss 0.018803797662258148, f1 0.507,  prec 0.679, rec 0.405
TRAINING - Epoch 148 Batch 50: loss 0.022657986730337143, f1 0.435,  prec 0.867, rec 0.29
VALIDATION - Epoch 148 Batch 0: loss 0.02370510809123516, f1 0.412, prec 0.75, rec 0.284
VALIDATION - Epoch 148 Batch 10: loss 0.026543976739048958, f1 0.424, prec 0.833, rec 0.284
VALIDATION - Epoch 148 Batch 20: loss 0.02392822690308094, f1 0.376, prec 0.793, rec 0.246
TRAINING - Epoch 149 Batch 0: loss 0.01795188896358013, f1 0.5,  prec 0.803, rec 0.363
TRAINING - Epoch 149 Batch 10: loss 0.016836849972605705, f1 0.503,  prec 0.724, rec 0.386
TRAINING - Epoch 149 Batch 20: loss 0.019482672214508057, f1 0.508,  prec 0.797, rec 0.373
TRAINING - Epoch 149 Batch 30: loss 0.019641496241092682, f1 0.486,  prec 0.854, rec 0.34
TRAINING - Epoch 149 Batch 40: loss 0.01901993714272976, f1 0.549,  prec 0.611, rec 0.498
TRAINING - Epoch 149 Batch 50: loss 0.02117299661040306, f1 0.462,  prec 0.84, rec 0.318
VALIDATION - Epoch 149 Batch 0: loss 0.023278754204511642, f1 0.402, prec 0.747, rec 0.275
VALIDATION - Epoch 149 Batch 10: loss 0.025610215961933136, f1 0.399, prec 0.694, rec 0.28
VALIDATION - Epoch 149 Batch 20: loss 0.022405561059713364, f1 0.393, prec 0.767, rec 0.264
TRAINING - Epoch 150 Batch 0: loss 0.01503337174654007, f1 0.493,  prec 0.808, rec 0.354
TRAINING - Epoch 150 Batch 10: loss 0.021308163180947304, f1 0.532,  prec 0.615, rec 0.468
TRAINING - Epoch 150 Batch 20: loss 0.01890266314148903, f1 0.501,  prec 0.778, rec 0.37
TRAINING - Epoch 150 Batch 30: loss 0.01905069686472416, f1 0.496,  prec 0.645, rec 0.403
TRAINING - Epoch 150 Batch 40: loss 0.019381098449230194, f1 0.475,  prec 0.792, rec 0.339
TRAINING - Epoch 150 Batch 50: loss 0.020202655345201492, f1 0.558,  prec 0.665, rec 0.48
VALIDATION - Epoch 150 Batch 0: loss 0.020782500505447388, f1 0.522, prec 0.705, rec 0.414
VALIDATION - Epoch 150 Batch 10: loss 0.024206582456827164, f1 0.495, prec 0.705, rec 0.382
VALIDATION - Epoch 150 Batch 20: loss 0.02357175201177597, f1 0.494, prec 0.689, rec 0.385
TRAINING - Epoch 151 Batch 0: loss 0.020499562844634056, f1 0.555,  prec 0.665, rec 0.476
TRAINING - Epoch 151 Batch 10: loss 0.015891699120402336, f1 0.586,  prec 0.849, rec 0.447
TRAINING - Epoch 151 Batch 20: loss 0.021037103608250618, f1 0.539,  prec 0.734, rec 0.426
TRAINING - Epoch 151 Batch 30: loss 0.018511224538087845, f1 0.541,  prec 0.79, rec 0.411
TRAINING - Epoch 151 Batch 40: loss 0.01757143624126911, f1 0.451,  prec 0.812, rec 0.312
TRAINING - Epoch 151 Batch 50: loss 0.018232159316539764, f1 0.574,  prec 0.818, rec 0.442
VALIDATION - Epoch 151 Batch 0: loss 0.020744645968079567, f1 0.465, prec 0.695, rec 0.349
VALIDATION - Epoch 151 Batch 10: loss 0.02377086505293846, f1 0.477, prec 0.726, rec 0.355
VALIDATION - Epoch 151 Batch 20: loss 0.02372543327510357, f1 0.472, prec 0.702, rec 0.355
TRAINING - Epoch 152 Batch 0: loss 0.01705450937151909, f1 0.583,  prec 0.724, rec 0.488
TRAINING - Epoch 152 Batch 10: loss 0.0171851497143507, f1 0.56,  prec 0.783, rec 0.436
TRAINING - Epoch 152 Batch 20: loss 0.017950501292943954, f1 0.393,  prec 0.905, rec 0.251
TRAINING - Epoch 152 Batch 30: loss 0.01928769052028656, f1 0.503,  prec 0.841, rec 0.358
TRAINING - Epoch 152 Batch 40: loss 0.02022908441722393, f1 0.584,  prec 0.717, rec 0.493
TRAINING - Epoch 152 Batch 50: loss 0.017065947875380516, f1 0.5,  prec 0.704, rec 0.388
VALIDATION - Epoch 152 Batch 0: loss 0.020898936316370964, f1 0.484, prec 0.698, rec 0.37
VALIDATION - Epoch 152 Batch 10: loss 0.02106623537838459, f1 0.437, prec 0.703, rec 0.317
VALIDATION - Epoch 152 Batch 20: loss 0.02375185117125511, f1 0.445, prec 0.669, rec 0.333
TRAINING - Epoch 153 Batch 0: loss 0.01970789209008217, f1 0.514,  prec 0.737, rec 0.395
TRAINING - Epoch 153 Batch 10: loss 0.01916079968214035, f1 0.482,  prec 0.711, rec 0.365
TRAINING - Epoch 153 Batch 20: loss 0.01951710134744644, f1 0.475,  prec 0.723, rec 0.354
TRAINING - Epoch 153 Batch 30: loss 0.017855942249298096, f1 0.614,  prec 0.768, rec 0.511
TRAINING - Epoch 153 Batch 40: loss 0.01970241777598858, f1 0.466,  prec 0.895, rec 0.315
TRAINING - Epoch 153 Batch 50: loss 0.01954789087176323, f1 0.541,  prec 0.704, rec 0.439
VALIDATION - Epoch 153 Batch 0: loss 0.02420068345963955, f1 0.403, prec 0.661, rec 0.29
VALIDATION - Epoch 153 Batch 10: loss 0.025249218568205833, f1 0.423, prec 0.692, rec 0.305
VALIDATION - Epoch 153 Batch 20: loss 0.02399587817490101, f1 0.404, prec 0.676, rec 0.289
TRAINING - Epoch 154 Batch 0: loss 0.018686771392822266, f1 0.485,  prec 0.699, rec 0.371
TRAINING - Epoch 154 Batch 10: loss 0.015599001199007034, f1 0.482,  prec 0.857, rec 0.335
TRAINING - Epoch 154 Batch 20: loss 0.02105741947889328, f1 0.581,  prec 0.707, rec 0.494
TRAINING - Epoch 154 Batch 30: loss 0.01783265732228756, f1 0.519,  prec 0.669, rec 0.423
TRAINING - Epoch 154 Batch 40: loss 0.019275283440947533, f1 0.544,  prec 0.815, rec 0.408
TRAINING - Epoch 154 Batch 50: loss 0.018284820020198822, f1 0.574,  prec 0.736, rec 0.471
VALIDATION - Epoch 154 Batch 0: loss 0.024284860119223595, f1 0.425, prec 0.658, rec 0.313
VALIDATION - Epoch 154 Batch 10: loss 0.021288348361849785, f1 0.562, prec 0.738, rec 0.454
VALIDATION - Epoch 154 Batch 20: loss 0.026046162471175194, f1 0.449, prec 0.726, rec 0.325
TRAINING - Epoch 155 Batch 0: loss 0.01909218356013298, f1 0.521,  prec 0.667, rec 0.428
TRAINING - Epoch 155 Batch 10: loss 0.017439253628253937, f1 0.5,  prec 0.783, rec 0.367
TRAINING - Epoch 155 Batch 20: loss 0.017945554107427597, f1 0.561,  prec 0.711, rec 0.463
TRAINING - Epoch 155 Batch 30: loss 0.02142389863729477, f1 0.37,  prec 0.855, rec 0.236
TRAINING - Epoch 155 Batch 40: loss 0.01862618885934353, f1 0.448,  prec 0.768, rec 0.317
TRAINING - Epoch 155 Batch 50: loss 0.015124986879527569, f1 0.583,  prec 0.811, rec 0.455
VALIDATION - Epoch 155 Batch 0: loss 0.026461061090230942, f1 0.46, prec 0.636, rec 0.36
VALIDATION - Epoch 155 Batch 10: loss 0.023697448894381523, f1 0.501, prec 0.646, rec 0.409
VALIDATION - Epoch 155 Batch 20: loss 0.025475438684225082, f1 0.483, prec 0.731, rec 0.361
TRAINING - Epoch 156 Batch 0: loss 0.02030293084681034, f1 0.557,  prec 0.678, rec 0.473
TRAINING - Epoch 156 Batch 10: loss 0.017239367589354515, f1 0.555,  prec 0.77, rec 0.434
TRAINING - Epoch 156 Batch 20: loss 0.016921011731028557, f1 0.475,  prec 0.755, rec 0.346
TRAINING - Epoch 156 Batch 30: loss 0.017904022708535194, f1 0.566,  prec 0.773, rec 0.446
TRAINING - Epoch 156 Batch 40: loss 0.016887962818145752, f1 0.499,  prec 0.75, rec 0.373
TRAINING - Epoch 156 Batch 50: loss 0.01836405135691166, f1 0.551,  prec 0.72, rec 0.446
VALIDATION - Epoch 156 Batch 0: loss 0.02206886000931263, f1 0.428, prec 0.804, rec 0.291
VALIDATION - Epoch 156 Batch 10: loss 0.02253996953368187, f1 0.382, prec 0.848, rec 0.246
VALIDATION - Epoch 156 Batch 20: loss 0.023645635694265366, f1 0.42, prec 0.79, rec 0.286
TRAINING - Epoch 157 Batch 0: loss 0.01866253837943077, f1 0.5,  prec 0.78, rec 0.368
TRAINING - Epoch 157 Batch 10: loss 0.015497301705181599, f1 0.507,  prec 0.79, rec 0.373
TRAINING - Epoch 157 Batch 20: loss 0.018995195627212524, f1 0.563,  prec 0.781, rec 0.44
TRAINING - Epoch 157 Batch 30: loss 0.01957925409078598, f1 0.506,  prec 0.748, rec 0.382
TRAINING - Epoch 157 Batch 40: loss 0.018562432378530502, f1 0.531,  prec 0.719, rec 0.421
TRAINING - Epoch 157 Batch 50: loss 0.01555860135704279, f1 0.627,  prec 0.732, rec 0.548
VALIDATION - Epoch 157 Batch 0: loss 0.022431664168834686, f1 0.512, prec 0.781, rec 0.38
VALIDATION - Epoch 157 Batch 10: loss 0.02474726177752018, f1 0.428, prec 0.658, rec 0.317
VALIDATION - Epoch 157 Batch 20: loss 0.02335827797651291, f1 0.509, prec 0.763, rec 0.381
TRAINING - Epoch 158 Batch 0: loss 0.019031371921300888, f1 0.539,  prec 0.728, rec 0.428
TRAINING - Epoch 158 Batch 10: loss 0.01826704666018486, f1 0.545,  prec 0.703, rec 0.445
TRAINING - Epoch 158 Batch 20: loss 0.017667507752776146, f1 0.495,  prec 0.789, rec 0.361
TRAINING - Epoch 158 Batch 30: loss 0.01795106567442417, f1 0.573,  prec 0.725, rec 0.474
TRAINING - Epoch 158 Batch 40: loss 0.01895028166472912, f1 0.43,  prec 0.691, rec 0.312
TRAINING - Epoch 158 Batch 50: loss 0.01706812158226967, f1 0.525,  prec 0.782, rec 0.395
VALIDATION - Epoch 158 Batch 0: loss 0.025493986904621124, f1 0.392, prec 0.775, rec 0.262
VALIDATION - Epoch 158 Batch 10: loss 0.022158615291118622, f1 0.432, prec 0.788, rec 0.297
VALIDATION - Epoch 158 Batch 20: loss 0.023691697046160698, f1 0.463, prec 0.845, rec 0.319
TRAINING - Epoch 159 Batch 0: loss 0.01885237917304039, f1 0.528,  prec 0.818, rec 0.39
TRAINING - Epoch 159 Batch 10: loss 0.016714956611394882, f1 0.613,  prec 0.714, rec 0.536
TRAINING - Epoch 159 Batch 20: loss 0.021770231425762177, f1 0.505,  prec 0.833, rec 0.362
TRAINING - Epoch 159 Batch 30: loss 0.019445594400167465, f1 0.515,  prec 0.74, rec 0.395
TRAINING - Epoch 159 Batch 40: loss 0.01799391582608223, f1 0.556,  prec 0.724, rec 0.451
TRAINING - Epoch 159 Batch 50: loss 0.01757609099149704, f1 0.615,  prec 0.735, rec 0.529
VALIDATION - Epoch 159 Batch 0: loss 0.0254820603877306, f1 0.432, prec 0.707, rec 0.311
VALIDATION - Epoch 159 Batch 10: loss 0.021667543798685074, f1 0.488, prec 0.726, rec 0.367
VALIDATION - Epoch 159 Batch 20: loss 0.025097830221056938, f1 0.412, prec 0.664, rec 0.299
TRAINING - Epoch 160 Batch 0: loss 0.019377373158931732, f1 0.533,  prec 0.745, rec 0.415
TRAINING - Epoch 160 Batch 10: loss 0.016005512326955795, f1 0.541,  prec 0.75, rec 0.423
TRAINING - Epoch 160 Batch 20: loss 0.01590009033679962, f1 0.521,  prec 0.773, rec 0.393
TRAINING - Epoch 160 Batch 30: loss 0.0199838075786829, f1 0.444,  prec 0.857, rec 0.3
TRAINING - Epoch 160 Batch 40: loss 0.017207149416208267, f1 0.532,  prec 0.761, rec 0.409
TRAINING - Epoch 160 Batch 50: loss 0.02316221222281456, f1 0.4,  prec 0.828, rec 0.264
VALIDATION - Epoch 160 Batch 0: loss 0.02281799539923668, f1 0.444, prec 0.778, rec 0.31
VALIDATION - Epoch 160 Batch 10: loss 0.023281732574105263, f1 0.393, prec 0.805, rec 0.26
VALIDATION - Epoch 160 Batch 20: loss 0.023165447637438774, f1 0.376, prec 0.739, rec 0.252
TRAINING - Epoch 161 Batch 0: loss 0.017077654600143433, f1 0.505,  prec 0.885, rec 0.354
TRAINING - Epoch 161 Batch 10: loss 0.01758071780204773, f1 0.552,  prec 0.736, rec 0.441
TRAINING - Epoch 161 Batch 20: loss 0.01707879826426506, f1 0.55,  prec 0.782, rec 0.424
TRAINING - Epoch 161 Batch 30: loss 0.016104400157928467, f1 0.613,  prec 0.717, rec 0.534
TRAINING - Epoch 161 Batch 40: loss 0.017982611432671547, f1 0.59,  prec 0.809, rec 0.464
TRAINING - Epoch 161 Batch 50: loss 0.016571680083870888, f1 0.525,  prec 0.855, rec 0.379
VALIDATION - Epoch 161 Batch 0: loss 0.02498696558177471, f1 0.535, prec 0.698, rec 0.434
VALIDATION - Epoch 161 Batch 10: loss 0.021738829091191292, f1 0.548, prec 0.764, rec 0.427
VALIDATION - Epoch 161 Batch 20: loss 0.02177141048014164, f1 0.507, prec 0.775, rec 0.377
TRAINING - Epoch 162 Batch 0: loss 0.017565535381436348, f1 0.6,  prec 0.711, rec 0.519
TRAINING - Epoch 162 Batch 10: loss 0.018065225332975388, f1 0.484,  prec 0.709, rec 0.368
TRAINING - Epoch 162 Batch 20: loss 0.017721857875585556, f1 0.571,  prec 0.742, rec 0.464
TRAINING - Epoch 162 Batch 30: loss 0.01653975620865822, f1 0.556,  prec 0.797, rec 0.427
TRAINING - Epoch 162 Batch 40: loss 0.0172940194606781, f1 0.575,  prec 0.723, rec 0.478
TRAINING - Epoch 162 Batch 50: loss 0.017076341435313225, f1 0.532,  prec 0.66, rec 0.445
VALIDATION - Epoch 162 Batch 0: loss 0.022104578092694283, f1 0.517, prec 0.711, rec 0.406
VALIDATION - Epoch 162 Batch 10: loss 0.02357260324060917, f1 0.51, prec 0.71, rec 0.399
VALIDATION - Epoch 162 Batch 20: loss 0.02519763447344303, f1 0.467, prec 0.617, rec 0.376
TRAINING - Epoch 163 Batch 0: loss 0.019678553566336632, f1 0.557,  prec 0.726, rec 0.452
TRAINING - Epoch 163 Batch 10: loss 0.01753116399049759, f1 0.5,  prec 0.694, rec 0.391
TRAINING - Epoch 163 Batch 20: loss 0.018260885030031204, f1 0.533,  prec 0.68, rec 0.439
TRAINING - Epoch 163 Batch 30: loss 0.019142478704452515, f1 0.515,  prec 0.779, rec 0.385
TRAINING - Epoch 163 Batch 40: loss 0.017791954800486565, f1 0.529,  prec 0.795, rec 0.396
TRAINING - Epoch 163 Batch 50: loss 0.017828188836574554, f1 0.586,  prec 0.713, rec 0.498
VALIDATION - Epoch 163 Batch 0: loss 0.02340741641819477, f1 0.435, prec 0.632, rec 0.332
VALIDATION - Epoch 163 Batch 10: loss 0.02432660199701786, f1 0.457, prec 0.626, rec 0.359
VALIDATION - Epoch 163 Batch 20: loss 0.02388865128159523, f1 0.465, prec 0.617, rec 0.373
TRAINING - Epoch 164 Batch 0: loss 0.018241262063384056, f1 0.585,  prec 0.685, rec 0.511
TRAINING - Epoch 164 Batch 10: loss 0.020061057060956955, f1 0.512,  prec 0.721, rec 0.397
TRAINING - Epoch 164 Batch 20: loss 0.015850074589252472, f1 0.524,  prec 0.75, rec 0.402
TRAINING - Epoch 164 Batch 30: loss 0.018456853926181793, f1 0.597,  prec 0.686, rec 0.528
TRAINING - Epoch 164 Batch 40: loss 0.01554393582046032, f1 0.524,  prec 0.731, rec 0.408
TRAINING - Epoch 164 Batch 50: loss 0.017425628378987312, f1 0.539,  prec 0.8, rec 0.406
VALIDATION - Epoch 164 Batch 0: loss 0.024469491094350815, f1 0.485, prec 0.752, rec 0.358
VALIDATION - Epoch 164 Batch 10: loss 0.025022367015480995, f1 0.456, prec 0.746, rec 0.328
VALIDATION - Epoch 164 Batch 20: loss 0.025424711406230927, f1 0.45, prec 0.737, rec 0.323
TRAINING - Epoch 165 Batch 0: loss 0.014543742872774601, f1 0.533,  prec 0.769, rec 0.408
TRAINING - Epoch 165 Batch 10: loss 0.019872993230819702, f1 0.532,  prec 0.827, rec 0.392
TRAINING - Epoch 165 Batch 20: loss 0.018765797838568687, f1 0.516,  prec 0.72, rec 0.401
TRAINING - Epoch 165 Batch 30: loss 0.017828647047281265, f1 0.557,  prec 0.747, rec 0.444
TRAINING - Epoch 165 Batch 40: loss 0.017040206119418144, f1 0.537,  prec 0.777, rec 0.41
TRAINING - Epoch 165 Batch 50: loss 0.016647329553961754, f1 0.625,  prec 0.804, rec 0.511
VALIDATION - Epoch 165 Batch 0: loss 0.025325393304228783, f1 0.468, prec 0.723, rec 0.346
VALIDATION - Epoch 165 Batch 10: loss 0.021068383008241653, f1 0.471, prec 0.775, rec 0.339
VALIDATION - Epoch 165 Batch 20: loss 0.02285224013030529, f1 0.438, prec 0.718, rec 0.315
TRAINING - Epoch 166 Batch 0: loss 0.0164702907204628, f1 0.57,  prec 0.766, rec 0.454
TRAINING - Epoch 166 Batch 10: loss 0.013935417868196964, f1 0.617,  prec 0.788, rec 0.506
TRAINING - Epoch 166 Batch 20: loss 0.015987439081072807, f1 0.583,  prec 0.784, rec 0.463
TRAINING - Epoch 166 Batch 30: loss 0.016966264694929123, f1 0.609,  prec 0.722, rec 0.527
TRAINING - Epoch 166 Batch 40: loss 0.020081205293536186, f1 0.499,  prec 0.785, rec 0.366
TRAINING - Epoch 166 Batch 50: loss 0.017049599438905716, f1 0.584,  prec 0.642, rec 0.535
VALIDATION - Epoch 166 Batch 0: loss 0.02193998172879219, f1 0.443, prec 0.778, rec 0.31
VALIDATION - Epoch 166 Batch 10: loss 0.024424932897090912, f1 0.401, prec 0.618, rec 0.297
VALIDATION - Epoch 166 Batch 20: loss 0.02199420891702175, f1 0.487, prec 0.699, rec 0.373
TRAINING - Epoch 167 Batch 0: loss 0.016394110396504402, f1 0.569,  prec 0.769, rec 0.452
TRAINING - Epoch 167 Batch 10: loss 0.01630687527358532, f1 0.522,  prec 0.689, rec 0.42
TRAINING - Epoch 167 Batch 20: loss 0.016109876334667206, f1 0.626,  prec 0.771, rec 0.527
TRAINING - Epoch 167 Batch 30: loss 0.018224269151687622, f1 0.507,  prec 0.858, rec 0.36
TRAINING - Epoch 167 Batch 40: loss 0.01730990782380104, f1 0.58,  prec 0.774, rec 0.463
TRAINING - Epoch 167 Batch 50: loss 0.014911407604813576, f1 0.583,  prec 0.732, rec 0.485
VALIDATION - Epoch 167 Batch 0: loss 0.023255346342921257, f1 0.467, prec 0.688, rec 0.353
VALIDATION - Epoch 167 Batch 10: loss 0.022975362837314606, f1 0.504, prec 0.748, rec 0.379
VALIDATION - Epoch 167 Batch 20: loss 0.026568057015538216, f1 0.47, prec 0.72, rec 0.349
TRAINING - Epoch 168 Batch 0: loss 0.0162657443434, f1 0.593,  prec 0.781, rec 0.478
TRAINING - Epoch 168 Batch 10: loss 0.016586272045969963, f1 0.5,  prec 0.736, rec 0.378
TRAINING - Epoch 168 Batch 20: loss 0.016263265162706375, f1 0.549,  prec 0.68, rec 0.46
TRAINING - Epoch 168 Batch 30: loss 0.016428617760539055, f1 0.566,  prec 0.76, rec 0.451
TRAINING - Epoch 168 Batch 40: loss 0.015335677191615105, f1 0.59,  prec 0.724, rec 0.498
TRAINING - Epoch 168 Batch 50: loss 0.016105107963085175, f1 0.556,  prec 0.819, rec 0.421
VALIDATION - Epoch 168 Batch 0: loss 0.024621624499559402, f1 0.49, prec 0.665, rec 0.388
VALIDATION - Epoch 168 Batch 10: loss 0.024046314880251884, f1 0.441, prec 0.69, rec 0.324
VALIDATION - Epoch 168 Batch 20: loss 0.024110114201903343, f1 0.462, prec 0.608, rec 0.373
TRAINING - Epoch 169 Batch 0: loss 0.019301844760775566, f1 0.558,  prec 0.658, rec 0.484
TRAINING - Epoch 169 Batch 10: loss 0.017873108386993408, f1 0.544,  prec 0.736, rec 0.431
TRAINING - Epoch 169 Batch 20: loss 0.01832643710076809, f1 0.565,  prec 0.701, rec 0.474
TRAINING - Epoch 169 Batch 30: loss 0.019811373203992844, f1 0.538,  prec 0.685, rec 0.443
TRAINING - Epoch 169 Batch 40: loss 0.017474157735705376, f1 0.499,  prec 0.71, rec 0.384
TRAINING - Epoch 169 Batch 50: loss 0.015483253635466099, f1 0.534,  prec 0.814, rec 0.398
VALIDATION - Epoch 169 Batch 0: loss 0.027040639892220497, f1 0.436, prec 0.784, rec 0.302
VALIDATION - Epoch 169 Batch 10: loss 0.026444146409630775, f1 0.439, prec 0.835, rec 0.298
VALIDATION - Epoch 169 Batch 20: loss 0.02899802476167679, f1 0.374, prec 0.739, rec 0.25
TRAINING - Epoch 170 Batch 0: loss 0.015241582877933979, f1 0.597,  prec 0.794, rec 0.479
TRAINING - Epoch 170 Batch 10: loss 0.017270883545279503, f1 0.586,  prec 0.748, rec 0.482
TRAINING - Epoch 170 Batch 20: loss 0.015955554321408272, f1 0.513,  prec 0.837, rec 0.37
TRAINING - Epoch 170 Batch 30: loss 0.0187044870108366, f1 0.545,  prec 0.65, rec 0.47
TRAINING - Epoch 170 Batch 40: loss 0.016753394156694412, f1 0.608,  prec 0.771, rec 0.502
TRAINING - Epoch 170 Batch 50: loss 0.016424309462308884, f1 0.602,  prec 0.779, rec 0.49
VALIDATION - Epoch 170 Batch 0: loss 0.025238804519176483, f1 0.492, prec 0.766, rec 0.362
VALIDATION - Epoch 170 Batch 10: loss 0.028470478951931, f1 0.402, prec 0.748, rec 0.275
VALIDATION - Epoch 170 Batch 20: loss 0.02070384845137596, f1 0.462, prec 0.729, rec 0.339
TRAINING - Epoch 171 Batch 0: loss 0.015853259712457657, f1 0.559,  prec 0.835, rec 0.421
TRAINING - Epoch 171 Batch 10: loss 0.01906208135187626, f1 0.552,  prec 0.719, rec 0.448
TRAINING - Epoch 171 Batch 20: loss 0.01831463724374771, f1 0.524,  prec 0.656, rec 0.436
TRAINING - Epoch 171 Batch 30: loss 0.01691918820142746, f1 0.504,  prec 0.719, rec 0.388
TRAINING - Epoch 171 Batch 40: loss 0.016246432438492775, f1 0.614,  prec 0.72, rec 0.535
TRAINING - Epoch 171 Batch 50: loss 0.019354544579982758, f1 0.585,  prec 0.718, rec 0.493
VALIDATION - Epoch 171 Batch 0: loss 0.02749844826757908, f1 0.402, prec 0.657, rec 0.29
VALIDATION - Epoch 171 Batch 10: loss 0.023104839026927948, f1 0.467, prec 0.745, rec 0.34
VALIDATION - Epoch 171 Batch 20: loss 0.02433883585035801, f1 0.431, prec 0.825, rec 0.292
TRAINING - Epoch 172 Batch 0: loss 0.016252949833869934, f1 0.545,  prec 0.832, rec 0.405
TRAINING - Epoch 172 Batch 10: loss 0.020010963082313538, f1 0.484,  prec 0.731, rec 0.362
TRAINING - Epoch 172 Batch 20: loss 0.016775406897068024, f1 0.453,  prec 0.708, rec 0.333
TRAINING - Epoch 172 Batch 30: loss 0.014943655580282211, f1 0.626,  prec 0.738, rec 0.543
TRAINING - Epoch 172 Batch 40: loss 0.01610700413584709, f1 0.665,  prec 0.78, rec 0.58
TRAINING - Epoch 172 Batch 50: loss 0.016632623970508575, f1 0.504,  prec 0.825, rec 0.363
VALIDATION - Epoch 172 Batch 0: loss 0.024263259023427963, f1 0.391, prec 0.711, rec 0.27
VALIDATION - Epoch 172 Batch 10: loss 0.027449848130345345, f1 0.354, prec 0.787, rec 0.229
VALIDATION - Epoch 172 Batch 20: loss 0.027084607630968094, f1 0.402, prec 0.783, rec 0.271
TRAINING - Epoch 173 Batch 0: loss 0.01596476510167122, f1 0.554,  prec 0.905, rec 0.399
TRAINING - Epoch 173 Batch 10: loss 0.018901657313108444, f1 0.605,  prec 0.697, rec 0.535
TRAINING - Epoch 173 Batch 20: loss 0.020563757047057152, f1 0.429,  prec 0.75, rec 0.3
TRAINING - Epoch 173 Batch 30: loss 0.017110660672187805, f1 0.56,  prec 0.663, rec 0.484
TRAINING - Epoch 173 Batch 40: loss 0.023621197789907455, f1 0.492,  prec 0.835, rec 0.349
TRAINING - Epoch 173 Batch 50: loss 0.019585011526942253, f1 0.568,  prec 0.656, rec 0.5
VALIDATION - Epoch 173 Batch 0: loss 0.025573011487722397, f1 0.366, prec 0.677, rec 0.251
VALIDATION - Epoch 173 Batch 10: loss 0.021719815209507942, f1 0.427, prec 0.806, rec 0.291
VALIDATION - Epoch 173 Batch 20: loss 0.026537872850894928, f1 0.4, prec 0.809, rec 0.266
TRAINING - Epoch 174 Batch 0: loss 0.018245544284582138, f1 0.538,  prec 0.8, rec 0.406
TRAINING - Epoch 174 Batch 10: loss 0.016560565680265427, f1 0.606,  prec 0.782, rec 0.494
TRAINING - Epoch 174 Batch 20: loss 0.017955206334590912, f1 0.551,  prec 0.784, rec 0.425
TRAINING - Epoch 174 Batch 30: loss 0.015780596062541008, f1 0.493,  prec 0.738, rec 0.37
TRAINING - Epoch 174 Batch 40: loss 0.015544099733233452, f1 0.569,  prec 0.758, rec 0.456
TRAINING - Epoch 174 Batch 50: loss 0.017115818336606026, f1 0.52,  prec 0.892, rec 0.367
VALIDATION - Epoch 174 Batch 0: loss 0.0254663173109293, f1 0.439, prec 0.763, rec 0.308
VALIDATION - Epoch 174 Batch 10: loss 0.02454216592013836, f1 0.447, prec 0.743, rec 0.32
VALIDATION - Epoch 174 Batch 20: loss 0.02419457770884037, f1 0.392, prec 0.756, rec 0.265
TRAINING - Epoch 175 Batch 0: loss 0.01820027269423008, f1 0.504,  prec 0.752, rec 0.379
TRAINING - Epoch 175 Batch 10: loss 0.015363280661404133, f1 0.579,  prec 0.71, rec 0.489
TRAINING - Epoch 175 Batch 20: loss 0.016445418819785118, f1 0.61,  prec 0.715, rec 0.531
TRAINING - Epoch 175 Batch 30: loss 0.016260920092463493, f1 0.622,  prec 0.794, rec 0.511
TRAINING - Epoch 175 Batch 40: loss 0.018139924854040146, f1 0.509,  prec 0.742, rec 0.388
TRAINING - Epoch 175 Batch 50: loss 0.017432237043976784, f1 0.556,  prec 0.616, rec 0.506
VALIDATION - Epoch 175 Batch 0: loss 0.02423141710460186, f1 0.44, prec 0.615, rec 0.342
VALIDATION - Epoch 175 Batch 10: loss 0.024956632405519485, f1 0.469, prec 0.66, rec 0.364
VALIDATION - Epoch 175 Batch 20: loss 0.027328914031386375, f1 0.429, prec 0.599, rec 0.335
TRAINING - Epoch 176 Batch 0: loss 0.014577869325876236, f1 0.606,  prec 0.726, rec 0.52
TRAINING - Epoch 176 Batch 10: loss 0.01667911373078823, f1 0.538,  prec 0.816, rec 0.402
TRAINING - Epoch 176 Batch 20: loss 0.016146432608366013, f1 0.558,  prec 0.679, rec 0.473
TRAINING - Epoch 176 Batch 30: loss 0.017233015969395638, f1 0.539,  prec 0.708, rec 0.435
TRAINING - Epoch 176 Batch 40: loss 0.01836782693862915, f1 0.579,  prec 0.724, rec 0.482
TRAINING - Epoch 176 Batch 50: loss 0.014360572211444378, f1 0.583,  prec 0.808, rec 0.457
VALIDATION - Epoch 176 Batch 0: loss 0.02715924382209778, f1 0.452, prec 0.746, rec 0.324
VALIDATION - Epoch 176 Batch 10: loss 0.022568615153431892, f1 0.456, prec 0.733, rec 0.331
VALIDATION - Epoch 176 Batch 20: loss 0.0277382992208004, f1 0.44, prec 0.706, rec 0.319
TRAINING - Epoch 177 Batch 0: loss 0.015988824889063835, f1 0.533,  prec 0.748, rec 0.414
TRAINING - Epoch 177 Batch 10: loss 0.01683836802840233, f1 0.569,  prec 0.746, rec 0.46
TRAINING - Epoch 177 Batch 20: loss 0.017099468037486076, f1 0.587,  prec 0.661, rec 0.528
TRAINING - Epoch 177 Batch 30: loss 0.014759217388927937, f1 0.561,  prec 0.857, rec 0.417
TRAINING - Epoch 177 Batch 40: loss 0.018305329605937004, f1 0.571,  prec 0.743, rec 0.464
TRAINING - Epoch 177 Batch 50: loss 0.018968358635902405, f1 0.516,  prec 0.757, rec 0.392
VALIDATION - Epoch 177 Batch 0: loss 0.025656990706920624, f1 0.442, prec 0.641, rec 0.337
VALIDATION - Epoch 177 Batch 10: loss 0.019864602014422417, f1 0.563, prec 0.75, rec 0.451
VALIDATION - Epoch 177 Batch 20: loss 0.025334756821393967, f1 0.486, prec 0.738, rec 0.363
TRAINING - Epoch 178 Batch 0: loss 0.015080925077199936, f1 0.62,  prec 0.723, rec 0.543
TRAINING - Epoch 178 Batch 10: loss 0.01568588614463806, f1 0.563,  prec 0.689, rec 0.476
TRAINING - Epoch 178 Batch 20: loss 0.02004617266356945, f1 0.539,  prec 0.782, rec 0.411
TRAINING - Epoch 178 Batch 30: loss 0.017409304156899452, f1 0.608,  prec 0.668, rec 0.557
TRAINING - Epoch 178 Batch 40: loss 0.017111698165535927, f1 0.611,  prec 0.71, rec 0.537
TRAINING - Epoch 178 Batch 50: loss 0.018843762576580048, f1 0.606,  prec 0.692, rec 0.539
VALIDATION - Epoch 178 Batch 0: loss 0.022435108199715614, f1 0.474, prec 0.65, rec 0.373
VALIDATION - Epoch 178 Batch 10: loss 0.02268611639738083, f1 0.421, prec 0.696, rec 0.302
VALIDATION - Epoch 178 Batch 20: loss 0.025009537115693092, f1 0.464, prec 0.701, rec 0.347
TRAINING - Epoch 179 Batch 0: loss 0.016076451167464256, f1 0.577,  prec 0.736, rec 0.474
TRAINING - Epoch 179 Batch 10: loss 0.0153778325766325, f1 0.591,  prec 0.689, rec 0.518
TRAINING - Epoch 179 Batch 20: loss 0.020068122074007988, f1 0.481,  prec 0.802, rec 0.344
TRAINING - Epoch 179 Batch 30: loss 0.01674766093492508, f1 0.576,  prec 0.75, rec 0.467
TRAINING - Epoch 179 Batch 40: loss 0.016478827223181725, f1 0.568,  prec 0.777, rec 0.448
TRAINING - Epoch 179 Batch 50: loss 0.020583102479577065, f1 0.483,  prec 0.798, rec 0.347
VALIDATION - Epoch 179 Batch 0: loss 0.024708015844225883, f1 0.429, prec 0.845, rec 0.287
VALIDATION - Epoch 179 Batch 10: loss 0.02796108089387417, f1 0.369, prec 0.802, rec 0.24
VALIDATION - Epoch 179 Batch 20: loss 0.024605028331279755, f1 0.473, prec 0.836, rec 0.33
TRAINING - Epoch 180 Batch 0: loss 0.015835408121347427, f1 0.556,  prec 0.855, rec 0.412
TRAINING - Epoch 180 Batch 10: loss 0.016363099217414856, f1 0.622,  prec 0.684, rec 0.57
TRAINING - Epoch 180 Batch 20: loss 0.02215038612484932, f1 0.401,  prec 0.697, rec 0.281
TRAINING - Epoch 180 Batch 30: loss 0.015299367718398571, f1 0.567,  prec 0.778, rec 0.446
TRAINING - Epoch 180 Batch 40: loss 0.016872402280569077, f1 0.583,  prec 0.857, rec 0.441
TRAINING - Epoch 180 Batch 50: loss 0.015920229256153107, f1 0.538,  prec 0.689, rec 0.441
VALIDATION - Epoch 180 Batch 0: loss 0.025723768398165703, f1 0.514, prec 0.665, rec 0.419
VALIDATION - Epoch 180 Batch 10: loss 0.026927800849080086, f1 0.408, prec 0.583, rec 0.314
VALIDATION - Epoch 180 Batch 20: loss 0.02032409980893135, f1 0.558, prec 0.736, rec 0.45
TRAINING - Epoch 181 Batch 0: loss 0.015201954171061516, f1 0.532,  prec 0.736, rec 0.417
TRAINING - Epoch 181 Batch 10: loss 0.019117964431643486, f1 0.527,  prec 0.803, rec 0.393
TRAINING - Epoch 181 Batch 20: loss 0.014333005994558334, f1 0.594,  prec 0.782, rec 0.478
TRAINING - Epoch 181 Batch 30: loss 0.014218172058463097, f1 0.626,  prec 0.763, rec 0.531
TRAINING - Epoch 181 Batch 40: loss 0.013160152360796928, f1 0.647,  prec 0.785, rec 0.551
TRAINING - Epoch 181 Batch 50: loss 0.016559207811951637, f1 0.538,  prec 0.748, rec 0.421
VALIDATION - Epoch 181 Batch 0: loss 0.023067820817232132, f1 0.48, prec 0.708, rec 0.364
VALIDATION - Epoch 181 Batch 10: loss 0.025438254699110985, f1 0.483, prec 0.664, rec 0.379
VALIDATION - Epoch 181 Batch 20: loss 0.026129676029086113, f1 0.417, prec 0.684, rec 0.3
TRAINING - Epoch 182 Batch 0: loss 0.015715859830379486, f1 0.604,  prec 0.763, rec 0.5
TRAINING - Epoch 182 Batch 10: loss 0.014484046027064323, f1 0.542,  prec 0.776, rec 0.416
TRAINING - Epoch 182 Batch 20: loss 0.014474578201770782, f1 0.582,  prec 0.792, rec 0.46
TRAINING - Epoch 182 Batch 30: loss 0.016007037833333015, f1 0.574,  prec 0.759, rec 0.461
TRAINING - Epoch 182 Batch 40: loss 0.01880165934562683, f1 0.572,  prec 0.686, rec 0.491
TRAINING - Epoch 182 Batch 50: loss 0.017920952290296555, f1 0.545,  prec 0.772, rec 0.422
VALIDATION - Epoch 182 Batch 0: loss 0.021018557250499725, f1 0.468, prec 0.706, rec 0.35
VALIDATION - Epoch 182 Batch 10: loss 0.0268363356590271, f1 0.463, prec 0.73, rec 0.339
VALIDATION - Epoch 182 Batch 20: loss 0.023186974227428436, f1 0.456, prec 0.781, rec 0.322
TRAINING - Epoch 183 Batch 0: loss 0.015875041484832764, f1 0.526,  prec 0.774, rec 0.398
TRAINING - Epoch 183 Batch 10: loss 0.01533345878124237, f1 0.59,  prec 0.737, rec 0.492
TRAINING - Epoch 183 Batch 20: loss 0.01743994653224945, f1 0.54,  prec 0.675, rec 0.45
TRAINING - Epoch 183 Batch 30: loss 0.01693590357899666, f1 0.663,  prec 0.738, rec 0.601
TRAINING - Epoch 183 Batch 40: loss 0.014919169247150421, f1 0.522,  prec 0.817, rec 0.384
TRAINING - Epoch 183 Batch 50: loss 0.019287120550870895, f1 0.556,  prec 0.719, rec 0.453
VALIDATION - Epoch 183 Batch 0: loss 0.023858526721596718, f1 0.51, prec 0.761, rec 0.383
VALIDATION - Epoch 183 Batch 10: loss 0.0253037977963686, f1 0.47, prec 0.757, rec 0.341
VALIDATION - Epoch 183 Batch 20: loss 0.029210463166236877, f1 0.465, prec 0.756, rec 0.336
TRAINING - Epoch 184 Batch 0: loss 0.016545899212360382, f1 0.591,  prec 0.784, rec 0.475
TRAINING - Epoch 184 Batch 10: loss 0.01702391542494297, f1 0.549,  prec 0.8, rec 0.418
TRAINING - Epoch 184 Batch 20: loss 0.016535956412553787, f1 0.577,  prec 0.72, rec 0.482
TRAINING - Epoch 184 Batch 30: loss 0.014795714989304543, f1 0.62,  prec 0.751, rec 0.528
TRAINING - Epoch 184 Batch 40: loss 0.015783268958330154, f1 0.618,  prec 0.771, rec 0.515
TRAINING - Epoch 184 Batch 50: loss 0.014829345978796482, f1 0.61,  prec 0.811, rec 0.489
VALIDATION - Epoch 184 Batch 0: loss 0.022264443337917328, f1 0.447, prec 0.672, rec 0.335
VALIDATION - Epoch 184 Batch 10: loss 0.026746908202767372, f1 0.472, prec 0.741, rec 0.346
VALIDATION - Epoch 184 Batch 20: loss 0.021103166043758392, f1 0.516, prec 0.728, rec 0.399
TRAINING - Epoch 185 Batch 0: loss 0.017375027760863304, f1 0.512,  prec 0.71, rec 0.401
TRAINING - Epoch 185 Batch 10: loss 0.015641767531633377, f1 0.627,  prec 0.759, rec 0.534
TRAINING - Epoch 185 Batch 20: loss 0.014628419652581215, f1 0.584,  prec 0.815, rec 0.455
TRAINING - Epoch 185 Batch 30: loss 0.01492479257285595, f1 0.546,  prec 0.725, rec 0.439
TRAINING - Epoch 185 Batch 40: loss 0.017241990193724632, f1 0.588,  prec 0.734, rec 0.491
TRAINING - Epoch 185 Batch 50: loss 0.017035461962223053, f1 0.553,  prec 0.67, rec 0.471
VALIDATION - Epoch 185 Batch 0: loss 0.02470494620501995, f1 0.506, prec 0.697, rec 0.397
VALIDATION - Epoch 185 Batch 10: loss 0.026280689984560013, f1 0.439, prec 0.63, rec 0.337
VALIDATION - Epoch 185 Batch 20: loss 0.020891012623906136, f1 0.543, prec 0.704, rec 0.442
TRAINING - Epoch 186 Batch 0: loss 0.01488589495420456, f1 0.611,  prec 0.75, rec 0.515
TRAINING - Epoch 186 Batch 10: loss 0.01605745032429695, f1 0.623,  prec 0.81, rec 0.507
TRAINING - Epoch 186 Batch 20: loss 0.01714308373630047, f1 0.596,  prec 0.854, rec 0.457
TRAINING - Epoch 186 Batch 30: loss 0.014053445309400558, f1 0.603,  prec 0.764, rec 0.498
TRAINING - Epoch 186 Batch 40: loss 0.01753937266767025, f1 0.528,  prec 0.701, rec 0.423
TRAINING - Epoch 186 Batch 50: loss 0.014502781443297863, f1 0.604,  prec 0.693, rec 0.536
VALIDATION - Epoch 186 Batch 0: loss 0.02748105861246586, f1 0.431, prec 0.56, rec 0.35
VALIDATION - Epoch 186 Batch 10: loss 0.022323545068502426, f1 0.502, prec 0.641, rec 0.413
VALIDATION - Epoch 186 Batch 20: loss 0.02385517582297325, f1 0.451, prec 0.68, rec 0.337
TRAINING - Epoch 187 Batch 0: loss 0.018794771283864975, f1 0.602,  prec 0.693, rec 0.532
TRAINING - Epoch 187 Batch 10: loss 0.014918075874447823, f1 0.586,  prec 0.783, rec 0.469
TRAINING - Epoch 187 Batch 20: loss 0.01574939861893654, f1 0.544,  prec 0.708, rec 0.442
TRAINING - Epoch 187 Batch 30: loss 0.012654873542487621, f1 0.606,  prec 0.779, rec 0.496
TRAINING - Epoch 187 Batch 40: loss 0.0161217600107193, f1 0.603,  prec 0.808, rec 0.481
TRAINING - Epoch 187 Batch 50: loss 0.014184068888425827, f1 0.65,  prec 0.8, rec 0.547
VALIDATION - Epoch 187 Batch 0: loss 0.021859442815184593, f1 0.489, prec 0.671, rec 0.384
VALIDATION - Epoch 187 Batch 10: loss 0.0241658054292202, f1 0.513, prec 0.73, rec 0.395
VALIDATION - Epoch 187 Batch 20: loss 0.02461894042789936, f1 0.552, prec 0.745, rec 0.438
TRAINING - Epoch 188 Batch 0: loss 0.012505067512392998, f1 0.602,  prec 0.708, rec 0.524
TRAINING - Epoch 188 Batch 10: loss 0.017107509076595306, f1 0.554,  prec 0.712, rec 0.453
TRAINING - Epoch 188 Batch 20: loss 0.013714708387851715, f1 0.65,  prec 0.731, rec 0.586
TRAINING - Epoch 188 Batch 30: loss 0.01594599150121212, f1 0.55,  prec 0.688, rec 0.458
TRAINING - Epoch 188 Batch 40: loss 0.015679575502872467, f1 0.548,  prec 0.806, rec 0.415
TRAINING - Epoch 188 Batch 50: loss 0.01686834916472435, f1 0.577,  prec 0.707, rec 0.487
VALIDATION - Epoch 188 Batch 0: loss 0.022764969617128372, f1 0.578, prec 0.61, rec 0.549
VALIDATION - Epoch 188 Batch 10: loss 0.029384873807430267, f1 0.531, prec 0.646, rec 0.451
VALIDATION - Epoch 188 Batch 20: loss 0.02578892558813095, f1 0.541, prec 0.595, rec 0.496
TRAINING - Epoch 189 Batch 0: loss 0.02023160457611084, f1 0.619,  prec 0.622, rec 0.615
TRAINING - Epoch 189 Batch 10: loss 0.017910048365592957, f1 0.506,  prec 0.785, rec 0.374
TRAINING - Epoch 189 Batch 20: loss 0.01547569315880537, f1 0.609,  prec 0.746, rec 0.514
TRAINING - Epoch 189 Batch 30: loss 0.014905823394656181, f1 0.643,  prec 0.732, rec 0.573
TRAINING - Epoch 189 Batch 40: loss 0.014915382489562035, f1 0.692,  prec 0.756, rec 0.639
TRAINING - Epoch 189 Batch 50: loss 0.018714454025030136, f1 0.522,  prec 0.73, rec 0.407
VALIDATION - Epoch 189 Batch 0: loss 0.025478221476078033, f1 0.427, prec 0.659, rec 0.316
VALIDATION - Epoch 189 Batch 10: loss 0.022303979843854904, f1 0.434, prec 0.696, rec 0.315
VALIDATION - Epoch 189 Batch 20: loss 0.02105824276804924, f1 0.504, prec 0.742, rec 0.382
TRAINING - Epoch 190 Batch 0: loss 0.01469652820378542, f1 0.558,  prec 0.736, rec 0.449
TRAINING - Epoch 190 Batch 10: loss 0.016108937561511993, f1 0.547,  prec 0.77, rec 0.424
TRAINING - Epoch 190 Batch 20: loss 0.015251453965902328, f1 0.554,  prec 0.752, rec 0.439
TRAINING - Epoch 190 Batch 30: loss 0.014759162440896034, f1 0.633,  prec 0.812, rec 0.518
TRAINING - Epoch 190 Batch 40: loss 0.016782443970441818, f1 0.571,  prec 0.731, rec 0.468
TRAINING - Epoch 190 Batch 50: loss 0.015936337411403656, f1 0.525,  prec 0.721, rec 0.412
VALIDATION - Epoch 190 Batch 0: loss 0.02131827548146248, f1 0.532, prec 0.705, rec 0.427
VALIDATION - Epoch 190 Batch 10: loss 0.025034267455339432, f1 0.453, prec 0.746, rec 0.325
VALIDATION - Epoch 190 Batch 20: loss 0.026448288932442665, f1 0.433, prec 0.722, rec 0.31
TRAINING - Epoch 191 Batch 0: loss 0.01372579112648964, f1 0.625,  prec 0.788, rec 0.518
TRAINING - Epoch 191 Batch 10: loss 0.015738118439912796, f1 0.584,  prec 0.795, rec 0.462
TRAINING - Epoch 191 Batch 20: loss 0.014055672101676464, f1 0.601,  prec 0.768, rec 0.494
TRAINING - Epoch 191 Batch 30: loss 0.013765744864940643, f1 0.491,  prec 0.83, rec 0.348
TRAINING - Epoch 191 Batch 40: loss 0.012260254472494125, f1 0.581,  prec 0.773, rec 0.466
TRAINING - Epoch 191 Batch 50: loss 0.015076329000294209, f1 0.622,  prec 0.727, rec 0.544
VALIDATION - Epoch 191 Batch 0: loss 0.02840295433998108, f1 0.375, prec 0.656, rec 0.262
VALIDATION - Epoch 191 Batch 10: loss 0.03028697334229946, f1 0.402, prec 0.643, rec 0.292
VALIDATION - Epoch 191 Batch 20: loss 0.03261179104447365, f1 0.426, prec 0.634, rec 0.321
TRAINING - Epoch 192 Batch 0: loss 0.01485423743724823, f1 0.61,  prec 0.805, rec 0.491
TRAINING - Epoch 192 Batch 10: loss 0.015168639831244946, f1 0.597,  prec 0.78, rec 0.483
TRAINING - Epoch 192 Batch 20: loss 0.015143467113375664, f1 0.529,  prec 0.77, rec 0.402
TRAINING - Epoch 192 Batch 30: loss 0.014315454289317131, f1 0.665,  prec 0.779, rec 0.58
TRAINING - Epoch 192 Batch 40: loss 0.014815018512308598, f1 0.64,  prec 0.798, rec 0.534
TRAINING - Epoch 192 Batch 50: loss 0.013924237340688705, f1 0.658,  prec 0.734, rec 0.596
VALIDATION - Epoch 192 Batch 0: loss 0.024275775998830795, f1 0.503, prec 0.696, rec 0.393
VALIDATION - Epoch 192 Batch 10: loss 0.03058682754635811, f1 0.491, prec 0.618, rec 0.407
VALIDATION - Epoch 192 Batch 20: loss 0.022728128358721733, f1 0.527, prec 0.716, rec 0.417
TRAINING - Epoch 193 Batch 0: loss 0.015496844425797462, f1 0.59,  prec 0.667, rec 0.53
TRAINING - Epoch 193 Batch 10: loss 0.015385324135422707, f1 0.549,  prec 0.741, rec 0.436
TRAINING - Epoch 193 Batch 20: loss 0.014231057837605476, f1 0.541,  prec 0.75, rec 0.423
TRAINING - Epoch 193 Batch 30: loss 0.015201718546450138, f1 0.566,  prec 0.772, rec 0.446
TRAINING - Epoch 193 Batch 40: loss 0.020561665296554565, f1 0.539,  prec 0.804, rec 0.405
TRAINING - Epoch 193 Batch 50: loss 0.01574755273759365, f1 0.605,  prec 0.735, rec 0.515
VALIDATION - Epoch 193 Batch 0: loss 0.02971302717924118, f1 0.363, prec 0.683, rec 0.247
VALIDATION - Epoch 193 Batch 10: loss 0.024524027481675148, f1 0.497, prec 0.736, rec 0.375
VALIDATION - Epoch 193 Batch 20: loss 0.024378513917326927, f1 0.507, prec 0.694, rec 0.4
TRAINING - Epoch 194 Batch 0: loss 0.014145741239190102, f1 0.61,  prec 0.783, rec 0.5
TRAINING - Epoch 194 Batch 10: loss 0.015792829915881157, f1 0.612,  prec 0.77, rec 0.507
TRAINING - Epoch 194 Batch 20: loss 0.016054123640060425, f1 0.573,  prec 0.738, rec 0.468
TRAINING - Epoch 194 Batch 30: loss 0.014470716938376427, f1 0.515,  prec 0.75, rec 0.392
TRAINING - Epoch 194 Batch 40: loss 0.015805762261152267, f1 0.631,  prec 0.692, rec 0.58
TRAINING - Epoch 194 Batch 50: loss 0.02360275574028492, f1 0.388,  prec 0.92, rec 0.246
VALIDATION - Epoch 194 Batch 0: loss 0.02197638899087906, f1 0.443, prec 0.755, rec 0.313
VALIDATION - Epoch 194 Batch 10: loss 0.02078092098236084, f1 0.533, prec 0.732, rec 0.419
VALIDATION - Epoch 194 Batch 20: loss 0.02372448518872261, f1 0.455, prec 0.656, rec 0.348
TRAINING - Epoch 195 Batch 0: loss 0.016503488644957542, f1 0.614,  prec 0.791, rec 0.502
TRAINING - Epoch 195 Batch 10: loss 0.014413881115615368, f1 0.497,  prec 0.792, rec 0.362
TRAINING - Epoch 195 Batch 20: loss 0.013097619637846947, f1 0.586,  prec 0.757, rec 0.479
TRAINING - Epoch 195 Batch 30: loss 0.015954095870256424, f1 0.605,  prec 0.73, rec 0.516
TRAINING - Epoch 195 Batch 40: loss 0.015469742007553577, f1 0.575,  prec 0.736, rec 0.472
TRAINING - Epoch 195 Batch 50: loss 0.015728702768683434, f1 0.655,  prec 0.78, rec 0.564
VALIDATION - Epoch 195 Batch 0: loss 0.024760553613305092, f1 0.391, prec 0.736, rec 0.266
VALIDATION - Epoch 195 Batch 10: loss 0.026776161044836044, f1 0.486, prec 0.779, rec 0.353
VALIDATION - Epoch 195 Batch 20: loss 0.03219597786664963, f1 0.407, prec 0.698, rec 0.287
TRAINING - Epoch 196 Batch 0: loss 0.015901178121566772, f1 0.573,  prec 0.831, rec 0.437
TRAINING - Epoch 196 Batch 10: loss 0.014528066851198673, f1 0.638,  prec 0.753, rec 0.553
TRAINING - Epoch 196 Batch 20: loss 0.016248514875769615, f1 0.576,  prec 0.797, rec 0.451
TRAINING - Epoch 196 Batch 30: loss 0.014623095281422138, f1 0.644,  prec 0.748, rec 0.565
TRAINING - Epoch 196 Batch 40: loss 0.015329297631978989, f1 0.605,  prec 0.747, rec 0.508
TRAINING - Epoch 196 Batch 50: loss 0.013469034805893898, f1 0.599,  prec 0.796, rec 0.48
VALIDATION - Epoch 196 Batch 0: loss 0.025603042915463448, f1 0.474, prec 0.594, rec 0.395
VALIDATION - Epoch 196 Batch 10: loss 0.024660971015691757, f1 0.451, prec 0.654, rec 0.344
VALIDATION - Epoch 196 Batch 20: loss 0.02443353272974491, f1 0.448, prec 0.705, rec 0.329
TRAINING - Epoch 197 Batch 0: loss 0.014947189018130302, f1 0.613,  prec 0.76, rec 0.514
TRAINING - Epoch 197 Batch 10: loss 0.014953297562897205, f1 0.539,  prec 0.837, rec 0.397
TRAINING - Epoch 197 Batch 20: loss 0.01832980290055275, f1 0.612,  prec 0.668, rec 0.565
TRAINING - Epoch 197 Batch 30: loss 0.01763037033379078, f1 0.577,  prec 0.796, rec 0.452
TRAINING - Epoch 197 Batch 40: loss 0.014404546469449997, f1 0.689,  prec 0.808, rec 0.601
TRAINING - Epoch 197 Batch 50: loss 0.01643787883222103, f1 0.522,  prec 0.798, rec 0.387
VALIDATION - Epoch 197 Batch 0: loss 0.024757465347647667, f1 0.464, prec 0.783, rec 0.33
VALIDATION - Epoch 197 Batch 10: loss 0.01891389489173889, f1 0.491, prec 0.748, rec 0.366
VALIDATION - Epoch 197 Batch 20: loss 0.022151250392198563, f1 0.453, prec 0.772, rec 0.321
TRAINING - Epoch 198 Batch 0: loss 0.015338476747274399, f1 0.543,  prec 0.794, rec 0.413
TRAINING - Epoch 198 Batch 10: loss 0.014431496150791645, f1 0.633,  prec 0.774, rec 0.535
TRAINING - Epoch 198 Batch 20: loss 0.013026750646531582, f1 0.655,  prec 0.78, rec 0.564
TRAINING - Epoch 198 Batch 30: loss 0.014450880698859692, f1 0.699,  prec 0.811, rec 0.615
TRAINING - Epoch 198 Batch 40: loss 0.012735004536807537, f1 0.6,  prec 0.755, rec 0.498
TRAINING - Epoch 198 Batch 50: loss 0.015088986605405807, f1 0.636,  prec 0.73, rec 0.564
VALIDATION - Epoch 198 Batch 0: loss 0.026333274319767952, f1 0.379, prec 0.674, rec 0.263
VALIDATION - Epoch 198 Batch 10: loss 0.028988167643547058, f1 0.395, prec 0.786, rec 0.264
VALIDATION - Epoch 198 Batch 20: loss 0.02427501417696476, f1 0.536, prec 0.744, rec 0.419
TRAINING - Epoch 199 Batch 0: loss 0.01302840281277895, f1 0.617,  prec 0.8, rec 0.502
TRAINING - Epoch 199 Batch 10: loss 0.015282842330634594, f1 0.626,  prec 0.772, rec 0.526
TRAINING - Epoch 199 Batch 20: loss 0.016640476882457733, f1 0.54,  prec 0.761, rec 0.418
TRAINING - Epoch 199 Batch 30: loss 0.014140100218355656, f1 0.603,  prec 0.77, rec 0.496
TRAINING - Epoch 199 Batch 40: loss 0.017438530921936035, f1 0.596,  prec 0.722, rec 0.507
TRAINING - Epoch 199 Batch 50: loss 0.013911668211221695, f1 0.586,  prec 0.901, rec 0.434
VALIDATION - Epoch 199 Batch 0: loss 0.028969965875148773, f1 0.474, prec 0.772, rec 0.342
VALIDATION - Epoch 199 Batch 10: loss 0.031142311170697212, f1 0.455, prec 0.714, rec 0.333
VALIDATION - Epoch 199 Batch 20: loss 0.029995983466506004, f1 0.391, prec 0.701, rec 0.271
TRAINING - Epoch 200 Batch 0: loss 0.016850732266902924, f1 0.611,  prec 0.716, rec 0.533
TRAINING - Epoch 200 Batch 10: loss 0.01597980223596096, f1 0.649,  prec 0.723, rec 0.588
TRAINING - Epoch 200 Batch 20: loss 0.012781539931893349, f1 0.612,  prec 0.773, rec 0.506
TRAINING - Epoch 200 Batch 30: loss 0.015727870166301727, f1 0.62,  prec 0.711, rec 0.55
TRAINING - Epoch 200 Batch 40: loss 0.014867164194583893, f1 0.58,  prec 0.733, rec 0.48
TRAINING - Epoch 200 Batch 50: loss 0.017614319920539856, f1 0.583,  prec 0.86, rec 0.441
VALIDATION - Epoch 200 Batch 0: loss 0.02942686900496483, f1 0.34, prec 0.631, rec 0.233
VALIDATION - Epoch 200 Batch 10: loss 0.023577319458127022, f1 0.42, prec 0.798, rec 0.285
VALIDATION - Epoch 200 Batch 20: loss 0.025852153077721596, f1 0.43, prec 0.716, rec 0.307
TRAINING - Epoch 201 Batch 0: loss 0.013563897460699081, f1 0.58,  prec 0.805, rec 0.453
TRAINING - Epoch 201 Batch 10: loss 0.014629247598350048, f1 0.674,  prec 0.707, rec 0.644
TRAINING - Epoch 201 Batch 20: loss 0.013910703361034393, f1 0.602,  prec 0.833, rec 0.471
TRAINING - Epoch 201 Batch 30: loss 0.014751692302525043, f1 0.56,  prec 0.793, rec 0.432
TRAINING - Epoch 201 Batch 40: loss 0.014958338811993599, f1 0.59,  prec 0.699, rec 0.511
TRAINING - Epoch 201 Batch 50: loss 0.016452817246317863, f1 0.541,  prec 0.803, rec 0.407
VALIDATION - Epoch 201 Batch 0: loss 0.0300464928150177, f1 0.382, prec 0.679, rec 0.266
VALIDATION - Epoch 201 Batch 10: loss 0.02817842923104763, f1 0.446, prec 0.76, rec 0.316
VALIDATION - Epoch 201 Batch 20: loss 0.023338181897997856, f1 0.413, prec 0.725, rec 0.288
TRAINING - Epoch 202 Batch 0: loss 0.013943125493824482, f1 0.505,  prec 0.778, rec 0.373
TRAINING - Epoch 202 Batch 10: loss 0.01585402712225914, f1 0.572,  prec 0.755, rec 0.461
TRAINING - Epoch 202 Batch 20: loss 0.015152327716350555, f1 0.567,  prec 0.711, rec 0.472
TRAINING - Epoch 202 Batch 30: loss 0.011964861303567886, f1 0.638,  prec 0.771, rec 0.544
TRAINING - Epoch 202 Batch 40: loss 0.01360911875963211, f1 0.591,  prec 0.8, rec 0.469
TRAINING - Epoch 202 Batch 50: loss 0.013469921424984932, f1 0.676,  prec 0.784, rec 0.594
VALIDATION - Epoch 202 Batch 0: loss 0.027148375287652016, f1 0.419, prec 0.649, rec 0.309
VALIDATION - Epoch 202 Batch 10: loss 0.02578866109251976, f1 0.441, prec 0.734, rec 0.315
VALIDATION - Epoch 202 Batch 20: loss 0.033974435180425644, f1 0.463, prec 0.818, rec 0.322
TRAINING - Epoch 203 Batch 0: loss 0.01641392521560192, f1 0.597,  prec 0.796, rec 0.478
TRAINING - Epoch 203 Batch 10: loss 0.012919154949486256, f1 0.637,  prec 0.763, rec 0.547
TRAINING - Epoch 203 Batch 20: loss 0.014088916592299938, f1 0.565,  prec 0.796, rec 0.438
TRAINING - Epoch 203 Batch 30: loss 0.015469704754650593, f1 0.627,  prec 0.678, rec 0.584
TRAINING - Epoch 203 Batch 40: loss 0.01575377956032753, f1 0.584,  prec 0.838, rec 0.449
TRAINING - Epoch 203 Batch 50: loss 0.014925914816558361, f1 0.651,  prec 0.773, rec 0.562
VALIDATION - Epoch 203 Batch 0: loss 0.025136489421129227, f1 0.405, prec 0.765, rec 0.276
VALIDATION - Epoch 203 Batch 10: loss 0.02937426045536995, f1 0.368, prec 0.739, rec 0.245
VALIDATION - Epoch 203 Batch 20: loss 0.02444014884531498, f1 0.424, prec 0.735, rec 0.298
TRAINING - Epoch 204 Batch 0: loss 0.01589437760412693, f1 0.576,  prec 0.835, rec 0.439
TRAINING - Epoch 204 Batch 10: loss 0.01406719721853733, f1 0.676,  prec 0.738, rec 0.623
TRAINING - Epoch 204 Batch 20: loss 0.013967984355986118, f1 0.632,  prec 0.822, rec 0.513
TRAINING - Epoch 204 Batch 30: loss 0.016285648569464684, f1 0.618,  prec 0.883, rec 0.476
TRAINING - Epoch 204 Batch 40: loss 0.012789418920874596, f1 0.605,  prec 0.803, rec 0.485
TRAINING - Epoch 204 Batch 50: loss 0.012942193076014519, f1 0.611,  prec 0.784, rec 0.5
VALIDATION - Epoch 204 Batch 0: loss 0.02829550765454769, f1 0.416, prec 0.748, rec 0.288
VALIDATION - Epoch 204 Batch 10: loss 0.023987868800759315, f1 0.505, prec 0.746, rec 0.381
VALIDATION - Epoch 204 Batch 20: loss 0.02907121367752552, f1 0.44, prec 0.739, rec 0.313
TRAINING - Epoch 205 Batch 0: loss 0.013483025133609772, f1 0.577,  prec 0.779, rec 0.458
TRAINING - Epoch 205 Batch 10: loss 0.015421757474541664, f1 0.609,  prec 0.747, rec 0.515
TRAINING - Epoch 205 Batch 20: loss 0.012280947528779507, f1 0.576,  prec 0.825, rec 0.443
TRAINING - Epoch 205 Batch 30: loss 0.015585403889417648, f1 0.64,  prec 0.682, rec 0.603
TRAINING - Epoch 205 Batch 40: loss 0.01645086333155632, f1 0.504,  prec 0.872, rec 0.354
TRAINING - Epoch 205 Batch 50: loss 0.015564359724521637, f1 0.62,  prec 0.708, rec 0.552
VALIDATION - Epoch 205 Batch 0: loss 0.023955848067998886, f1 0.493, prec 0.723, rec 0.375
VALIDATION - Epoch 205 Batch 10: loss 0.029967445880174637, f1 0.462, prec 0.694, rec 0.346
VALIDATION - Epoch 205 Batch 20: loss 0.025207512080669403, f1 0.571, prec 0.75, rec 0.461
TRAINING - Epoch 206 Batch 0: loss 0.012642795220017433, f1 0.657,  prec 0.756, rec 0.581
TRAINING - Epoch 206 Batch 10: loss 0.013192557729780674, f1 0.668,  prec 0.79, rec 0.579
TRAINING - Epoch 206 Batch 20: loss 0.013301977887749672, f1 0.591,  prec 0.794, rec 0.471
TRAINING - Epoch 206 Batch 30: loss 0.014885825105011463, f1 0.609,  prec 0.816, rec 0.486
TRAINING - Epoch 206 Batch 40: loss 0.01605115458369255, f1 0.538,  prec 0.719, rec 0.429
TRAINING - Epoch 206 Batch 50: loss 0.015037596225738525, f1 0.628,  prec 0.819, rec 0.509
VALIDATION - Epoch 206 Batch 0: loss 0.02638007514178753, f1 0.458, prec 0.734, rec 0.333
VALIDATION - Epoch 206 Batch 10: loss 0.02602311596274376, f1 0.492, prec 0.701, rec 0.379
VALIDATION - Epoch 206 Batch 20: loss 0.026697538793087006, f1 0.45, prec 0.732, rec 0.325
TRAINING - Epoch 207 Batch 0: loss 0.01325592864304781, f1 0.638,  prec 0.843, rec 0.513
TRAINING - Epoch 207 Batch 10: loss 0.017946258187294006, f1 0.636,  prec 0.652, rec 0.621
TRAINING - Epoch 207 Batch 20: loss 0.015090638771653175, f1 0.562,  prec 0.793, rec 0.435
TRAINING - Epoch 207 Batch 30: loss 0.015213639475405216, f1 0.627,  prec 0.754, rec 0.537
TRAINING - Epoch 207 Batch 40: loss 0.012126559391617775, f1 0.679,  prec 0.8, rec 0.589
TRAINING - Epoch 207 Batch 50: loss 0.01436771173030138, f1 0.533,  prec 0.803, rec 0.398
VALIDATION - Epoch 207 Batch 0: loss 0.028966763988137245, f1 0.448, prec 0.655, rec 0.341
VALIDATION - Epoch 207 Batch 10: loss 0.02520534209907055, f1 0.48, prec 0.655, rec 0.379
VALIDATION - Epoch 207 Batch 20: loss 0.02863166667521, f1 0.444, prec 0.718, rec 0.322
TRAINING - Epoch 208 Batch 0: loss 0.013730007223784924, f1 0.612,  prec 0.732, rec 0.527
TRAINING - Epoch 208 Batch 10: loss 0.015736717730760574, f1 0.689,  prec 0.74, rec 0.644
TRAINING - Epoch 208 Batch 20: loss 0.014588635414838791, f1 0.609,  prec 0.773, rec 0.502
TRAINING - Epoch 208 Batch 30: loss 0.013203908689320087, f1 0.713,  prec 0.848, rec 0.616
TRAINING - Epoch 208 Batch 40: loss 0.014912757091224194, f1 0.59,  prec 0.775, rec 0.477
TRAINING - Epoch 208 Batch 50: loss 0.016350187361240387, f1 0.546,  prec 0.807, rec 0.412
VALIDATION - Epoch 208 Batch 0: loss 0.026428619399666786, f1 0.426, prec 0.75, rec 0.298
VALIDATION - Epoch 208 Batch 10: loss 0.02757713943719864, f1 0.438, prec 0.71, rec 0.317
VALIDATION - Epoch 208 Batch 20: loss 0.026956066489219666, f1 0.388, prec 0.724, rec 0.265
TRAINING - Epoch 209 Batch 0: loss 0.014020990580320358, f1 0.629,  prec 0.8, rec 0.519
TRAINING - Epoch 209 Batch 10: loss 0.013545033521950245, f1 0.62,  prec 0.775, rec 0.517
TRAINING - Epoch 209 Batch 20: loss 0.014236563816666603, f1 0.623,  prec 0.796, rec 0.512
TRAINING - Epoch 209 Batch 30: loss 0.013901827856898308, f1 0.659,  prec 0.774, rec 0.574
TRAINING - Epoch 209 Batch 40: loss 0.019158978015184402, f1 0.501,  prec 0.826, rec 0.36
TRAINING - Epoch 209 Batch 50: loss 0.015130923129618168, f1 0.598,  prec 0.755, rec 0.496
VALIDATION - Epoch 209 Batch 0: loss 0.02624909020960331, f1 0.433, prec 0.725, rec 0.308
VALIDATION - Epoch 209 Batch 10: loss 0.02664896473288536, f1 0.443, prec 0.828, rec 0.303
VALIDATION - Epoch 209 Batch 20: loss 0.02592010423541069, f1 0.504, prec 0.8, rec 0.368
TRAINING - Epoch 210 Batch 0: loss 0.015159932896494865, f1 0.603,  prec 0.799, rec 0.485
TRAINING - Epoch 210 Batch 10: loss 0.013253509066998959, f1 0.664,  prec 0.741, rec 0.601
TRAINING - Epoch 210 Batch 20: loss 0.012926967814564705, f1 0.615,  prec 0.765, rec 0.515
TRAINING - Epoch 210 Batch 30: loss 0.013451549224555492, f1 0.643,  prec 0.769, rec 0.552
TRAINING - Epoch 210 Batch 40: loss 0.013884983956813812, f1 0.525,  prec 0.762, rec 0.401
TRAINING - Epoch 210 Batch 50: loss 0.015574830584228039, f1 0.664,  prec 0.755, rec 0.593
VALIDATION - Epoch 210 Batch 0: loss 0.025990162044763565, f1 0.534, prec 0.73, rec 0.42
VALIDATION - Epoch 210 Batch 10: loss 0.025119710713624954, f1 0.543, prec 0.627, rec 0.479
VALIDATION - Epoch 210 Batch 20: loss 0.02536633238196373, f1 0.587, prec 0.75, rec 0.482
TRAINING - Epoch 211 Batch 0: loss 0.01322389766573906, f1 0.605,  prec 0.71, rec 0.526
TRAINING - Epoch 211 Batch 10: loss 0.014372659847140312, f1 0.601,  prec 0.79, rec 0.485
TRAINING - Epoch 211 Batch 20: loss 0.014114919118583202, f1 0.623,  prec 0.719, rec 0.549
TRAINING - Epoch 211 Batch 30: loss 0.015781033784151077, f1 0.598,  prec 0.841, rec 0.464
TRAINING - Epoch 211 Batch 40: loss 0.015208949334919453, f1 0.664,  prec 0.737, rec 0.605
TRAINING - Epoch 211 Batch 50: loss 0.014374622143805027, f1 0.687,  prec 0.757, rec 0.628
VALIDATION - Epoch 211 Batch 0: loss 0.02686612866818905, f1 0.447, prec 0.735, rec 0.322
VALIDATION - Epoch 211 Batch 10: loss 0.024351008236408234, f1 0.556, prec 0.709, rec 0.457
VALIDATION - Epoch 211 Batch 20: loss 0.034753452986478806, f1 0.457, prec 0.673, rec 0.345
TRAINING - Epoch 212 Batch 0: loss 0.010908371768891811, f1 0.613,  prec 0.777, rec 0.507
TRAINING - Epoch 212 Batch 10: loss 0.014385264366865158, f1 0.647,  prec 0.802, rec 0.542
TRAINING - Epoch 212 Batch 20: loss 0.015588612295687199, f1 0.504,  prec 0.805, rec 0.367
TRAINING - Epoch 212 Batch 30: loss 0.016412310302257538, f1 0.597,  prec 0.69, rec 0.527
TRAINING - Epoch 212 Batch 40: loss 0.01233764924108982, f1 0.632,  prec 0.84, rec 0.506
TRAINING - Epoch 212 Batch 50: loss 0.015148001722991467, f1 0.619,  prec 0.737, rec 0.533
VALIDATION - Epoch 212 Batch 0: loss 0.02623370848596096, f1 0.429, prec 0.839, rec 0.288
VALIDATION - Epoch 212 Batch 10: loss 0.031819168478250504, f1 0.437, prec 0.79, rec 0.302
VALIDATION - Epoch 212 Batch 20: loss 0.028155647218227386, f1 0.419, prec 0.78, rec 0.287
TRAINING - Epoch 213 Batch 0: loss 0.014641688205301762, f1 0.575,  prec 0.788, rec 0.452
TRAINING - Epoch 213 Batch 10: loss 0.014253766275942326, f1 0.649,  prec 0.811, rec 0.541
TRAINING - Epoch 213 Batch 20: loss 0.014447410590946674, f1 0.592,  prec 0.74, rec 0.494
TRAINING - Epoch 213 Batch 30: loss 0.012405605055391788, f1 0.578,  prec 0.831, rec 0.443
TRAINING - Epoch 213 Batch 40: loss 0.014909438788890839, f1 0.583,  prec 0.752, rec 0.475
TRAINING - Epoch 213 Batch 50: loss 0.016064677387475967, f1 0.611,  prec 0.795, rec 0.496
VALIDATION - Epoch 213 Batch 0: loss 0.02688014693558216, f1 0.399, prec 0.793, rec 0.266
VALIDATION - Epoch 213 Batch 10: loss 0.028903741389513016, f1 0.344, prec 0.698, rec 0.228
VALIDATION - Epoch 213 Batch 20: loss 0.023298151791095734, f1 0.466, prec 0.802, rec 0.328
TRAINING - Epoch 214 Batch 0: loss 0.013942832127213478, f1 0.597,  prec 0.781, rec 0.484
TRAINING - Epoch 214 Batch 10: loss 0.013900103978812695, f1 0.644,  prec 0.816, rec 0.532
TRAINING - Epoch 214 Batch 20: loss 0.015303682535886765, f1 0.646,  prec 0.764, rec 0.559
TRAINING - Epoch 214 Batch 30: loss 0.013668922707438469, f1 0.631,  prec 0.801, rec 0.521
TRAINING - Epoch 214 Batch 40: loss 0.01669704169034958, f1 0.522,  prec 0.857, rec 0.375
TRAINING - Epoch 214 Batch 50: loss 0.014579731039702892, f1 0.614,  prec 0.708, rec 0.542
VALIDATION - Epoch 214 Batch 0: loss 0.02696857787668705, f1 0.52, prec 0.717, rec 0.408
VALIDATION - Epoch 214 Batch 10: loss 0.026084398850798607, f1 0.462, prec 0.73, rec 0.338
VALIDATION - Epoch 214 Batch 20: loss 0.026520006358623505, f1 0.446, prec 0.75, rec 0.317
TRAINING - Epoch 215 Batch 0: loss 0.01471096370369196, f1 0.667,  prec 0.776, rec 0.585
TRAINING - Epoch 215 Batch 10: loss 0.013417926616966724, f1 0.61,  prec 0.714, rec 0.533
TRAINING - Epoch 215 Batch 20: loss 0.012743165716528893, f1 0.6,  prec 0.808, rec 0.477
TRAINING - Epoch 215 Batch 30: loss 0.01580853760242462, f1 0.624,  prec 0.7, rec 0.563
TRAINING - Epoch 215 Batch 40: loss 0.012510199099779129, f1 0.635,  prec 0.827, rec 0.516
TRAINING - Epoch 215 Batch 50: loss 0.013194499537348747, f1 0.636,  prec 0.737, rec 0.559
VALIDATION - Epoch 215 Batch 0: loss 0.027133772149682045, f1 0.422, prec 0.819, rec 0.284
VALIDATION - Epoch 215 Batch 10: loss 0.028571240603923798, f1 0.366, prec 0.673, rec 0.252
VALIDATION - Epoch 215 Batch 20: loss 0.028434524312615395, f1 0.391, prec 0.747, rec 0.264
TRAINING - Epoch 216 Batch 0: loss 0.012605336494743824, f1 0.607,  prec 0.888, rec 0.461
TRAINING - Epoch 216 Batch 10: loss 0.014622206799685955, f1 0.678,  prec 0.818, rec 0.578
TRAINING - Epoch 216 Batch 20: loss 0.013427590020000935, f1 0.603,  prec 0.805, rec 0.482
TRAINING - Epoch 216 Batch 30: loss 0.01719011180102825, f1 0.633,  prec 0.796, rec 0.526
TRAINING - Epoch 216 Batch 40: loss 0.012603666633367538, f1 0.658,  prec 0.847, rec 0.537
TRAINING - Epoch 216 Batch 50: loss 0.013836110010743141, f1 0.632,  prec 0.793, rec 0.525
VALIDATION - Epoch 216 Batch 0: loss 0.030598515644669533, f1 0.453, prec 0.752, rec 0.324
VALIDATION - Epoch 216 Batch 10: loss 0.02189059369266033, f1 0.438, prec 0.71, rec 0.317
VALIDATION - Epoch 216 Batch 20: loss 0.02603122778236866, f1 0.479, prec 0.736, rec 0.354
TRAINING - Epoch 217 Batch 0: loss 0.012930329889059067, f1 0.594,  prec 0.868, rec 0.452
TRAINING - Epoch 217 Batch 10: loss 0.0128356097266078, f1 0.641,  prec 0.773, rec 0.548
TRAINING - Epoch 217 Batch 20: loss 0.013333906419575214, f1 0.618,  prec 0.799, rec 0.504
TRAINING - Epoch 217 Batch 30: loss 0.01430230587720871, f1 0.554,  prec 0.78, rec 0.429
TRAINING - Epoch 217 Batch 40: loss 0.013310720212757587, f1 0.606,  prec 0.767, rec 0.5
TRAINING - Epoch 217 Batch 50: loss 0.012627600692212582, f1 0.668,  prec 0.774, rec 0.588
VALIDATION - Epoch 217 Batch 0: loss 0.027042994275689125, f1 0.426, prec 0.633, rec 0.321
VALIDATION - Epoch 217 Batch 10: loss 0.021752173081040382, f1 0.54, prec 0.727, rec 0.429
VALIDATION - Epoch 217 Batch 20: loss 0.025216279551386833, f1 0.492, prec 0.671, rec 0.389
TRAINING - Epoch 218 Batch 0: loss 0.014334090054035187, f1 0.622,  prec 0.761, rec 0.525
TRAINING - Epoch 218 Batch 10: loss 0.01496779266744852, f1 0.595,  prec 0.731, rec 0.502
TRAINING - Epoch 218 Batch 20: loss 0.012533552013337612, f1 0.662,  prec 0.79, rec 0.57
TRAINING - Epoch 218 Batch 30: loss 0.015238059684634209, f1 0.594,  prec 0.895, rec 0.444
TRAINING - Epoch 218 Batch 40: loss 0.011802846565842628, f1 0.668,  prec 0.772, rec 0.589
TRAINING - Epoch 218 Batch 50: loss 0.013804551213979721, f1 0.616,  prec 0.831, rec 0.489
VALIDATION - Epoch 218 Batch 0: loss 0.029018450528383255, f1 0.487, prec 0.803, rec 0.349
VALIDATION - Epoch 218 Batch 10: loss 0.02695080265402794, f1 0.487, prec 0.752, rec 0.36
VALIDATION - Epoch 218 Batch 20: loss 0.026004362851381302, f1 0.47, prec 0.788, rec 0.335
TRAINING - Epoch 219 Batch 0: loss 0.011923356913030148, f1 0.649,  prec 0.873, rec 0.516
TRAINING - Epoch 219 Batch 10: loss 0.013048323802649975, f1 0.664,  prec 0.759, rec 0.59
TRAINING - Epoch 219 Batch 20: loss 0.013843447901308537, f1 0.564,  prec 0.805, rec 0.434
TRAINING - Epoch 219 Batch 30: loss 0.011955822817981243, f1 0.626,  prec 0.741, rec 0.542
TRAINING - Epoch 219 Batch 40: loss 0.0147709297016263, f1 0.627,  prec 0.818, rec 0.508
TRAINING - Epoch 219 Batch 50: loss 0.013047520071268082, f1 0.597,  prec 0.815, rec 0.471
VALIDATION - Epoch 219 Batch 0: loss 0.027863087132573128, f1 0.526, prec 0.727, rec 0.413
VALIDATION - Epoch 219 Batch 10: loss 0.025878317654132843, f1 0.497, prec 0.653, rec 0.402
VALIDATION - Epoch 219 Batch 20: loss 0.026387371122837067, f1 0.485, prec 0.664, rec 0.382
TRAINING - Epoch 220 Batch 0: loss 0.011807825416326523, f1 0.671,  prec 0.765, rec 0.598
TRAINING - Epoch 220 Batch 10: loss 0.012078923173248768, f1 0.618,  prec 0.816, rec 0.498
TRAINING - Epoch 220 Batch 20: loss 0.012378457002341747, f1 0.682,  prec 0.866, rec 0.562
TRAINING - Epoch 220 Batch 30: loss 0.013590567745268345, f1 0.665,  prec 0.819, rec 0.56
TRAINING - Epoch 220 Batch 40: loss 0.011799807660281658, f1 0.673,  prec 0.822, rec 0.569
TRAINING - Epoch 220 Batch 50: loss 0.014534736052155495, f1 0.617,  prec 0.839, rec 0.488
VALIDATION - Epoch 220 Batch 0: loss 0.024560661986470222, f1 0.463, prec 0.737, rec 0.337
VALIDATION - Epoch 220 Batch 10: loss 0.02115413174033165, f1 0.415, prec 0.623, rec 0.311
VALIDATION - Epoch 220 Batch 20: loss 0.025862429291009903, f1 0.409, prec 0.697, rec 0.289
TRAINING - Epoch 221 Batch 0: loss 0.015112137421965599, f1 0.664,  prec 0.851, rec 0.544
TRAINING - Epoch 221 Batch 10: loss 0.015071559697389603, f1 0.562,  prec 0.768, rec 0.443
TRAINING - Epoch 221 Batch 20: loss 0.012735131196677685, f1 0.668,  prec 0.764, rec 0.593
TRAINING - Epoch 221 Batch 30: loss 0.014614339917898178, f1 0.632,  prec 0.826, rec 0.512
TRAINING - Epoch 221 Batch 40: loss 0.013270450755953789, f1 0.596,  prec 0.761, rec 0.49
TRAINING - Epoch 221 Batch 50: loss 0.01447793934494257, f1 0.654,  prec 0.757, rec 0.576
VALIDATION - Epoch 221 Batch 0: loss 0.027611827477812767, f1 0.479, prec 0.779, rec 0.345
VALIDATION - Epoch 221 Batch 10: loss 0.02226097695529461, f1 0.495, prec 0.708, rec 0.38
VALIDATION - Epoch 221 Batch 20: loss 0.030158981680870056, f1 0.461, prec 0.701, rec 0.344
TRAINING - Epoch 222 Batch 0: loss 0.0136564327403903, f1 0.667,  prec 0.818, rec 0.562
TRAINING - Epoch 222 Batch 10: loss 0.013975314795970917, f1 0.611,  prec 0.844, rec 0.479
TRAINING - Epoch 222 Batch 20: loss 0.015614977106451988, f1 0.588,  prec 0.853, rec 0.449
TRAINING - Epoch 222 Batch 30: loss 0.015397025272250175, f1 0.636,  prec 0.84, rec 0.512
TRAINING - Epoch 222 Batch 40: loss 0.011884882114827633, f1 0.654,  prec 0.767, rec 0.57
TRAINING - Epoch 222 Batch 50: loss 0.015718398615717888, f1 0.606,  prec 0.818, rec 0.481
VALIDATION - Epoch 222 Batch 0: loss 0.02621791511774063, f1 0.377, prec 0.667, rec 0.263
VALIDATION - Epoch 222 Batch 10: loss 0.032415445894002914, f1 0.416, prec 0.712, rec 0.294
VALIDATION - Epoch 222 Batch 20: loss 0.02861745096743107, f1 0.389, prec 0.787, rec 0.258
TRAINING - Epoch 223 Batch 0: loss 0.013186621479690075, f1 0.632,  prec 0.876, rec 0.494
TRAINING - Epoch 223 Batch 10: loss 0.012453379109501839, f1 0.675,  prec 0.73, rec 0.628
TRAINING - Epoch 223 Batch 20: loss 0.014787955209612846, f1 0.648,  prec 0.831, rec 0.531
TRAINING - Epoch 223 Batch 30: loss 0.01367686502635479, f1 0.624,  prec 0.812, rec 0.507
TRAINING - Epoch 223 Batch 40: loss 0.015033461153507233, f1 0.627,  prec 0.782, rec 0.524
TRAINING - Epoch 223 Batch 50: loss 0.014611540362238884, f1 0.649,  prec 0.729, rec 0.584
VALIDATION - Epoch 223 Batch 0: loss 0.04104887694120407, f1 0.355, prec 0.68, rec 0.24
VALIDATION - Epoch 223 Batch 10: loss 0.026050036773085594, f1 0.468, prec 0.826, rec 0.326
VALIDATION - Epoch 223 Batch 20: loss 0.0324699729681015, f1 0.472, prec 0.746, rec 0.345
TRAINING - Epoch 224 Batch 0: loss 0.018530182540416718, f1 0.486,  prec 0.75, rec 0.36
TRAINING - Epoch 224 Batch 10: loss 0.014115463942289352, f1 0.649,  prec 0.708, rec 0.599
TRAINING - Epoch 224 Batch 20: loss 0.011751524172723293, f1 0.538,  prec 0.766, rec 0.415
TRAINING - Epoch 224 Batch 30: loss 0.013098915107548237, f1 0.68,  prec 0.795, rec 0.594
TRAINING - Epoch 224 Batch 40: loss 0.014613248407840729, f1 0.648,  prec 0.818, rec 0.537
TRAINING - Epoch 224 Batch 50: loss 0.010609891265630722, f1 0.751,  prec 0.852, rec 0.671
VALIDATION - Epoch 224 Batch 0: loss 0.02980661392211914, f1 0.524, prec 0.653, rec 0.438
VALIDATION - Epoch 224 Batch 10: loss 0.02727779932320118, f1 0.543, prec 0.701, rec 0.444
VALIDATION - Epoch 224 Batch 20: loss 0.02919704280793667, f1 0.525, prec 0.708, rec 0.418
TRAINING - Epoch 225 Batch 0: loss 0.013884269632399082, f1 0.629,  prec 0.693, rec 0.575
TRAINING - Epoch 225 Batch 10: loss 0.015970151871442795, f1 0.593,  prec 0.772, rec 0.482
TRAINING - Epoch 225 Batch 20: loss 0.016979193314909935, f1 0.587,  prec 0.819, rec 0.457
TRAINING - Epoch 225 Batch 30: loss 0.012617606669664383, f1 0.637,  prec 0.728, rec 0.567
TRAINING - Epoch 225 Batch 40: loss 0.017943063750863075, f1 0.567,  prec 0.844, rec 0.427
TRAINING - Epoch 225 Batch 50: loss 0.012693868018686771, f1 0.626,  prec 0.698, rec 0.567
VALIDATION - Epoch 225 Batch 0: loss 0.027346273884177208, f1 0.496, prec 0.662, rec 0.397
VALIDATION - Epoch 225 Batch 10: loss 0.023571791127324104, f1 0.551, prec 0.739, rec 0.439
VALIDATION - Epoch 225 Batch 20: loss 0.02824031561613083, f1 0.467, prec 0.656, rec 0.362
TRAINING - Epoch 226 Batch 0: loss 0.012168069370090961, f1 0.664,  prec 0.805, rec 0.564
TRAINING - Epoch 226 Batch 10: loss 0.013783026486635208, f1 0.597,  prec 0.833, rec 0.465
TRAINING - Epoch 226 Batch 20: loss 0.010029492899775505, f1 0.744,  prec 0.836, rec 0.671
TRAINING - Epoch 226 Batch 30: loss 0.013701120391488075, f1 0.587,  prec 0.799, rec 0.464
TRAINING - Epoch 226 Batch 40: loss 0.014657864347100258, f1 0.597,  prec 0.764, rec 0.49
TRAINING - Epoch 226 Batch 50: loss 0.013020893558859825, f1 0.615,  prec 0.772, rec 0.511
VALIDATION - Epoch 226 Batch 0: loss 0.028820868581533432, f1 0.471, prec 0.805, rec 0.333
VALIDATION - Epoch 226 Batch 10: loss 0.027812715619802475, f1 0.456, prec 0.745, rec 0.328
VALIDATION - Epoch 226 Batch 20: loss 0.03625207394361496, f1 0.38, prec 0.684, rec 0.263
TRAINING - Epoch 227 Batch 0: loss 0.013633133843541145, f1 0.649,  prec 0.886, rec 0.512
TRAINING - Epoch 227 Batch 10: loss 0.01111598964780569, f1 0.608,  prec 0.745, rec 0.513
TRAINING - Epoch 227 Batch 20: loss 0.011498255655169487, f1 0.7,  prec 0.845, rec 0.598
TRAINING - Epoch 227 Batch 30: loss 0.013267399743199348, f1 0.624,  prec 0.86, rec 0.49
TRAINING - Epoch 227 Batch 40: loss 0.011749372817575932, f1 0.657,  prec 0.782, rec 0.567
TRAINING - Epoch 227 Batch 50: loss 0.014607015997171402, f1 0.631,  prec 0.734, rec 0.553
VALIDATION - Epoch 227 Batch 0: loss 0.028066521510481834, f1 0.415, prec 0.727, rec 0.29
VALIDATION - Epoch 227 Batch 10: loss 0.02355809323489666, f1 0.528, prec 0.748, rec 0.408
VALIDATION - Epoch 227 Batch 20: loss 0.025883454829454422, f1 0.506, prec 0.718, rec 0.39
TRAINING - Epoch 228 Batch 0: loss 0.0125260716304183, f1 0.656,  prec 0.77, rec 0.571
TRAINING - Epoch 228 Batch 10: loss 0.013702532276511192, f1 0.685,  prec 0.813, rec 0.592
TRAINING - Epoch 228 Batch 20: loss 0.013720737770199776, f1 0.642,  prec 0.719, rec 0.58
TRAINING - Epoch 228 Batch 30: loss 0.013944976031780243, f1 0.631,  prec 0.824, rec 0.512
TRAINING - Epoch 228 Batch 40: loss 0.013957531191408634, f1 0.667,  prec 0.731, rec 0.613
TRAINING - Epoch 228 Batch 50: loss 0.011643008328974247, f1 0.617,  prec 0.856, rec 0.483
VALIDATION - Epoch 228 Batch 0: loss 0.02698878012597561, f1 0.527, prec 0.619, rec 0.459
VALIDATION - Epoch 228 Batch 10: loss 0.02811478078365326, f1 0.487, prec 0.611, rec 0.405
VALIDATION - Epoch 228 Batch 20: loss 0.027918439358472824, f1 0.483, prec 0.606, rec 0.402
TRAINING - Epoch 229 Batch 0: loss 0.014545612968504429, f1 0.65,  prec 0.768, rec 0.563
TRAINING - Epoch 229 Batch 10: loss 0.013773931190371513, f1 0.64,  prec 0.801, rec 0.533
TRAINING - Epoch 229 Batch 20: loss 0.015521397814154625, f1 0.664,  prec 0.784, rec 0.576
TRAINING - Epoch 229 Batch 30: loss 0.011887263506650925, f1 0.694,  prec 0.804, rec 0.61
TRAINING - Epoch 229 Batch 40: loss 0.011165386065840721, f1 0.642,  prec 0.827, rec 0.524
TRAINING - Epoch 229 Batch 50: loss 0.011643274687230587, f1 0.646,  prec 0.781, rec 0.551
VALIDATION - Epoch 229 Batch 0: loss 0.027184849604964256, f1 0.476, prec 0.626, rec 0.383
VALIDATION - Epoch 229 Batch 10: loss 0.028892837464809418, f1 0.498, prec 0.663, rec 0.399
VALIDATION - Epoch 229 Batch 20: loss 0.028101585805416107, f1 0.479, prec 0.598, rec 0.399
TRAINING - Epoch 230 Batch 0: loss 0.013582106679677963, f1 0.658,  prec 0.737, rec 0.594
TRAINING - Epoch 230 Batch 10: loss 0.012614774517714977, f1 0.683,  prec 0.833, rec 0.579
TRAINING - Epoch 230 Batch 20: loss 0.01070402655750513, f1 0.7,  prec 0.814, rec 0.614
TRAINING - Epoch 230 Batch 30: loss 0.014759406447410583, f1 0.649,  prec 0.773, rec 0.559
TRAINING - Epoch 230 Batch 40: loss 0.013441288843750954, f1 0.578,  prec 0.735, rec 0.476
TRAINING - Epoch 230 Batch 50: loss 0.011311446316540241, f1 0.668,  prec 0.841, rec 0.554
VALIDATION - Epoch 230 Batch 0: loss 0.022104324772953987, f1 0.458, prec 0.713, rec 0.338
VALIDATION - Epoch 230 Batch 10: loss 0.031490620225667953, f1 0.497, prec 0.674, rec 0.393
VALIDATION - Epoch 230 Batch 20: loss 0.029454264789819717, f1 0.437, prec 0.713, rec 0.315
TRAINING - Epoch 231 Batch 0: loss 0.012525285594165325, f1 0.6,  prec 0.824, rec 0.471
TRAINING - Epoch 231 Batch 10: loss 0.01608843170106411, f1 0.683,  prec 0.684, rec 0.681
TRAINING - Epoch 231 Batch 20: loss 0.012800552882254124, f1 0.614,  prec 0.772, rec 0.51
TRAINING - Epoch 231 Batch 30: loss 0.010776207782328129, f1 0.68,  prec 0.783, rec 0.6
TRAINING - Epoch 231 Batch 40: loss 0.01338291633874178, f1 0.637,  prec 0.824, rec 0.519
TRAINING - Epoch 231 Batch 50: loss 0.012018028646707535, f1 0.639,  prec 0.839, rec 0.516
VALIDATION - Epoch 231 Batch 0: loss 0.022775238379836082, f1 0.475, prec 0.69, rec 0.362
VALIDATION - Epoch 231 Batch 10: loss 0.03324354439973831, f1 0.448, prec 0.591, rec 0.36
VALIDATION - Epoch 231 Batch 20: loss 0.0277546439319849, f1 0.45, prec 0.589, rec 0.365
TRAINING - Epoch 232 Batch 0: loss 0.01417273748666048, f1 0.628,  prec 0.769, rec 0.53
TRAINING - Epoch 232 Batch 10: loss 0.01198001578450203, f1 0.584,  prec 0.783, rec 0.465
TRAINING - Epoch 232 Batch 20: loss 0.012067718431353569, f1 0.679,  prec 0.774, rec 0.605
TRAINING - Epoch 232 Batch 30: loss 0.012143398635089397, f1 0.621,  prec 0.826, rec 0.498
TRAINING - Epoch 232 Batch 40: loss 0.013517635874450207, f1 0.652,  prec 0.758, rec 0.573
TRAINING - Epoch 232 Batch 50: loss 0.012389720417559147, f1 0.637,  prec 0.838, rec 0.514
VALIDATION - Epoch 232 Batch 0: loss 0.027025863528251648, f1 0.523, prec 0.7, rec 0.418
VALIDATION - Epoch 232 Batch 10: loss 0.023596348240971565, f1 0.552, prec 0.758, rec 0.434
VALIDATION - Epoch 232 Batch 20: loss 0.028239574283361435, f1 0.421, prec 0.632, rec 0.316
TRAINING - Epoch 233 Batch 0: loss 0.01297468040138483, f1 0.674,  prec 0.795, rec 0.585
TRAINING - Epoch 233 Batch 10: loss 0.014718243852257729, f1 0.612,  prec 0.765, rec 0.51
TRAINING - Epoch 233 Batch 20: loss 0.01121399737894535, f1 0.578,  prec 0.802, rec 0.451
TRAINING - Epoch 233 Batch 30: loss 0.012847966514527798, f1 0.626,  prec 0.795, rec 0.516
TRAINING - Epoch 233 Batch 40: loss 0.012883272022008896, f1 0.693,  prec 0.787, rec 0.619
TRAINING - Epoch 233 Batch 50: loss 0.013124424032866955, f1 0.585,  prec 0.691, rec 0.506
VALIDATION - Epoch 233 Batch 0: loss 0.027898477390408516, f1 0.508, prec 0.746, rec 0.385
VALIDATION - Epoch 233 Batch 10: loss 0.030220994725823402, f1 0.408, prec 0.685, rec 0.29
VALIDATION - Epoch 233 Batch 20: loss 0.028540775179862976, f1 0.448, prec 0.679, rec 0.335
TRAINING - Epoch 234 Batch 0: loss 0.014445923268795013, f1 0.636,  prec 0.826, rec 0.517
TRAINING - Epoch 234 Batch 10: loss 0.013427452184259892, f1 0.616,  prec 0.736, rec 0.53
TRAINING - Epoch 234 Batch 20: loss 0.013153936713933945, f1 0.672,  prec 0.825, rec 0.567
TRAINING - Epoch 234 Batch 30: loss 0.014949031174182892, f1 0.608,  prec 0.821, rec 0.483
TRAINING - Epoch 234 Batch 40: loss 0.014323841780424118, f1 0.66,  prec 0.75, rec 0.589
TRAINING - Epoch 234 Batch 50: loss 0.012317383661866188, f1 0.614,  prec 0.762, rec 0.514
VALIDATION - Epoch 234 Batch 0: loss 0.0293582696467638, f1 0.491, prec 0.704, rec 0.377
VALIDATION - Epoch 234 Batch 10: loss 0.03374703973531723, f1 0.432, prec 0.654, rec 0.322
VALIDATION - Epoch 234 Batch 20: loss 0.028271693736314774, f1 0.495, prec 0.699, rec 0.383
TRAINING - Epoch 235 Batch 0: loss 0.01238532830029726, f1 0.67,  prec 0.822, rec 0.565
TRAINING - Epoch 235 Batch 10: loss 0.012622881680727005, f1 0.654,  prec 0.793, rec 0.557
TRAINING - Epoch 235 Batch 20: loss 0.011326340958476067, f1 0.644,  prec 0.776, rec 0.55
TRAINING - Epoch 235 Batch 30: loss 0.013967444188892841, f1 0.653,  prec 0.706, rec 0.606
TRAINING - Epoch 235 Batch 40: loss 0.01370618212968111, f1 0.665,  prec 0.825, rec 0.557
TRAINING - Epoch 235 Batch 50: loss 0.014223350211977959, f1 0.642,  prec 0.82, rec 0.528
VALIDATION - Epoch 235 Batch 0: loss 0.033171433955430984, f1 0.423, prec 0.545, rec 0.346
VALIDATION - Epoch 235 Batch 10: loss 0.02826661802828312, f1 0.498, prec 0.697, rec 0.387
VALIDATION - Epoch 235 Batch 20: loss 0.030540617182850838, f1 0.477, prec 0.662, rec 0.373
TRAINING - Epoch 236 Batch 0: loss 0.013732612133026123, f1 0.685,  prec 0.762, rec 0.622
TRAINING - Epoch 236 Batch 10: loss 0.013567824847996235, f1 0.671,  prec 0.757, rec 0.602
TRAINING - Epoch 236 Batch 20: loss 0.013886230997741222, f1 0.645,  prec 0.774, rec 0.553
TRAINING - Epoch 236 Batch 30: loss 0.013359813950955868, f1 0.644,  prec 0.737, rec 0.572
TRAINING - Epoch 236 Batch 40: loss 0.012868721038103104, f1 0.659,  prec 0.847, rec 0.54
TRAINING - Epoch 236 Batch 50: loss 0.012255782261490822, f1 0.675,  prec 0.777, rec 0.597
VALIDATION - Epoch 236 Batch 0: loss 0.028290631249547005, f1 0.498, prec 0.609, rec 0.421
VALIDATION - Epoch 236 Batch 10: loss 0.02840682491660118, f1 0.467, prec 0.658, rec 0.362
VALIDATION - Epoch 236 Batch 20: loss 0.029284914955496788, f1 0.47, prec 0.618, rec 0.379
TRAINING - Epoch 237 Batch 0: loss 0.011471905745565891, f1 0.662,  prec 0.781, rec 0.575
TRAINING - Epoch 237 Batch 10: loss 0.015227177180349827, f1 0.613,  prec 0.783, rec 0.504
TRAINING - Epoch 237 Batch 20: loss 0.011994442902505398, f1 0.662,  prec 0.872, rec 0.534
TRAINING - Epoch 237 Batch 30: loss 0.013008510693907738, f1 0.574,  prec 0.682, rec 0.495
TRAINING - Epoch 237 Batch 40: loss 0.013638688251376152, f1 0.649,  prec 0.9, rec 0.508
TRAINING - Epoch 237 Batch 50: loss 0.01266800332814455, f1 0.622,  prec 0.753, rec 0.53
VALIDATION - Epoch 237 Batch 0: loss 0.025930384173989296, f1 0.485, prec 0.607, rec 0.404
VALIDATION - Epoch 237 Batch 10: loss 0.024693353101611137, f1 0.498, prec 0.687, rec 0.39
VALIDATION - Epoch 237 Batch 20: loss 0.030057374387979507, f1 0.444, prec 0.623, rec 0.345
TRAINING - Epoch 238 Batch 0: loss 0.012742618098855019, f1 0.702,  prec 0.776, rec 0.641
TRAINING - Epoch 238 Batch 10: loss 0.012892188504338264, f1 0.613,  prec 0.804, rec 0.496
TRAINING - Epoch 238 Batch 20: loss 0.012144410982728004, f1 0.692,  prec 0.733, rec 0.655
TRAINING - Epoch 238 Batch 30: loss 0.013716357760131359, f1 0.659,  prec 0.826, rec 0.549
TRAINING - Epoch 238 Batch 40: loss 0.01100208330899477, f1 0.676,  prec 0.801, rec 0.585
TRAINING - Epoch 238 Batch 50: loss 0.012691793031990528, f1 0.682,  prec 0.804, rec 0.591
VALIDATION - Epoch 238 Batch 0: loss 0.02549862116575241, f1 0.509, prec 0.696, rec 0.401
VALIDATION - Epoch 238 Batch 10: loss 0.02564227767288685, f1 0.5, prec 0.613, rec 0.422
VALIDATION - Epoch 238 Batch 20: loss 0.02613517828285694, f1 0.441, prec 0.583, rec 0.355
TRAINING - Epoch 239 Batch 0: loss 0.012957330793142319, f1 0.659,  prec 0.756, rec 0.584
TRAINING - Epoch 239 Batch 10: loss 0.011247096583247185, f1 0.676,  prec 0.775, rec 0.6
TRAINING - Epoch 239 Batch 20: loss 0.015086835250258446, f1 0.617,  prec 0.764, rec 0.517
TRAINING - Epoch 239 Batch 30: loss 0.011798341758549213, f1 0.687,  prec 0.871, rec 0.568
TRAINING - Epoch 239 Batch 40: loss 0.012477466836571693, f1 0.637,  prec 0.833, rec 0.516
TRAINING - Epoch 239 Batch 50: loss 0.011340214870870113, f1 0.667,  prec 0.769, rec 0.588
VALIDATION - Epoch 239 Batch 0: loss 0.026837702840566635, f1 0.489, prec 0.681, rec 0.381
VALIDATION - Epoch 239 Batch 10: loss 0.022949887439608574, f1 0.538, prec 0.714, rec 0.431
VALIDATION - Epoch 239 Batch 20: loss 0.029207397252321243, f1 0.481, prec 0.667, rec 0.376
TRAINING - Epoch 240 Batch 0: loss 0.011015383526682854, f1 0.691,  prec 0.797, rec 0.61
TRAINING - Epoch 240 Batch 10: loss 0.013831278309226036, f1 0.627,  prec 0.703, rec 0.566
TRAINING - Epoch 240 Batch 20: loss 0.013639616779983044, f1 0.69,  prec 0.773, rec 0.623
TRAINING - Epoch 240 Batch 30: loss 0.013023930601775646, f1 0.569,  prec 0.848, rec 0.427
TRAINING - Epoch 240 Batch 40: loss 0.011750013567507267, f1 0.649,  prec 0.79, rec 0.551
TRAINING - Epoch 240 Batch 50: loss 0.012534165754914284, f1 0.662,  prec 0.813, rec 0.558
VALIDATION - Epoch 240 Batch 0: loss 0.0277932807803154, f1 0.458, prec 0.787, rec 0.323
VALIDATION - Epoch 240 Batch 10: loss 0.02605869248509407, f1 0.455, prec 0.748, rec 0.327
VALIDATION - Epoch 240 Batch 20: loss 0.026910247281193733, f1 0.487, prec 0.761, rec 0.358
TRAINING - Epoch 241 Batch 0: loss 0.010811020620167255, f1 0.694,  prec 0.832, rec 0.595
TRAINING - Epoch 241 Batch 10: loss 0.013181017711758614, f1 0.645,  prec 0.813, rec 0.535
TRAINING - Epoch 241 Batch 20: loss 0.011028004810214043, f1 0.719,  prec 0.799, rec 0.653
TRAINING - Epoch 241 Batch 30: loss 0.01461685448884964, f1 0.618,  prec 0.769, rec 0.517
TRAINING - Epoch 241 Batch 40: loss 0.013379286974668503, f1 0.59,  prec 0.881, rec 0.444
TRAINING - Epoch 241 Batch 50: loss 0.014151882380247116, f1 0.65,  prec 0.858, rec 0.523
VALIDATION - Epoch 241 Batch 0: loss 0.03025897778570652, f1 0.424, prec 0.648, rec 0.315
VALIDATION - Epoch 241 Batch 10: loss 0.028402751311659813, f1 0.464, prec 0.674, rec 0.354
VALIDATION - Epoch 241 Batch 20: loss 0.032950691878795624, f1 0.451, prec 0.744, rec 0.324
TRAINING - Epoch 242 Batch 0: loss 0.013282524421811104, f1 0.637,  prec 0.8, rec 0.529
TRAINING - Epoch 242 Batch 10: loss 0.012813094072043896, f1 0.605,  prec 0.756, rec 0.504
TRAINING - Epoch 242 Batch 20: loss 0.012198787182569504, f1 0.68,  prec 0.797, rec 0.593
TRAINING - Epoch 242 Batch 30: loss 0.01364769134670496, f1 0.638,  prec 0.85, rec 0.51
TRAINING - Epoch 242 Batch 40: loss 0.012602189555764198, f1 0.667,  prec 0.776, rec 0.584
TRAINING - Epoch 242 Batch 50: loss 0.013463463634252548, f1 0.667,  prec 0.804, rec 0.569
VALIDATION - Epoch 242 Batch 0: loss 0.025774599984288216, f1 0.526, prec 0.725, rec 0.412
VALIDATION - Epoch 242 Batch 10: loss 0.027283720672130585, f1 0.501, prec 0.671, rec 0.4
VALIDATION - Epoch 242 Batch 20: loss 0.02474752999842167, f1 0.519, prec 0.703, rec 0.411
TRAINING - Epoch 243 Batch 0: loss 0.011922551319003105, f1 0.649,  prec 0.762, rec 0.566
TRAINING - Epoch 243 Batch 10: loss 0.01148164551705122, f1 0.667,  prec 0.785, rec 0.579
TRAINING - Epoch 243 Batch 20: loss 0.011844265274703503, f1 0.646,  prec 0.789, rec 0.548
TRAINING - Epoch 243 Batch 30: loss 0.013365731574594975, f1 0.667,  prec 0.797, rec 0.573
TRAINING - Epoch 243 Batch 40: loss 0.013551799580454826, f1 0.618,  prec 0.782, rec 0.511
TRAINING - Epoch 243 Batch 50: loss 0.012936045415699482, f1 0.63,  prec 0.782, rec 0.528
VALIDATION - Epoch 243 Batch 0: loss 0.02241346798837185, f1 0.569, prec 0.736, rec 0.464
VALIDATION - Epoch 243 Batch 10: loss 0.030920173972845078, f1 0.441, prec 0.669, rec 0.329
VALIDATION - Epoch 243 Batch 20: loss 0.026301605626940727, f1 0.519, prec 0.713, rec 0.408
TRAINING - Epoch 244 Batch 0: loss 0.012678826227784157, f1 0.639,  prec 0.761, rec 0.55
TRAINING - Epoch 244 Batch 10: loss 0.013887135311961174, f1 0.636,  prec 0.788, rec 0.534
TRAINING - Epoch 244 Batch 20: loss 0.012927801348268986, f1 0.682,  prec 0.814, rec 0.587
TRAINING - Epoch 244 Batch 30: loss 0.012952828779816628, f1 0.648,  prec 0.819, rec 0.536
TRAINING - Epoch 244 Batch 40: loss 0.014787075109779835, f1 0.619,  prec 0.787, rec 0.51
TRAINING - Epoch 244 Batch 50: loss 0.015353088267147541, f1 0.634,  prec 0.759, rec 0.544
VALIDATION - Epoch 244 Batch 0: loss 0.030461207032203674, f1 0.429, prec 0.731, rec 0.304
VALIDATION - Epoch 244 Batch 10: loss 0.030721785500645638, f1 0.448, prec 0.779, rec 0.314
VALIDATION - Epoch 244 Batch 20: loss 0.02553037740290165, f1 0.452, prec 0.79, rec 0.317
TRAINING - Epoch 245 Batch 0: loss 0.010534762404859066, f1 0.621,  prec 0.799, rec 0.509
TRAINING - Epoch 245 Batch 10: loss 0.012346113100647926, f1 0.664,  prec 0.746, rec 0.597
TRAINING - Epoch 245 Batch 20: loss 0.012928581796586514, f1 0.64,  prec 0.815, rec 0.527
TRAINING - Epoch 245 Batch 30: loss 0.012094583362340927, f1 0.679,  prec 0.844, rec 0.567
TRAINING - Epoch 245 Batch 40: loss 0.013039798475801945, f1 0.678,  prec 0.807, rec 0.585
TRAINING - Epoch 245 Batch 50: loss 0.012865577824413776, f1 0.624,  prec 0.839, rec 0.496
VALIDATION - Epoch 245 Batch 0: loss 0.03365414962172508, f1 0.488, prec 0.649, rec 0.391
VALIDATION - Epoch 245 Batch 10: loss 0.028939910233020782, f1 0.463, prec 0.634, rec 0.365
VALIDATION - Epoch 245 Batch 20: loss 0.023323941975831985, f1 0.519, prec 0.644, rec 0.435
TRAINING - Epoch 246 Batch 0: loss 0.013667301274836063, f1 0.648,  prec 0.748, rec 0.571
TRAINING - Epoch 246 Batch 10: loss 0.013502242974936962, f1 0.628,  prec 0.869, rec 0.492
TRAINING - Epoch 246 Batch 20: loss 0.012474537827074528, f1 0.687,  prec 0.796, rec 0.604
TRAINING - Epoch 246 Batch 30: loss 0.012100626714527607, f1 0.687,  prec 0.824, rec 0.589
TRAINING - Epoch 246 Batch 40: loss 0.013780917972326279, f1 0.69,  prec 0.784, rec 0.617
TRAINING - Epoch 246 Batch 50: loss 0.012536806985735893, f1 0.624,  prec 0.839, rec 0.496
VALIDATION - Epoch 246 Batch 0: loss 0.03536897525191307, f1 0.433, prec 0.714, rec 0.31
VALIDATION - Epoch 246 Batch 10: loss 0.028914257884025574, f1 0.495, prec 0.719, rec 0.377
VALIDATION - Epoch 246 Batch 20: loss 0.030338868498802185, f1 0.448, prec 0.613, rec 0.353
TRAINING - Epoch 247 Batch 0: loss 0.012071735225617886, f1 0.668,  prec 0.806, rec 0.571
TRAINING - Epoch 247 Batch 10: loss 0.012156461365520954, f1 0.63,  prec 0.764, rec 0.536
TRAINING - Epoch 247 Batch 20: loss 0.012880105525255203, f1 0.609,  prec 0.859, rec 0.472
TRAINING - Epoch 247 Batch 30: loss 0.01191286277025938, f1 0.662,  prec 0.806, rec 0.561
TRAINING - Epoch 247 Batch 40: loss 0.012070145457983017, f1 0.696,  prec 0.893, rec 0.57
TRAINING - Epoch 247 Batch 50: loss 0.01241122093051672, f1 0.627,  prec 0.801, rec 0.515
VALIDATION - Epoch 247 Batch 0: loss 0.02687627449631691, f1 0.464, prec 0.686, rec 0.35
VALIDATION - Epoch 247 Batch 10: loss 0.03223666921257973, f1 0.426, prec 0.72, rec 0.302
VALIDATION - Epoch 247 Batch 20: loss 0.025591721758246422, f1 0.504, prec 0.703, rec 0.392
TRAINING - Epoch 248 Batch 0: loss 0.011473015882074833, f1 0.652,  prec 0.829, rec 0.538
TRAINING - Epoch 248 Batch 10: loss 0.012723620980978012, f1 0.681,  prec 0.799, rec 0.593
TRAINING - Epoch 248 Batch 20: loss 0.013519678264856339, f1 0.65,  prec 0.798, rec 0.549
TRAINING - Epoch 248 Batch 30: loss 0.011261817067861557, f1 0.664,  prec 0.789, rec 0.573
TRAINING - Epoch 248 Batch 40: loss 0.012525341473519802, f1 0.697,  prec 0.847, rec 0.592
TRAINING - Epoch 248 Batch 50: loss 0.013549411669373512, f1 0.649,  prec 0.862, rec 0.521
VALIDATION - Epoch 248 Batch 0: loss 0.03238869830965996, f1 0.469, prec 0.728, rec 0.346
VALIDATION - Epoch 248 Batch 10: loss 0.028598809614777565, f1 0.482, prec 0.719, rec 0.362
VALIDATION - Epoch 248 Batch 20: loss 0.02800888754427433, f1 0.453, prec 0.661, rec 0.345
TRAINING - Epoch 249 Batch 0: loss 0.011594424955546856, f1 0.661,  prec 0.813, rec 0.556
TRAINING - Epoch 249 Batch 10: loss 0.011093774810433388, f1 0.631,  prec 0.761, rec 0.539
TRAINING - Epoch 249 Batch 20: loss 0.01342625729739666, f1 0.662,  prec 0.837, rec 0.548
TRAINING - Epoch 249 Batch 30: loss 0.014873631298542023, f1 0.663,  prec 0.811, rec 0.56
TRAINING - Epoch 249 Batch 40: loss 0.0099330460652709, f1 0.672,  prec 0.83, rec 0.564
TRAINING - Epoch 249 Batch 50: loss 0.013289588503539562, f1 0.588,  prec 0.826, rec 0.456
VALIDATION - Epoch 249 Batch 0: loss 0.024872994050383568, f1 0.48, prec 0.701, rec 0.364
VALIDATION - Epoch 249 Batch 10: loss 0.029441699385643005, f1 0.484, prec 0.773, rec 0.352
VALIDATION - Epoch 249 Batch 20: loss 0.0271238312125206, f1 0.387, prec 0.657, rec 0.274
